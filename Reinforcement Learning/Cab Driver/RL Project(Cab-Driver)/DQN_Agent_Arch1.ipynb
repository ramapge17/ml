{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon = 1\n",
    "        # the below epsilon decay rate has been calculated from the graph as shown at the end of the file\n",
    "        self.epsilon_decay = 0.9991\n",
    "        #self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state,env):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment\n",
    "        #print(\"Get Action state is \",state)\n",
    "        possible_actions_index,actions = env.requests(state) # Find possible action indexes and append 0\n",
    "        possible_actions_index.append(0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            # Give a random action only amongst possible action\n",
    "            return random.sample(possible_actions_index,1)[0]\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = state.reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state)\n",
    "            # Give action with max q_value only amongst possible action\n",
    "            return np.where(q_value[0] == np.max(np.array([q_value[0][i] for i in possible_actions_index])))[0][0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state,done):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state,done))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self,env):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            \n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                \n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                done.append(done_boolean)\n",
    "                update_output[i] = next_state\n",
    "                \n",
    "                # Write your code from here\n",
    "                \n",
    "            # 1. Predict the target from earlier model           \n",
    "            target = self.model.predict(update_input)\n",
    "            \n",
    "            # 2. Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                # Find possible actions from next state\n",
    "                next_possible_actions_index,_ = env.requests(update_output[i])\n",
    "                next_possible_actions_index.append(0)\n",
    "                if not done[i]:\n",
    "                    # Only take the max q_value from valid actions from next state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(np.array([target_qval[i][j] for j in next_possible_actions_index]))\n",
    "                else:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                \n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "            #print(\"Training Model\")\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            #print(\"Model Training Model\")\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State is  [0, 21, 6]\n",
      "episode 0, reward -235.0, memory_length 134, epsilon 0.9991, time 726.0, rides 133\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 1, reward -248.0, memory_length 258, epsilon 0.9982008099999999, time 733.0, rides 123\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 2, reward -317.0, memory_length 375, epsilon 0.9973024292709999, time 729.0, rides 116\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 3, reward -392.0, memory_length 507, epsilon 0.996404857084656, time 731.0, rides 131\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 4, reward -144.0, memory_length 631, epsilon 0.9955080927132798, time 727.0, rides 123\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 5, reward -284.0, memory_length 759, epsilon 0.9946121354298378, time 724.0, rides 127\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 6, reward -466.0, memory_length 898, epsilon 0.993716984507951, time 732.0, rides 138\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7, reward -224.0, memory_length 1014, epsilon 0.9928226392218938, time 728.0, rides 115\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 8, reward -241.0, memory_length 1151, epsilon 0.9919290988465941, time 730.0, rides 136\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 9, reward -310.0, memory_length 1288, epsilon 0.9910363626576322, time 733.0, rides 136\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 10, reward -287.0, memory_length 1430, epsilon 0.9901444299312403, time 738.0, rides 141\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 11, reward -133.0, memory_length 1556, epsilon 0.9892532999443022, time 732.0, rides 125\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 12, reward -489.0, memory_length 1673, epsilon 0.9883629719743523, time 730.0, rides 116\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 13, reward -56.0, memory_length 1804, epsilon 0.9874734452995754, time 729.0, rides 130\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 14, reward -226.0, memory_length 1939, epsilon 0.9865847191988057, time 722.0, rides 134\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 15, reward -103.0, memory_length 2000, epsilon 0.9856967929515268, time 725.0, rides 135\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 16, reward -164.0, memory_length 2000, epsilon 0.9848096658378704, time 733.0, rides 132\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 17, reward -201.0, memory_length 2000, epsilon 0.9839233371386163, time 727.0, rides 127\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 18, reward -207.0, memory_length 2000, epsilon 0.9830378061351915, time 732.0, rides 115\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 19, reward -416.0, memory_length 2000, epsilon 0.9821530721096698, time 727.0, rides 133\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 20, reward 134.0, memory_length 2000, epsilon 0.9812691343447711, time 731.0, rides 134\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 21, reward -61.0, memory_length 2000, epsilon 0.9803859921238608, time 729.0, rides 119\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 22, reward -467.0, memory_length 2000, epsilon 0.9795036447309493, time 728.0, rides 131\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 23, reward -389.0, memory_length 2000, epsilon 0.9786220914506915, time 733.0, rides 125\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 24, reward -441.0, memory_length 2000, epsilon 0.9777413315683858, time 727.0, rides 144\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 25, reward -227.0, memory_length 2000, epsilon 0.9768613643699743, time 731.0, rides 139\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 26, reward -267.0, memory_length 2000, epsilon 0.9759821891420413, time 730.0, rides 140\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 27, reward -348.0, memory_length 2000, epsilon 0.9751038051718134, time 730.0, rides 126\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 28, reward -380.0, memory_length 2000, epsilon 0.9742262117471587, time 737.0, rides 121\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 29, reward -315.0, memory_length 2000, epsilon 0.9733494081565863, time 728.0, rides 128\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 30, reward -382.0, memory_length 2000, epsilon 0.9724733936892453, time 731.0, rides 124\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 31, reward -468.0, memory_length 2000, epsilon 0.971598167634925, time 724.0, rides 134\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 32, reward -76.0, memory_length 2000, epsilon 0.9707237292840536, time 726.0, rides 128\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 33, reward -229.0, memory_length 2000, epsilon 0.969850077927698, time 734.0, rides 128\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 34, reward -249.0, memory_length 2000, epsilon 0.968977212857563, time 731.0, rides 123\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 35, reward -346.0, memory_length 2000, epsilon 0.9681051333659911, time 727.0, rides 128\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 36, reward -158.0, memory_length 2000, epsilon 0.9672338387459617, time 735.0, rides 132\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 37, reward -52.0, memory_length 2000, epsilon 0.9663633282910903, time 723.0, rides 137\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 38, reward -392.0, memory_length 2000, epsilon 0.9654936012956283, time 727.0, rides 126\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 39, reward -207.0, memory_length 2000, epsilon 0.9646246570544622, time 735.0, rides 143\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 40, reward -341.0, memory_length 2000, epsilon 0.9637564948631132, time 729.0, rides 117\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 41, reward -384.0, memory_length 2000, epsilon 0.9628891140177364, time 726.0, rides 141\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 42, reward -151.0, memory_length 2000, epsilon 0.9620225138151204, time 728.0, rides 143\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 43, reward -437.0, memory_length 2000, epsilon 0.9611566935526867, time 727.0, rides 131\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 44, reward -353.0, memory_length 2000, epsilon 0.9602916525284894, time 737.0, rides 131\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 45, reward -248.0, memory_length 2000, epsilon 0.9594273900412137, time 733.0, rides 123\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 46, reward -167.0, memory_length 2000, epsilon 0.9585639053901766, time 738.0, rides 139\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 47, reward -210.0, memory_length 2000, epsilon 0.9577011978753254, time 730.0, rides 113\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 48, reward -260.0, memory_length 2000, epsilon 0.9568392667972375, time 724.0, rides 127\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 49, reward -268.0, memory_length 2000, epsilon 0.95597811145712, time 734.0, rides 135\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 50, reward -142.0, memory_length 2000, epsilon 0.9551177311568085, time 727.0, rides 118\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 51, reward -277.0, memory_length 2000, epsilon 0.9542581251987674, time 722.0, rides 138\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 52, reward 17.0, memory_length 2000, epsilon 0.9533992928860885, time 734.0, rides 133\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 53, reward -344.0, memory_length 2000, epsilon 0.952541233522491, time 722.0, rides 127\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 54, reward -141.0, memory_length 2000, epsilon 0.9516839464123207, time 725.0, rides 126\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 55, reward -185.0, memory_length 2000, epsilon 0.9508274308605495, time 729.0, rides 128\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 56, reward -313.0, memory_length 2000, epsilon 0.949971686172775, time 725.0, rides 121\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 57, reward -97.0, memory_length 2000, epsilon 0.9491167116552195, time 730.0, rides 121\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 58, reward -259.0, memory_length 2000, epsilon 0.9482625066147298, time 727.0, rides 126\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 59, reward -332.0, memory_length 2000, epsilon 0.9474090703587765, time 730.0, rides 139\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 60, reward -68.0, memory_length 2000, epsilon 0.9465564021954537, time 724.0, rides 127\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 61, reward 120.0, memory_length 2000, epsilon 0.9457045014334777, time 726.0, rides 116\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 62, reward -268.0, memory_length 2000, epsilon 0.9448533673821876, time 731.0, rides 122\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 63, reward -293.0, memory_length 2000, epsilon 0.9440029993515436, time 723.0, rides 115\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 64, reward -85.0, memory_length 2000, epsilon 0.9431533966521273, time 726.0, rides 127\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 65, reward -307.0, memory_length 2000, epsilon 0.9423045585951404, time 727.0, rides 123\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 66, reward -305.0, memory_length 2000, epsilon 0.9414564844924047, time 727.0, rides 132\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 67, reward -131.0, memory_length 2000, epsilon 0.9406091736563615, time 724.0, rides 124\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 68, reward -167.0, memory_length 2000, epsilon 0.9397626254000708, time 733.0, rides 122\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 69, reward -24.0, memory_length 2000, epsilon 0.9389168390372108, time 725.0, rides 121\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 70, reward -312.0, memory_length 2000, epsilon 0.9380718138820773, time 730.0, rides 130\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 71, reward -302.0, memory_length 2000, epsilon 0.9372275492495834, time 725.0, rides 131\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 72, reward -335.0, memory_length 2000, epsilon 0.9363840444552588, time 729.0, rides 127\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 73, reward -210.0, memory_length 2000, epsilon 0.9355412988152491, time 724.0, rides 130\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 74, reward -275.0, memory_length 2000, epsilon 0.9346993116463154, time 723.0, rides 129\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 75, reward -87.0, memory_length 2000, epsilon 0.9338580822658337, time 739.0, rides 126\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 76, reward -42.0, memory_length 2000, epsilon 0.9330176099917944, time 730.0, rides 118\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 77, reward -392.0, memory_length 2000, epsilon 0.9321778941428017, time 732.0, rides 123\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 78, reward -120.0, memory_length 2000, epsilon 0.9313389340380732, time 724.0, rides 111\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 79, reward -229.0, memory_length 2000, epsilon 0.930500728997439, time 727.0, rides 136\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 80, reward -173.0, memory_length 2000, epsilon 0.9296632783413412, time 730.0, rides 132\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 81, reward -375.0, memory_length 2000, epsilon 0.928826581390834, time 730.0, rides 123\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 82, reward -138.0, memory_length 2000, epsilon 0.9279906374675821, time 722.0, rides 133\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 83, reward -63.0, memory_length 2000, epsilon 0.9271554458938613, time 729.0, rides 134\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 84, reward -166.0, memory_length 2000, epsilon 0.9263210059925568, time 735.0, rides 127\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 85, reward -30.0, memory_length 2000, epsilon 0.9254873170871636, time 725.0, rides 126\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 86, reward -103.0, memory_length 2000, epsilon 0.9246543785017851, time 723.0, rides 137\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 87, reward -449.0, memory_length 2000, epsilon 0.9238221895611335, time 736.0, rides 125\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 88, reward -258.0, memory_length 2000, epsilon 0.9229907495905284, time 726.0, rides 135\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 89, reward -389.0, memory_length 2000, epsilon 0.922160057915897, time 727.0, rides 122\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 90, reward -26.0, memory_length 2000, epsilon 0.9213301138637726, time 729.0, rides 127\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 91, reward -323.0, memory_length 2000, epsilon 0.9205009167612952, time 728.0, rides 124\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 92, reward -355.0, memory_length 2000, epsilon 0.91967246593621, time 730.0, rides 120\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 93, reward -187.0, memory_length 2000, epsilon 0.9188447607168674, time 730.0, rides 113\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 94, reward -329.0, memory_length 2000, epsilon 0.9180178004322221, time 733.0, rides 125\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 95, reward -81.0, memory_length 2000, epsilon 0.9171915844118331, time 727.0, rides 121\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 96, reward -332.0, memory_length 2000, epsilon 0.9163661119858625, time 725.0, rides 126\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 97, reward -196.0, memory_length 2000, epsilon 0.9155413824850752, time 727.0, rides 119\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 98, reward -133.0, memory_length 2000, epsilon 0.9147173952408386, time 731.0, rides 126\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 99, reward -377.0, memory_length 2000, epsilon 0.9138941495851218, time 736.0, rides 128\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 100, reward 69.0, memory_length 2000, epsilon 0.9130716448504952, time 736.0, rides 122\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 101, reward -189.0, memory_length 2000, epsilon 0.9122498803701298, time 730.0, rides 125\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 102, reward -108.0, memory_length 2000, epsilon 0.9114288554777966, time 728.0, rides 125\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 103, reward -509.0, memory_length 2000, epsilon 0.9106085695078666, time 725.0, rides 137\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 104, reward -149.0, memory_length 2000, epsilon 0.9097890217953095, time 721.0, rides 120\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 105, reward 14.0, memory_length 2000, epsilon 0.9089702116756937, time 731.0, rides 126\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 106, reward -1.0, memory_length 2000, epsilon 0.9081521384851856, time 734.0, rides 124\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 107, reward -222.0, memory_length 2000, epsilon 0.9073348015605489, time 728.0, rides 119\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 108, reward -170.0, memory_length 2000, epsilon 0.9065182002391444, time 723.0, rides 134\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 109, reward -75.0, memory_length 2000, epsilon 0.9057023338589292, time 722.0, rides 114\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 110, reward -439.0, memory_length 2000, epsilon 0.9048872017584562, time 737.0, rides 131\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 111, reward -66.0, memory_length 2000, epsilon 0.9040728032768736, time 739.0, rides 129\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 112, reward -353.0, memory_length 2000, epsilon 0.9032591377539244, time 727.0, rides 130\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 113, reward -12.0, memory_length 2000, epsilon 0.9024462045299458, time 741.0, rides 132\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 114, reward -463.0, memory_length 2000, epsilon 0.9016340029458689, time 724.0, rides 120\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 115, reward -239.0, memory_length 2000, epsilon 0.9008225323432176, time 732.0, rides 146\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 116, reward -260.0, memory_length 2000, epsilon 0.9000117920641088, time 724.0, rides 123\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 117, reward -130.0, memory_length 2000, epsilon 0.8992017814512511, time 729.0, rides 137\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 118, reward -256.0, memory_length 2000, epsilon 0.8983924998479449, time 728.0, rides 132\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 119, reward -262.0, memory_length 2000, epsilon 0.8975839465980817, time 723.0, rides 117\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 120, reward -334.0, memory_length 2000, epsilon 0.8967761210461435, time 733.0, rides 124\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 121, reward -65.0, memory_length 2000, epsilon 0.8959690225372019, time 730.0, rides 133\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 122, reward -5.0, memory_length 2000, epsilon 0.8951626504169184, time 727.0, rides 140\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 123, reward -176.0, memory_length 2000, epsilon 0.8943570040315432, time 726.0, rides 132\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 124, reward -95.0, memory_length 2000, epsilon 0.8935520827279148, time 733.0, rides 119\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 125, reward -274.0, memory_length 2000, epsilon 0.8927478858534597, time 727.0, rides 137\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 126, reward -149.0, memory_length 2000, epsilon 0.8919444127561915, time 726.0, rides 114\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 127, reward 12.0, memory_length 2000, epsilon 0.891141662784711, time 729.0, rides 131\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 128, reward -100.0, memory_length 2000, epsilon 0.8903396352882047, time 738.0, rides 121\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 129, reward -69.0, memory_length 2000, epsilon 0.8895383296164453, time 738.0, rides 121\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 130, reward -282.0, memory_length 2000, epsilon 0.8887377451197905, time 727.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 131, reward -170.0, memory_length 2000, epsilon 0.8879378811491827, time 733.0, rides 129\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 132, reward -350.0, memory_length 2000, epsilon 0.8871387370561484, time 730.0, rides 139\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 133, reward -254.0, memory_length 2000, epsilon 0.8863403121927979, time 724.0, rides 130\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 134, reward -227.0, memory_length 2000, epsilon 0.8855426059118243, time 720.0, rides 121\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 135, reward -194.0, memory_length 2000, epsilon 0.8847456175665037, time 723.0, rides 125\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 136, reward -484.0, memory_length 2000, epsilon 0.8839493465106939, time 726.0, rides 132\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 137, reward -15.0, memory_length 2000, epsilon 0.8831537920988343, time 737.0, rides 127\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 138, reward -308.0, memory_length 2000, epsilon 0.8823589536859453, time 729.0, rides 140\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 139, reward 25.0, memory_length 2000, epsilon 0.8815648306276279, time 728.0, rides 123\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 140, reward -34.0, memory_length 2000, epsilon 0.880771422280063, time 728.0, rides 122\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 141, reward -157.0, memory_length 2000, epsilon 0.879978728000011, time 727.0, rides 119\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 142, reward -335.0, memory_length 2000, epsilon 0.8791867471448109, time 725.0, rides 137\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 143, reward -102.0, memory_length 2000, epsilon 0.8783954790723806, time 728.0, rides 133\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 144, reward -116.0, memory_length 2000, epsilon 0.8776049231412154, time 725.0, rides 120\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 145, reward -59.0, memory_length 2000, epsilon 0.8768150787103883, time 728.0, rides 119\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 146, reward -398.0, memory_length 2000, epsilon 0.876025945139549, time 736.0, rides 124\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 147, reward -252.0, memory_length 2000, epsilon 0.8752375217889234, time 736.0, rides 130\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 148, reward -169.0, memory_length 2000, epsilon 0.8744498080193134, time 732.0, rides 141\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 149, reward -121.0, memory_length 2000, epsilon 0.873662803192096, time 724.0, rides 125\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 150, reward 96.0, memory_length 2000, epsilon 0.8728765066692231, time 731.0, rides 122\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 151, reward -97.0, memory_length 2000, epsilon 0.8720909178132208, time 731.0, rides 128\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 152, reward -333.0, memory_length 2000, epsilon 0.8713060359871889, time 732.0, rides 136\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 153, reward -241.0, memory_length 2000, epsilon 0.8705218605548004, time 732.0, rides 143\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 154, reward 5.0, memory_length 2000, epsilon 0.869738390880301, time 731.0, rides 143\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 155, reward -120.0, memory_length 2000, epsilon 0.8689556263285088, time 725.0, rides 125\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 156, reward -387.0, memory_length 2000, epsilon 0.8681735662648131, time 722.0, rides 131\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 157, reward -123.0, memory_length 2000, epsilon 0.8673922100551748, time 725.0, rides 113\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 158, reward -96.0, memory_length 2000, epsilon 0.8666115570661251, time 722.0, rides 136\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 159, reward -359.0, memory_length 2000, epsilon 0.8658316066647657, time 724.0, rides 130\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 160, reward -276.0, memory_length 2000, epsilon 0.8650523582187674, time 728.0, rides 124\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 161, reward -568.0, memory_length 2000, epsilon 0.8642738110963705, time 728.0, rides 121\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 162, reward -142.0, memory_length 2000, epsilon 0.8634959646663837, time 739.0, rides 126\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 163, reward -113.0, memory_length 2000, epsilon 0.8627188182981839, time 732.0, rides 130\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 164, reward -186.0, memory_length 2000, epsilon 0.8619423713617155, time 726.0, rides 122\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 165, reward -240.0, memory_length 2000, epsilon 0.8611666232274899, time 733.0, rides 127\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 166, reward -350.0, memory_length 2000, epsilon 0.8603915732665852, time 727.0, rides 118\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 167, reward -460.0, memory_length 2000, epsilon 0.8596172208506453, time 725.0, rides 116\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 168, reward -242.0, memory_length 2000, epsilon 0.8588435653518797, time 722.0, rides 125\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 169, reward -306.0, memory_length 2000, epsilon 0.858070606143063, time 737.0, rides 117\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 170, reward -32.0, memory_length 2000, epsilon 0.8572983425975342, time 731.0, rides 148\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 171, reward -343.0, memory_length 2000, epsilon 0.8565267740891964, time 732.0, rides 116\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 172, reward -56.0, memory_length 2000, epsilon 0.8557558999925161, time 725.0, rides 117\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 173, reward -12.0, memory_length 2000, epsilon 0.8549857196825228, time 725.0, rides 132\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 174, reward -480.0, memory_length 2000, epsilon 0.8542162325348085, time 726.0, rides 120\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 175, reward 3.0, memory_length 2000, epsilon 0.8534474379255271, time 730.0, rides 142\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 176, reward 5.0, memory_length 2000, epsilon 0.8526793352313942, time 731.0, rides 124\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 177, reward 33.0, memory_length 2000, epsilon 0.851911923829686, time 730.0, rides 140\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 178, reward 90.0, memory_length 2000, epsilon 0.8511452030982393, time 730.0, rides 127\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 179, reward -261.0, memory_length 2000, epsilon 0.8503791724154508, time 738.0, rides 139\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 180, reward -33.0, memory_length 2000, epsilon 0.8496138311602769, time 727.0, rides 127\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 181, reward -108.0, memory_length 2000, epsilon 0.8488491787122326, time 723.0, rides 117\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 182, reward -302.0, memory_length 2000, epsilon 0.8480852144513916, time 731.0, rides 126\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 183, reward -275.0, memory_length 2000, epsilon 0.8473219377583854, time 723.0, rides 132\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 184, reward -214.0, memory_length 2000, epsilon 0.8465593480144028, time 732.0, rides 132\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 185, reward -242.0, memory_length 2000, epsilon 0.8457974446011898, time 726.0, rides 116\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 186, reward -299.0, memory_length 2000, epsilon 0.8450362269010487, time 725.0, rides 127\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 187, reward -80.0, memory_length 2000, epsilon 0.8442756942968378, time 731.0, rides 120\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 188, reward -138.0, memory_length 2000, epsilon 0.8435158461719706, time 729.0, rides 117\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 189, reward -56.0, memory_length 2000, epsilon 0.8427566819104159, time 730.0, rides 122\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 190, reward -2.0, memory_length 2000, epsilon 0.8419982008966965, time 736.0, rides 114\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 191, reward -310.0, memory_length 2000, epsilon 0.8412404025158895, time 729.0, rides 119\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 192, reward -272.0, memory_length 2000, epsilon 0.8404832861536252, time 729.0, rides 124\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 193, reward -242.0, memory_length 2000, epsilon 0.8397268511960869, time 732.0, rides 119\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 194, reward -160.0, memory_length 2000, epsilon 0.8389710970300104, time 728.0, rides 136\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 195, reward -197.0, memory_length 2000, epsilon 0.8382160230426834, time 725.0, rides 134\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 196, reward 50.0, memory_length 2000, epsilon 0.837461628621945, time 734.0, rides 128\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 197, reward -192.0, memory_length 2000, epsilon 0.8367079131561852, time 730.0, rides 144\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 198, reward -251.0, memory_length 2000, epsilon 0.8359548760343446, time 732.0, rides 126\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 199, reward -93.0, memory_length 2000, epsilon 0.8352025166459137, time 735.0, rides 120\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 200, reward -152.0, memory_length 2000, epsilon 0.8344508343809324, time 734.0, rides 119\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 201, reward -252.0, memory_length 2000, epsilon 0.8336998286299895, time 728.0, rides 137\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 202, reward -19.0, memory_length 2000, epsilon 0.8329494987842225, time 735.0, rides 132\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 203, reward -1.0, memory_length 2000, epsilon 0.8321998442353167, time 725.0, rides 122\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 204, reward 86.0, memory_length 2000, epsilon 0.8314508643755049, time 724.0, rides 137\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 205, reward 34.0, memory_length 2000, epsilon 0.8307025585975669, time 725.0, rides 134\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 206, reward -38.0, memory_length 2000, epsilon 0.8299549262948291, time 725.0, rides 127\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 207, reward 27.0, memory_length 2000, epsilon 0.8292079668611638, time 737.0, rides 128\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 208, reward -252.0, memory_length 2000, epsilon 0.8284616796909887, time 735.0, rides 127\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 209, reward -437.0, memory_length 2000, epsilon 0.8277160641792668, time 728.0, rides 120\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 210, reward -15.0, memory_length 2000, epsilon 0.8269711197215055, time 727.0, rides 134\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 211, reward 89.0, memory_length 2000, epsilon 0.8262268457137562, time 725.0, rides 123\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 212, reward -148.0, memory_length 2000, epsilon 0.8254832415526138, time 725.0, rides 131\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 213, reward -271.0, memory_length 2000, epsilon 0.8247403066352164, time 730.0, rides 123\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 214, reward -193.0, memory_length 2000, epsilon 0.8239980403592446, time 725.0, rides 135\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 215, reward -178.0, memory_length 2000, epsilon 0.8232564421229213, time 732.0, rides 115\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 216, reward -296.0, memory_length 2000, epsilon 0.8225155113250107, time 731.0, rides 135\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 217, reward -434.0, memory_length 2000, epsilon 0.8217752473648181, time 727.0, rides 141\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 218, reward -169.0, memory_length 2000, epsilon 0.8210356496421898, time 727.0, rides 131\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 219, reward -213.0, memory_length 2000, epsilon 0.8202967175575118, time 721.0, rides 134\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 220, reward -220.0, memory_length 2000, epsilon 0.81955845051171, time 738.0, rides 126\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 221, reward -78.0, memory_length 2000, epsilon 0.8188208479062494, time 731.0, rides 132\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 222, reward -213.0, memory_length 2000, epsilon 0.8180839091431338, time 724.0, rides 132\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 223, reward -226.0, memory_length 2000, epsilon 0.8173476336249049, time 727.0, rides 118\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 224, reward -59.0, memory_length 2000, epsilon 0.8166120207546425, time 733.0, rides 142\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 225, reward -167.0, memory_length 2000, epsilon 0.8158770699359633, time 734.0, rides 123\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 226, reward 83.0, memory_length 2000, epsilon 0.8151427805730209, time 723.0, rides 131\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 227, reward -38.0, memory_length 2000, epsilon 0.8144091520705052, time 735.0, rides 128\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 228, reward -200.0, memory_length 2000, epsilon 0.8136761838336418, time 726.0, rides 113\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 229, reward 29.0, memory_length 2000, epsilon 0.8129438752681916, time 722.0, rides 123\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 230, reward -148.0, memory_length 2000, epsilon 0.8122122257804502, time 726.0, rides 127\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 231, reward -111.0, memory_length 2000, epsilon 0.8114812347772478, time 732.0, rides 133\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 232, reward -210.0, memory_length 2000, epsilon 0.8107509016659482, time 733.0, rides 136\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 233, reward -125.0, memory_length 2000, epsilon 0.8100212258544488, time 732.0, rides 130\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 234, reward -228.0, memory_length 2000, epsilon 0.8092922067511797, time 727.0, rides 142\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 235, reward -248.0, memory_length 2000, epsilon 0.8085638437651037, time 724.0, rides 123\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 236, reward -289.0, memory_length 2000, epsilon 0.8078361363057152, time 725.0, rides 126\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 237, reward 104.0, memory_length 2000, epsilon 0.80710908378304, time 728.0, rides 119\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 238, reward -172.0, memory_length 2000, epsilon 0.8063826856076353, time 734.0, rides 125\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 239, reward -103.0, memory_length 2000, epsilon 0.8056569411905884, time 728.0, rides 123\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 240, reward 80.0, memory_length 2000, epsilon 0.8049318499435169, time 736.0, rides 119\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 241, reward -4.0, memory_length 2000, epsilon 0.8042074112785677, time 729.0, rides 122\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 242, reward -119.0, memory_length 2000, epsilon 0.8034836246084169, time 726.0, rides 127\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 243, reward -239.0, memory_length 2000, epsilon 0.8027604893462693, time 727.0, rides 129\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 244, reward -197.0, memory_length 2000, epsilon 0.8020380049058576, time 730.0, rides 139\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 245, reward -21.0, memory_length 2000, epsilon 0.8013161707014423, time 731.0, rides 122\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 246, reward 0.0, memory_length 2000, epsilon 0.800594986147811, time 728.0, rides 128\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 247, reward -374.0, memory_length 2000, epsilon 0.799874450660278, time 732.0, rides 140\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 248, reward 39.0, memory_length 2000, epsilon 0.7991545636546837, time 730.0, rides 123\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 249, reward -93.0, memory_length 2000, epsilon 0.7984353245473945, time 730.0, rides 134\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 250, reward -50.0, memory_length 2000, epsilon 0.7977167327553019, time 732.0, rides 121\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 251, reward 30.0, memory_length 2000, epsilon 0.7969987876958221, time 726.0, rides 115\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 252, reward -245.0, memory_length 2000, epsilon 0.7962814887868959, time 731.0, rides 125\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 253, reward -64.0, memory_length 2000, epsilon 0.7955648354469876, time 728.0, rides 122\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 254, reward -342.0, memory_length 2000, epsilon 0.7948488270950853, time 728.0, rides 133\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 255, reward -41.0, memory_length 2000, epsilon 0.7941334631506998, time 728.0, rides 124\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 256, reward -102.0, memory_length 2000, epsilon 0.7934187430338642, time 733.0, rides 131\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 257, reward -185.0, memory_length 2000, epsilon 0.7927046661651337, time 726.0, rides 133\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 258, reward -181.0, memory_length 2000, epsilon 0.7919912319655851, time 727.0, rides 122\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 259, reward 115.0, memory_length 2000, epsilon 0.791278439856816, time 724.0, rides 129\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 260, reward -126.0, memory_length 2000, epsilon 0.7905662892609449, time 736.0, rides 130\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 261, reward -274.0, memory_length 2000, epsilon 0.78985477960061, time 724.0, rides 127\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 262, reward -176.0, memory_length 2000, epsilon 0.7891439102989695, time 735.0, rides 139\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 263, reward -113.0, memory_length 2000, epsilon 0.7884336807797003, time 729.0, rides 128\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 264, reward -156.0, memory_length 2000, epsilon 0.7877240904669985, time 730.0, rides 125\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 265, reward -44.0, memory_length 2000, epsilon 0.7870151387855783, time 731.0, rides 127\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 266, reward -28.0, memory_length 2000, epsilon 0.7863068251606713, time 728.0, rides 116\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 267, reward -88.0, memory_length 2000, epsilon 0.7855991490180266, time 727.0, rides 129\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 268, reward -35.0, memory_length 2000, epsilon 0.7848921097839104, time 725.0, rides 136\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 269, reward 27.0, memory_length 2000, epsilon 0.7841857068851049, time 728.0, rides 125\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 270, reward -463.0, memory_length 2000, epsilon 0.7834799397489083, time 733.0, rides 125\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 271, reward -222.0, memory_length 2000, epsilon 0.7827748078031342, time 734.0, rides 118\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 272, reward -124.0, memory_length 2000, epsilon 0.7820703104761114, time 723.0, rides 111\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 273, reward 162.0, memory_length 2000, epsilon 0.7813664471966829, time 735.0, rides 129\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 274, reward -56.0, memory_length 2000, epsilon 0.7806632173942059, time 729.0, rides 115\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 275, reward 181.0, memory_length 2000, epsilon 0.7799606204985511, time 734.0, rides 117\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 276, reward 15.0, memory_length 2000, epsilon 0.7792586559401024, time 726.0, rides 128\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 277, reward -260.0, memory_length 2000, epsilon 0.7785573231497562, time 733.0, rides 123\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 278, reward -85.0, memory_length 2000, epsilon 0.7778566215589214, time 740.0, rides 139\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 279, reward -329.0, memory_length 2000, epsilon 0.7771565505995184, time 728.0, rides 116\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 280, reward 118.0, memory_length 2000, epsilon 0.7764571097039789, time 732.0, rides 126\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 281, reward -328.0, memory_length 2000, epsilon 0.7757582983052452, time 734.0, rides 133\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 282, reward -217.0, memory_length 2000, epsilon 0.7750601158367705, time 723.0, rides 129\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 283, reward -279.0, memory_length 2000, epsilon 0.7743625617325174, time 730.0, rides 118\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 284, reward -340.0, memory_length 2000, epsilon 0.7736656354269581, time 737.0, rides 131\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 285, reward -156.0, memory_length 2000, epsilon 0.7729693363550738, time 735.0, rides 123\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 286, reward -8.0, memory_length 2000, epsilon 0.7722736639523542, time 729.0, rides 122\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 287, reward -24.0, memory_length 2000, epsilon 0.7715786176547971, time 725.0, rides 118\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 288, reward 42.0, memory_length 2000, epsilon 0.7708841968989077, time 738.0, rides 130\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 289, reward -5.0, memory_length 2000, epsilon 0.7701904011216987, time 733.0, rides 123\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 290, reward 130.0, memory_length 2000, epsilon 0.7694972297606891, time 731.0, rides 112\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 291, reward -4.0, memory_length 2000, epsilon 0.7688046822539045, time 734.0, rides 127\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 292, reward 27.0, memory_length 2000, epsilon 0.768112758039876, time 727.0, rides 138\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 293, reward -61.0, memory_length 2000, epsilon 0.76742145655764, time 732.0, rides 117\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 294, reward -216.0, memory_length 2000, epsilon 0.7667307772467382, time 724.0, rides 140\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 295, reward -68.0, memory_length 2000, epsilon 0.7660407195472161, time 725.0, rides 120\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 296, reward -33.0, memory_length 2000, epsilon 0.7653512828996236, time 728.0, rides 138\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 297, reward -129.0, memory_length 2000, epsilon 0.7646624667450139, time 738.0, rides 125\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 298, reward -362.0, memory_length 2000, epsilon 0.7639742705249434, time 733.0, rides 137\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 299, reward 71.0, memory_length 2000, epsilon 0.763286693681471, time 728.0, rides 136\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 300, reward -228.0, memory_length 2000, epsilon 0.7625997356571577, time 725.0, rides 126\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 301, reward -189.0, memory_length 2000, epsilon 0.7619133958950662, time 730.0, rides 127\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 302, reward -274.0, memory_length 2000, epsilon 0.7612276738387607, time 736.0, rides 131\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 303, reward -137.0, memory_length 2000, epsilon 0.7605425689323058, time 722.0, rides 131\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 304, reward -159.0, memory_length 2000, epsilon 0.7598580806202667, time 727.0, rides 113\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 305, reward -372.0, memory_length 2000, epsilon 0.7591742083477084, time 729.0, rides 123\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 306, reward -175.0, memory_length 2000, epsilon 0.7584909515601955, time 725.0, rides 116\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 307, reward -69.0, memory_length 2000, epsilon 0.7578083097037913, time 726.0, rides 129\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 308, reward -288.0, memory_length 2000, epsilon 0.7571262822250578, time 733.0, rides 119\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 309, reward -426.0, memory_length 2000, epsilon 0.7564448685710553, time 727.0, rides 139\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 310, reward -187.0, memory_length 2000, epsilon 0.7557640681893414, time 736.0, rides 119\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 311, reward -140.0, memory_length 2000, epsilon 0.7550838805279709, time 736.0, rides 133\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 312, reward -73.0, memory_length 2000, epsilon 0.7544043050354957, time 723.0, rides 134\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 313, reward -54.0, memory_length 2000, epsilon 0.7537253411609638, time 720.0, rides 125\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 314, reward -263.0, memory_length 2000, epsilon 0.7530469883539189, time 724.0, rides 133\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 315, reward 138.0, memory_length 2000, epsilon 0.7523692460644004, time 728.0, rides 134\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 316, reward -338.0, memory_length 2000, epsilon 0.7516921137429424, time 735.0, rides 133\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 317, reward 69.0, memory_length 2000, epsilon 0.7510155908405738, time 734.0, rides 121\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 318, reward 63.0, memory_length 2000, epsilon 0.7503396768088173, time 733.0, rides 121\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 319, reward -285.0, memory_length 2000, epsilon 0.7496643710996893, time 730.0, rides 130\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 320, reward -81.0, memory_length 2000, epsilon 0.7489896731656995, time 736.0, rides 126\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 321, reward 134.0, memory_length 2000, epsilon 0.7483155824598504, time 733.0, rides 137\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 322, reward -73.0, memory_length 2000, epsilon 0.7476420984356366, time 732.0, rides 124\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 323, reward -14.0, memory_length 2000, epsilon 0.7469692205470445, time 725.0, rides 122\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 324, reward -79.0, memory_length 2000, epsilon 0.7462969482485522, time 724.0, rides 137\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 325, reward 49.0, memory_length 2000, epsilon 0.7456252809951285, time 737.0, rides 130\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 326, reward -171.0, memory_length 2000, epsilon 0.7449542182422328, time 725.0, rides 138\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 327, reward -229.0, memory_length 2000, epsilon 0.7442837594458148, time 730.0, rides 129\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 328, reward -363.0, memory_length 2000, epsilon 0.7436139040623135, time 736.0, rides 130\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 329, reward 2.0, memory_length 2000, epsilon 0.7429446515486574, time 726.0, rides 123\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 330, reward -22.0, memory_length 2000, epsilon 0.7422760013622636, time 741.0, rides 132\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 331, reward -207.0, memory_length 2000, epsilon 0.7416079529610375, time 729.0, rides 129\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 332, reward 117.0, memory_length 2000, epsilon 0.7409405058033726, time 731.0, rides 137\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 333, reward -232.0, memory_length 2000, epsilon 0.7402736593481495, time 733.0, rides 122\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 334, reward 101.0, memory_length 2000, epsilon 0.7396074130547361, time 720.0, rides 140\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 335, reward -327.0, memory_length 2000, epsilon 0.7389417663829868, time 730.0, rides 138\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 336, reward -156.0, memory_length 2000, epsilon 0.7382767187932421, time 726.0, rides 143\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 337, reward -101.0, memory_length 2000, epsilon 0.7376122697463282, time 733.0, rides 130\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 338, reward -139.0, memory_length 2000, epsilon 0.7369484187035565, time 725.0, rides 123\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 339, reward -119.0, memory_length 2000, epsilon 0.7362851651267234, time 726.0, rides 131\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 340, reward -311.0, memory_length 2000, epsilon 0.7356225084781093, time 726.0, rides 140\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 341, reward 157.0, memory_length 2000, epsilon 0.734960448220479, time 724.0, rides 150\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 342, reward -17.0, memory_length 2000, epsilon 0.7342989838170806, time 723.0, rides 132\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 343, reward 21.0, memory_length 2000, epsilon 0.7336381147316452, time 735.0, rides 147\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 344, reward -13.0, memory_length 2000, epsilon 0.7329778404283868, time 723.0, rides 123\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 345, reward -57.0, memory_length 2000, epsilon 0.7323181603720013, time 735.0, rides 125\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 346, reward -517.0, memory_length 2000, epsilon 0.7316590740276665, time 724.0, rides 125\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 347, reward -55.0, memory_length 2000, epsilon 0.7310005808610416, time 730.0, rides 120\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 348, reward -109.0, memory_length 2000, epsilon 0.7303426803382667, time 727.0, rides 123\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 349, reward -210.0, memory_length 2000, epsilon 0.7296853719259622, time 729.0, rides 138\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 350, reward 45.0, memory_length 2000, epsilon 0.7290286550912288, time 732.0, rides 125\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 351, reward -120.0, memory_length 2000, epsilon 0.7283725293016468, time 728.0, rides 124\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 352, reward -70.0, memory_length 2000, epsilon 0.7277169940252752, time 736.0, rides 140\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 353, reward -156.0, memory_length 2000, epsilon 0.7270620487306525, time 728.0, rides 141\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 354, reward -154.0, memory_length 2000, epsilon 0.7264076928867949, time 727.0, rides 142\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 355, reward 123.0, memory_length 2000, epsilon 0.7257539259631968, time 728.0, rides 126\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 356, reward -57.0, memory_length 2000, epsilon 0.7251007474298299, time 733.0, rides 140\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 357, reward -203.0, memory_length 2000, epsilon 0.724448156757143, time 733.0, rides 127\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 358, reward -458.0, memory_length 2000, epsilon 0.7237961534160616, time 725.0, rides 127\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 359, reward 18.0, memory_length 2000, epsilon 0.7231447368779872, time 733.0, rides 127\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 360, reward -9.0, memory_length 2000, epsilon 0.722493906614797, time 732.0, rides 116\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 361, reward -237.0, memory_length 2000, epsilon 0.7218436620988437, time 730.0, rides 116\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 362, reward -78.0, memory_length 2000, epsilon 0.7211940028029546, time 731.0, rides 135\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 363, reward -3.0, memory_length 2000, epsilon 0.720544928200432, time 726.0, rides 120\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 364, reward 71.0, memory_length 2000, epsilon 0.7198964377650516, time 740.0, rides 123\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 365, reward -179.0, memory_length 2000, epsilon 0.7192485309710631, time 733.0, rides 132\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 366, reward 12.0, memory_length 2000, epsilon 0.7186012072931891, time 724.0, rides 131\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 367, reward 38.0, memory_length 2000, epsilon 0.7179544662066252, time 728.0, rides 132\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 368, reward -237.0, memory_length 2000, epsilon 0.7173083071870392, time 728.0, rides 124\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 369, reward -61.0, memory_length 2000, epsilon 0.7166627297105709, time 739.0, rides 126\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 370, reward -103.0, memory_length 2000, epsilon 0.7160177332538313, time 726.0, rides 120\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 371, reward -75.0, memory_length 2000, epsilon 0.7153733172939029, time 738.0, rides 131\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 372, reward 22.0, memory_length 2000, epsilon 0.7147294813083384, time 734.0, rides 125\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 373, reward 173.0, memory_length 2000, epsilon 0.7140862247751608, time 726.0, rides 119\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 374, reward -18.0, memory_length 2000, epsilon 0.7134435471728632, time 726.0, rides 123\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 375, reward 147.0, memory_length 2000, epsilon 0.7128014479804076, time 726.0, rides 123\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 376, reward 3.0, memory_length 2000, epsilon 0.7121599266772252, time 729.0, rides 135\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 377, reward 68.0, memory_length 2000, epsilon 0.7115189827432157, time 727.0, rides 123\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 378, reward 77.0, memory_length 2000, epsilon 0.7108786156587468, time 729.0, rides 120\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 379, reward -100.0, memory_length 2000, epsilon 0.7102388249046538, time 737.0, rides 121\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 380, reward -74.0, memory_length 2000, epsilon 0.7095996099622397, time 725.0, rides 123\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 381, reward 112.0, memory_length 2000, epsilon 0.7089609703132737, time 731.0, rides 132\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 382, reward 84.0, memory_length 2000, epsilon 0.7083229054399917, time 725.0, rides 116\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 383, reward -68.0, memory_length 2000, epsilon 0.7076854148250956, time 724.0, rides 123\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 384, reward -103.0, memory_length 2000, epsilon 0.7070484979517531, time 738.0, rides 139\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 385, reward -38.0, memory_length 2000, epsilon 0.7064121543035965, time 731.0, rides 136\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 386, reward -184.0, memory_length 2000, epsilon 0.7057763833647233, time 733.0, rides 115\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 387, reward 296.0, memory_length 2000, epsilon 0.705141184619695, time 723.0, rides 144\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 388, reward -136.0, memory_length 2000, epsilon 0.7045065575535373, time 733.0, rides 130\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 389, reward 98.0, memory_length 2000, epsilon 0.7038725016517391, time 721.0, rides 135\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 390, reward -91.0, memory_length 2000, epsilon 0.7032390164002525, time 729.0, rides 119\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 391, reward 96.0, memory_length 2000, epsilon 0.7026061012854923, time 736.0, rides 136\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 392, reward -146.0, memory_length 2000, epsilon 0.7019737557943353, time 734.0, rides 131\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 393, reward -209.0, memory_length 2000, epsilon 0.7013419794141204, time 730.0, rides 117\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 394, reward 106.0, memory_length 2000, epsilon 0.7007107716326476, time 727.0, rides 125\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 395, reward 44.0, memory_length 2000, epsilon 0.7000801319381782, time 728.0, rides 139\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 396, reward -183.0, memory_length 2000, epsilon 0.6994500598194339, time 728.0, rides 120\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 397, reward 216.0, memory_length 2000, epsilon 0.6988205547655963, time 731.0, rides 112\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 398, reward -20.0, memory_length 2000, epsilon 0.6981916162663073, time 729.0, rides 129\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 399, reward 215.0, memory_length 2000, epsilon 0.6975632438116677, time 733.0, rides 117\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 400, reward 71.0, memory_length 2000, epsilon 0.6969354368922371, time 723.0, rides 119\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 401, reward -163.0, memory_length 2000, epsilon 0.6963081949990341, time 731.0, rides 136\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 402, reward 141.0, memory_length 2000, epsilon 0.6956815176235349, time 727.0, rides 133\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 403, reward -141.0, memory_length 2000, epsilon 0.6950554042576738, time 734.0, rides 127\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 404, reward -103.0, memory_length 2000, epsilon 0.6944298543938419, time 726.0, rides 121\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 405, reward 64.0, memory_length 2000, epsilon 0.6938048675248873, time 726.0, rides 129\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 406, reward -233.0, memory_length 2000, epsilon 0.693180443144115, time 733.0, rides 137\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 407, reward -209.0, memory_length 2000, epsilon 0.6925565807452853, time 734.0, rides 126\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 408, reward -121.0, memory_length 2000, epsilon 0.6919332798226145, time 730.0, rides 113\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 409, reward 153.0, memory_length 2000, epsilon 0.6913105398707742, time 729.0, rides 115\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 410, reward -151.0, memory_length 2000, epsilon 0.6906883603848905, time 723.0, rides 113\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 411, reward 10.0, memory_length 2000, epsilon 0.6900667408605441, time 730.0, rides 130\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 412, reward -8.0, memory_length 2000, epsilon 0.6894456807937696, time 733.0, rides 119\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 413, reward 205.0, memory_length 2000, epsilon 0.6888251796810552, time 723.0, rides 127\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 414, reward -185.0, memory_length 2000, epsilon 0.6882052370193422, time 733.0, rides 119\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 415, reward 63.0, memory_length 2000, epsilon 0.6875858523060248, time 732.0, rides 122\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 416, reward -32.0, memory_length 2000, epsilon 0.6869670250389494, time 733.0, rides 125\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 417, reward -72.0, memory_length 2000, epsilon 0.6863487547164143, time 723.0, rides 126\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 418, reward 141.0, memory_length 2000, epsilon 0.6857310408371695, time 724.0, rides 126\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 419, reward -131.0, memory_length 2000, epsilon 0.6851138829004161, time 730.0, rides 121\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 420, reward 87.0, memory_length 2000, epsilon 0.6844972804058057, time 725.0, rides 127\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 421, reward 41.0, memory_length 2000, epsilon 0.6838812328534405, time 732.0, rides 148\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 422, reward -2.0, memory_length 2000, epsilon 0.6832657397438724, time 733.0, rides 118\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 423, reward 15.0, memory_length 2000, epsilon 0.6826508005781029, time 726.0, rides 133\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 424, reward -52.0, memory_length 2000, epsilon 0.6820364148575826, time 725.0, rides 112\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 425, reward 101.0, memory_length 2000, epsilon 0.6814225820842108, time 729.0, rides 126\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 426, reward 59.0, memory_length 2000, epsilon 0.680809301760335, time 728.0, rides 127\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 427, reward 167.0, memory_length 2000, epsilon 0.6801965733887507, time 730.0, rides 128\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 428, reward 5.0, memory_length 2000, epsilon 0.6795843964727009, time 727.0, rides 129\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 429, reward -185.0, memory_length 2000, epsilon 0.6789727705158755, time 731.0, rides 128\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 430, reward 192.0, memory_length 2000, epsilon 0.6783616950224112, time 740.0, rides 122\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 431, reward 1.0, memory_length 2000, epsilon 0.677751169496891, time 723.0, rides 139\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 432, reward -94.0, memory_length 2000, epsilon 0.6771411934443438, time 725.0, rides 122\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 433, reward -27.0, memory_length 2000, epsilon 0.6765317663702438, time 722.0, rides 132\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 434, reward -169.0, memory_length 2000, epsilon 0.6759228877805106, time 722.0, rides 129\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 435, reward 127.0, memory_length 2000, epsilon 0.6753145571815081, time 728.0, rides 122\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 436, reward -188.0, memory_length 2000, epsilon 0.6747067740800448, time 730.0, rides 114\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 437, reward -43.0, memory_length 2000, epsilon 0.6740995379833727, time 729.0, rides 132\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 438, reward -55.0, memory_length 2000, epsilon 0.6734928483991877, time 723.0, rides 125\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 439, reward -134.0, memory_length 2000, epsilon 0.6728867048356284, time 736.0, rides 136\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 440, reward -82.0, memory_length 2000, epsilon 0.6722811068012763, time 742.0, rides 130\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 441, reward -3.0, memory_length 2000, epsilon 0.6716760538051552, time 730.0, rides 123\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 442, reward 119.0, memory_length 2000, epsilon 0.6710715453567305, time 732.0, rides 136\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 443, reward -6.0, memory_length 2000, epsilon 0.6704675809659094, time 725.0, rides 129\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 444, reward 276.0, memory_length 2000, epsilon 0.6698641601430401, time 737.0, rides 121\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 445, reward 5.0, memory_length 2000, epsilon 0.6692612823989114, time 725.0, rides 118\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 446, reward 160.0, memory_length 2000, epsilon 0.6686589472447524, time 731.0, rides 125\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 447, reward 96.0, memory_length 2000, epsilon 0.6680571541922321, time 733.0, rides 126\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 448, reward -121.0, memory_length 2000, epsilon 0.6674559027534591, time 742.0, rides 137\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 449, reward 24.0, memory_length 2000, epsilon 0.666855192440981, time 733.0, rides 119\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 450, reward 25.0, memory_length 2000, epsilon 0.6662550227677841, time 726.0, rides 117\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 451, reward 206.0, memory_length 2000, epsilon 0.6656553932472932, time 734.0, rides 127\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 452, reward 389.0, memory_length 2000, epsilon 0.6650563033933706, time 727.0, rides 138\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 453, reward -164.0, memory_length 2000, epsilon 0.6644577527203166, time 737.0, rides 134\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 454, reward 128.0, memory_length 2000, epsilon 0.6638597407428684, time 728.0, rides 128\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 455, reward 221.0, memory_length 2000, epsilon 0.6632622669761997, time 727.0, rides 138\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 456, reward 5.0, memory_length 2000, epsilon 0.6626653309359212, time 729.0, rides 129\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 457, reward 66.0, memory_length 2000, epsilon 0.6620689321380788, time 731.0, rides 113\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 458, reward 37.0, memory_length 2000, epsilon 0.6614730700991546, time 725.0, rides 122\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 459, reward -31.0, memory_length 2000, epsilon 0.6608777443360653, time 733.0, rides 137\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 460, reward -63.0, memory_length 2000, epsilon 0.6602829543661628, time 727.0, rides 120\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 461, reward -95.0, memory_length 2000, epsilon 0.6596886997072332, time 730.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 462, reward 15.0, memory_length 2000, epsilon 0.6590949798774967, time 724.0, rides 121\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 463, reward -110.0, memory_length 2000, epsilon 0.6585017943956069, time 725.0, rides 126\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 464, reward 88.0, memory_length 2000, epsilon 0.6579091427806508, time 735.0, rides 118\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 465, reward 84.0, memory_length 2000, epsilon 0.6573170245521482, time 729.0, rides 113\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 466, reward -100.0, memory_length 2000, epsilon 0.6567254392300513, time 727.0, rides 118\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 467, reward 111.0, memory_length 2000, epsilon 0.6561343863347443, time 727.0, rides 117\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 468, reward -134.0, memory_length 2000, epsilon 0.655543865387043, time 728.0, rides 122\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 469, reward -369.0, memory_length 2000, epsilon 0.6549538759081946, time 726.0, rides 127\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 470, reward -154.0, memory_length 2000, epsilon 0.6543644174198773, time 729.0, rides 130\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 471, reward 127.0, memory_length 2000, epsilon 0.6537754894441994, time 733.0, rides 130\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 472, reward 159.0, memory_length 2000, epsilon 0.6531870915036996, time 724.0, rides 131\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 473, reward -323.0, memory_length 2000, epsilon 0.6525992231213462, time 735.0, rides 125\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 474, reward 4.0, memory_length 2000, epsilon 0.652011883820537, time 728.0, rides 133\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 475, reward -215.0, memory_length 2000, epsilon 0.6514250731250985, time 728.0, rides 127\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 476, reward 296.0, memory_length 2000, epsilon 0.6508387905592858, time 727.0, rides 130\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 477, reward 293.0, memory_length 2000, epsilon 0.6502530356477825, time 731.0, rides 132\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 478, reward -79.0, memory_length 2000, epsilon 0.6496678079156994, time 729.0, rides 132\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 479, reward 186.0, memory_length 2000, epsilon 0.6490831068885753, time 728.0, rides 118\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 480, reward -35.0, memory_length 2000, epsilon 0.6484989320923755, time 725.0, rides 125\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 481, reward -145.0, memory_length 2000, epsilon 0.6479152830534923, time 724.0, rides 128\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 482, reward 201.0, memory_length 2000, epsilon 0.6473321592987442, time 731.0, rides 129\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 483, reward 122.0, memory_length 2000, epsilon 0.6467495603553753, time 730.0, rides 123\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 484, reward 202.0, memory_length 2000, epsilon 0.6461674857510555, time 729.0, rides 129\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 485, reward -137.0, memory_length 2000, epsilon 0.6455859350138796, time 734.0, rides 123\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 486, reward 135.0, memory_length 2000, epsilon 0.6450049076723671, time 721.0, rides 134\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 487, reward 249.0, memory_length 2000, epsilon 0.6444244032554619, time 728.0, rides 128\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 488, reward 173.0, memory_length 2000, epsilon 0.6438444212925319, time 732.0, rides 138\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 489, reward 53.0, memory_length 2000, epsilon 0.6432649613133686, time 722.0, rides 120\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 490, reward -59.0, memory_length 2000, epsilon 0.6426860228481865, time 736.0, rides 125\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 491, reward 115.0, memory_length 2000, epsilon 0.6421076054276231, time 730.0, rides 111\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 492, reward 135.0, memory_length 2000, epsilon 0.6415297085827383, time 732.0, rides 139\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 493, reward 107.0, memory_length 2000, epsilon 0.6409523318450138, time 741.0, rides 130\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 494, reward -168.0, memory_length 2000, epsilon 0.6403754747463533, time 730.0, rides 128\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 495, reward 230.0, memory_length 2000, epsilon 0.6397991368190815, time 737.0, rides 144\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 496, reward -189.0, memory_length 2000, epsilon 0.6392233175959443, time 727.0, rides 121\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 497, reward 71.0, memory_length 2000, epsilon 0.638648016610108, time 733.0, rides 123\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 498, reward 187.0, memory_length 2000, epsilon 0.6380732333951589, time 720.0, rides 120\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 499, reward 15.0, memory_length 2000, epsilon 0.6374989674851033, time 725.0, rides 122\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 500, reward 128.0, memory_length 2000, epsilon 0.6369252184143667, time 729.0, rides 140\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 501, reward 275.0, memory_length 2000, epsilon 0.6363519857177937, time 733.0, rides 122\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 502, reward -24.0, memory_length 2000, epsilon 0.6357792689306477, time 731.0, rides 126\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 503, reward 103.0, memory_length 2000, epsilon 0.6352070675886101, time 723.0, rides 134\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 504, reward -109.0, memory_length 2000, epsilon 0.6346353812277804, time 731.0, rides 116\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 505, reward 276.0, memory_length 2000, epsilon 0.6340642093846754, time 727.0, rides 123\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 506, reward -19.0, memory_length 2000, epsilon 0.6334935515962292, time 733.0, rides 120\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 507, reward 61.0, memory_length 2000, epsilon 0.6329234073997926, time 736.0, rides 120\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 508, reward 332.0, memory_length 2000, epsilon 0.6323537763331327, time 724.0, rides 129\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 509, reward 64.0, memory_length 2000, epsilon 0.631784657934433, time 729.0, rides 110\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 510, reward 155.0, memory_length 2000, epsilon 0.6312160517422919, time 731.0, rides 123\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 511, reward 121.0, memory_length 2000, epsilon 0.6306479572957239, time 725.0, rides 126\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 512, reward 292.0, memory_length 2000, epsilon 0.6300803741341577, time 737.0, rides 123\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 513, reward 217.0, memory_length 2000, epsilon 0.629513301797437, time 730.0, rides 141\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 514, reward 369.0, memory_length 2000, epsilon 0.6289467398258193, time 730.0, rides 131\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 515, reward 169.0, memory_length 2000, epsilon 0.628380687759976, time 729.0, rides 130\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 516, reward 506.0, memory_length 2000, epsilon 0.627815145140992, time 726.0, rides 127\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 517, reward -25.0, memory_length 2000, epsilon 0.6272501115103651, time 724.0, rides 127\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 518, reward 273.0, memory_length 2000, epsilon 0.6266855864100058, time 722.0, rides 132\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 519, reward 56.0, memory_length 2000, epsilon 0.6261215693822368, time 725.0, rides 132\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 520, reward -123.0, memory_length 2000, epsilon 0.6255580599697929, time 730.0, rides 127\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 521, reward 127.0, memory_length 2000, epsilon 0.6249950577158201, time 725.0, rides 136\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 522, reward -36.0, memory_length 2000, epsilon 0.6244325621638759, time 730.0, rides 121\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 523, reward -54.0, memory_length 2000, epsilon 0.6238705728579284, time 725.0, rides 125\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 524, reward -171.0, memory_length 2000, epsilon 0.6233090893423562, time 736.0, rides 127\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 525, reward 111.0, memory_length 2000, epsilon 0.6227481111619481, time 729.0, rides 118\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 526, reward -102.0, memory_length 2000, epsilon 0.6221876378619023, time 728.0, rides 118\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 527, reward -25.0, memory_length 2000, epsilon 0.6216276689878266, time 728.0, rides 123\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 528, reward 89.0, memory_length 2000, epsilon 0.6210682040857376, time 732.0, rides 138\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 529, reward -44.0, memory_length 2000, epsilon 0.6205092427020604, time 721.0, rides 116\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 530, reward 272.0, memory_length 2000, epsilon 0.6199507843836286, time 727.0, rides 120\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 531, reward 336.0, memory_length 2000, epsilon 0.6193928286776833, time 736.0, rides 128\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 532, reward 10.0, memory_length 2000, epsilon 0.6188353751318734, time 744.0, rides 131\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 533, reward -104.0, memory_length 2000, epsilon 0.6182784232942546, time 727.0, rides 127\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 534, reward -55.0, memory_length 2000, epsilon 0.6177219727132898, time 728.0, rides 106\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 535, reward 135.0, memory_length 2000, epsilon 0.6171660229378478, time 729.0, rides 145\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 536, reward 166.0, memory_length 2000, epsilon 0.6166105735172037, time 725.0, rides 137\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 537, reward -161.0, memory_length 2000, epsilon 0.6160556240010382, time 725.0, rides 103\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 538, reward 121.0, memory_length 2000, epsilon 0.6155011739394373, time 729.0, rides 137\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 539, reward -213.0, memory_length 2000, epsilon 0.6149472228828917, time 732.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 540, reward 323.0, memory_length 2000, epsilon 0.6143937703822971, time 729.0, rides 135\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 541, reward 184.0, memory_length 2000, epsilon 0.613840815988953, time 724.0, rides 124\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 542, reward -19.0, memory_length 2000, epsilon 0.6132883592545629, time 738.0, rides 131\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 543, reward 69.0, memory_length 2000, epsilon 0.6127363997312338, time 733.0, rides 118\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 544, reward 135.0, memory_length 2000, epsilon 0.6121849369714757, time 731.0, rides 115\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 545, reward 123.0, memory_length 2000, epsilon 0.6116339705282013, time 728.0, rides 141\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 546, reward 61.0, memory_length 2000, epsilon 0.611083499954726, time 739.0, rides 121\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 547, reward 189.0, memory_length 2000, epsilon 0.6105335248047667, time 734.0, rides 131\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 548, reward 96.0, memory_length 2000, epsilon 0.6099840446324425, time 731.0, rides 130\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 549, reward -2.0, memory_length 2000, epsilon 0.6094350589922732, time 730.0, rides 126\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 550, reward 166.0, memory_length 2000, epsilon 0.6088865674391802, time 729.0, rides 124\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 551, reward 186.0, memory_length 2000, epsilon 0.608338569528485, time 729.0, rides 117\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 552, reward 159.0, memory_length 2000, epsilon 0.6077910648159093, time 735.0, rides 130\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 553, reward 316.0, memory_length 2000, epsilon 0.607244052857575, time 737.0, rides 121\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 554, reward 189.0, memory_length 2000, epsilon 0.6066975332100032, time 730.0, rides 120\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 555, reward 239.0, memory_length 2000, epsilon 0.6061515054301142, time 734.0, rides 132\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 556, reward -58.0, memory_length 2000, epsilon 0.6056059690752271, time 729.0, rides 123\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 557, reward -122.0, memory_length 2000, epsilon 0.6050609237030594, time 730.0, rides 127\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 558, reward -6.0, memory_length 2000, epsilon 0.6045163688717267, time 734.0, rides 136\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 559, reward -11.0, memory_length 2000, epsilon 0.6039723041397421, time 735.0, rides 117\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 560, reward -32.0, memory_length 2000, epsilon 0.6034287290660163, time 734.0, rides 138\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 561, reward 152.0, memory_length 2000, epsilon 0.6028856432098568, time 730.0, rides 125\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 562, reward 33.0, memory_length 2000, epsilon 0.6023430461309679, time 730.0, rides 135\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 563, reward 3.0, memory_length 2000, epsilon 0.6018009373894501, time 729.0, rides 123\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 564, reward 154.0, memory_length 2000, epsilon 0.6012593165457996, time 722.0, rides 119\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 565, reward -14.0, memory_length 2000, epsilon 0.6007181831609083, time 733.0, rides 129\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 566, reward 206.0, memory_length 2000, epsilon 0.6001775367960634, time 732.0, rides 119\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 567, reward 168.0, memory_length 2000, epsilon 0.599637377012947, time 730.0, rides 120\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 568, reward 47.0, memory_length 2000, epsilon 0.5990977033736353, time 733.0, rides 124\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 569, reward 67.0, memory_length 2000, epsilon 0.598558515440599, time 724.0, rides 125\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 570, reward -28.0, memory_length 2000, epsilon 0.5980198127767025, time 721.0, rides 129\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 571, reward 172.0, memory_length 2000, epsilon 0.5974815949452035, time 734.0, rides 123\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 572, reward 49.0, memory_length 2000, epsilon 0.5969438615097528, time 725.0, rides 124\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 573, reward 17.0, memory_length 2000, epsilon 0.5964066120343939, time 728.0, rides 118\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 574, reward 208.0, memory_length 2000, epsilon 0.595869846083563, time 725.0, rides 124\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 575, reward 88.0, memory_length 2000, epsilon 0.5953335632220877, time 726.0, rides 112\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 576, reward 68.0, memory_length 2000, epsilon 0.5947977630151878, time 728.0, rides 115\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 577, reward 148.0, memory_length 2000, epsilon 0.5942624450284741, time 723.0, rides 122\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 578, reward 64.0, memory_length 2000, epsilon 0.5937276088279485, time 732.0, rides 116\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 579, reward 23.0, memory_length 2000, epsilon 0.5931932539800033, time 733.0, rides 139\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 580, reward 355.0, memory_length 2000, epsilon 0.5926593800514213, time 730.0, rides 130\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 581, reward 142.0, memory_length 2000, epsilon 0.592125986609375, time 724.0, rides 129\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 582, reward -6.0, memory_length 2000, epsilon 0.5915930732214265, time 726.0, rides 123\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 583, reward 237.0, memory_length 2000, epsilon 0.5910606394555272, time 734.0, rides 132\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 584, reward 243.0, memory_length 2000, epsilon 0.5905286848800172, time 731.0, rides 120\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 585, reward -59.0, memory_length 2000, epsilon 0.5899972090636252, time 737.0, rides 123\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 586, reward -59.0, memory_length 2000, epsilon 0.589466211575468, time 728.0, rides 116\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 587, reward 165.0, memory_length 2000, epsilon 0.58893569198505, time 737.0, rides 114\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 588, reward 253.0, memory_length 2000, epsilon 0.5884056498622635, time 734.0, rides 132\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 589, reward 163.0, memory_length 2000, epsilon 0.5878760847773875, time 725.0, rides 136\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 590, reward 281.0, memory_length 2000, epsilon 0.5873469963010879, time 729.0, rides 120\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 591, reward -54.0, memory_length 2000, epsilon 0.5868183840044169, time 734.0, rides 135\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 592, reward 66.0, memory_length 2000, epsilon 0.5862902474588129, time 727.0, rides 129\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 593, reward 108.0, memory_length 2000, epsilon 0.5857625862360999, time 728.0, rides 123\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 594, reward 53.0, memory_length 2000, epsilon 0.5852353999084874, time 736.0, rides 123\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 595, reward 268.0, memory_length 2000, epsilon 0.5847086880485698, time 734.0, rides 128\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 596, reward 245.0, memory_length 2000, epsilon 0.584182450229326, time 725.0, rides 121\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 597, reward 347.0, memory_length 2000, epsilon 0.5836566860241196, time 728.0, rides 133\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 598, reward -91.0, memory_length 2000, epsilon 0.5831313950066979, time 741.0, rides 126\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 599, reward 42.0, memory_length 2000, epsilon 0.5826065767511919, time 734.0, rides 124\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 600, reward 26.0, memory_length 2000, epsilon 0.5820822308321157, time 734.0, rides 119\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 601, reward -22.0, memory_length 2000, epsilon 0.5815583568243669, time 728.0, rides 139\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 602, reward 69.0, memory_length 2000, epsilon 0.5810349543032249, time 728.0, rides 121\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 603, reward 551.0, memory_length 2000, epsilon 0.580512022844352, time 725.0, rides 118\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 604, reward 397.0, memory_length 2000, epsilon 0.579989562023792, time 731.0, rides 131\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 605, reward -130.0, memory_length 2000, epsilon 0.5794675714179707, time 728.0, rides 128\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 606, reward 71.0, memory_length 2000, epsilon 0.5789460506036945, time 732.0, rides 121\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 607, reward -15.0, memory_length 2000, epsilon 0.5784249991581512, time 727.0, rides 131\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 608, reward 135.0, memory_length 2000, epsilon 0.5779044166589088, time 727.0, rides 127\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 609, reward -63.0, memory_length 2000, epsilon 0.5773843026839157, time 725.0, rides 130\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 610, reward -140.0, memory_length 2000, epsilon 0.5768646568115002, time 731.0, rides 125\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 611, reward 103.0, memory_length 2000, epsilon 0.5763454786203699, time 739.0, rides 136\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 612, reward 59.0, memory_length 2000, epsilon 0.5758267676896115, time 724.0, rides 121\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 613, reward -19.0, memory_length 2000, epsilon 0.5753085235986909, time 726.0, rides 133\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 614, reward -26.0, memory_length 2000, epsilon 0.574790745927452, time 734.0, rides 149\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 615, reward 94.0, memory_length 2000, epsilon 0.5742734342561173, time 726.0, rides 132\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 616, reward 295.0, memory_length 2000, epsilon 0.5737565881652869, time 733.0, rides 123\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 617, reward 325.0, memory_length 2000, epsilon 0.573240207235938, time 723.0, rides 117\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 618, reward -161.0, memory_length 2000, epsilon 0.5727242910494257, time 726.0, rides 138\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 619, reward 100.0, memory_length 2000, epsilon 0.5722088391874812, time 728.0, rides 128\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 620, reward 164.0, memory_length 2000, epsilon 0.5716938512322125, time 732.0, rides 126\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 621, reward -24.0, memory_length 2000, epsilon 0.5711793267661035, time 731.0, rides 126\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 622, reward 216.0, memory_length 2000, epsilon 0.570665265372014, time 732.0, rides 113\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 623, reward 231.0, memory_length 2000, epsilon 0.5701516666331792, time 731.0, rides 130\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 624, reward 54.0, memory_length 2000, epsilon 0.5696385301332093, time 727.0, rides 117\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 625, reward -164.0, memory_length 2000, epsilon 0.5691258554560894, time 732.0, rides 128\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 626, reward 275.0, memory_length 2000, epsilon 0.5686136421861789, time 731.0, rides 139\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 627, reward 187.0, memory_length 2000, epsilon 0.5681018899082114, time 726.0, rides 125\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 628, reward 152.0, memory_length 2000, epsilon 0.5675905982072941, time 729.0, rides 115\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 629, reward 346.0, memory_length 2000, epsilon 0.5670797666689075, time 733.0, rides 125\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 630, reward -233.0, memory_length 2000, epsilon 0.5665693948789055, time 730.0, rides 123\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 631, reward 494.0, memory_length 2000, epsilon 0.5660594824235144, time 723.0, rides 131\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 632, reward -15.0, memory_length 2000, epsilon 0.5655500288893333, time 725.0, rides 120\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 633, reward 302.0, memory_length 2000, epsilon 0.5650410338633328, time 729.0, rides 130\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 634, reward 116.0, memory_length 2000, epsilon 0.5645324969328558, time 726.0, rides 111\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 635, reward 190.0, memory_length 2000, epsilon 0.5640244176856162, time 725.0, rides 129\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 636, reward 28.0, memory_length 2000, epsilon 0.5635167957096991, time 723.0, rides 120\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 637, reward 500.0, memory_length 2000, epsilon 0.5630096305935605, time 727.0, rides 127\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 638, reward 102.0, memory_length 2000, epsilon 0.5625029219260262, time 730.0, rides 137\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 639, reward 6.0, memory_length 2000, epsilon 0.5619966692962928, time 724.0, rides 132\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 640, reward 56.0, memory_length 2000, epsilon 0.5614908722939261, time 731.0, rides 130\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 641, reward 357.0, memory_length 2000, epsilon 0.5609855305088616, time 722.0, rides 122\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 642, reward 234.0, memory_length 2000, epsilon 0.5604806435314036, time 728.0, rides 121\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 643, reward 166.0, memory_length 2000, epsilon 0.5599762109522253, time 726.0, rides 125\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 644, reward 278.0, memory_length 2000, epsilon 0.5594722323623683, time 732.0, rides 126\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 645, reward 181.0, memory_length 2000, epsilon 0.5589687073532422, time 730.0, rides 126\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 646, reward -190.0, memory_length 2000, epsilon 0.5584656355166243, time 734.0, rides 130\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 647, reward 77.0, memory_length 2000, epsilon 0.5579630164446594, time 730.0, rides 120\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 648, reward 228.0, memory_length 2000, epsilon 0.5574608497298592, time 728.0, rides 115\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 649, reward -81.0, memory_length 2000, epsilon 0.5569591349651023, time 728.0, rides 121\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 650, reward 34.0, memory_length 2000, epsilon 0.5564578717436337, time 730.0, rides 132\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 651, reward 293.0, memory_length 2000, epsilon 0.5559570596590644, time 726.0, rides 127\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 652, reward 461.0, memory_length 2000, epsilon 0.5554566983053713, time 727.0, rides 143\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 653, reward 40.0, memory_length 2000, epsilon 0.5549567872768965, time 728.0, rides 134\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 654, reward 104.0, memory_length 2000, epsilon 0.5544573261683472, time 721.0, rides 125\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 655, reward -62.0, memory_length 2000, epsilon 0.5539583145747957, time 722.0, rides 119\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 656, reward 83.0, memory_length 2000, epsilon 0.5534597520916784, time 723.0, rides 133\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 657, reward -67.0, memory_length 2000, epsilon 0.552961638314796, time 729.0, rides 130\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 658, reward 214.0, memory_length 2000, epsilon 0.5524639728403126, time 729.0, rides 123\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 659, reward 723.0, memory_length 2000, epsilon 0.5519667552647562, time 727.0, rides 120\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 660, reward 110.0, memory_length 2000, epsilon 0.551469985185018, time 725.0, rides 123\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 661, reward -44.0, memory_length 2000, epsilon 0.5509736621983514, time 732.0, rides 123\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 662, reward 703.0, memory_length 2000, epsilon 0.550477785902373, time 723.0, rides 123\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 663, reward 112.0, memory_length 2000, epsilon 0.5499823558950608, time 724.0, rides 113\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 664, reward 129.0, memory_length 2000, epsilon 0.5494873717747553, time 725.0, rides 130\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 665, reward -41.0, memory_length 2000, epsilon 0.548992833140158, time 729.0, rides 130\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 666, reward 331.0, memory_length 2000, epsilon 0.5484987395903319, time 732.0, rides 127\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 667, reward 49.0, memory_length 2000, epsilon 0.5480050907247006, time 726.0, rides 129\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 668, reward 285.0, memory_length 2000, epsilon 0.5475118861430484, time 732.0, rides 120\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 669, reward 336.0, memory_length 2000, epsilon 0.5470191254455196, time 739.0, rides 128\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 670, reward 399.0, memory_length 2000, epsilon 0.5465268082326186, time 722.0, rides 134\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 671, reward 261.0, memory_length 2000, epsilon 0.5460349341052092, time 726.0, rides 131\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 672, reward 87.0, memory_length 2000, epsilon 0.5455435026645145, time 740.0, rides 121\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 673, reward 89.0, memory_length 2000, epsilon 0.5450525135121164, time 727.0, rides 133\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 674, reward -1.0, memory_length 2000, epsilon 0.5445619662499555, time 738.0, rides 127\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 675, reward -59.0, memory_length 2000, epsilon 0.5440718604803305, time 723.0, rides 112\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 676, reward 439.0, memory_length 2000, epsilon 0.5435821958058982, time 726.0, rides 126\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 677, reward -46.0, memory_length 2000, epsilon 0.5430929718296729, time 731.0, rides 120\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 678, reward 244.0, memory_length 2000, epsilon 0.5426041881550262, time 728.0, rides 121\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 679, reward 144.0, memory_length 2000, epsilon 0.5421158443856867, time 726.0, rides 118\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 680, reward 181.0, memory_length 2000, epsilon 0.5416279401257396, time 726.0, rides 122\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 681, reward 243.0, memory_length 2000, epsilon 0.5411404749796264, time 726.0, rides 121\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 682, reward 311.0, memory_length 2000, epsilon 0.5406534485521447, time 732.0, rides 120\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 683, reward 373.0, memory_length 2000, epsilon 0.5401668604484477, time 726.0, rides 131\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 684, reward 372.0, memory_length 2000, epsilon 0.5396807102740442, time 728.0, rides 138\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 685, reward 227.0, memory_length 2000, epsilon 0.5391949976347975, time 724.0, rides 120\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 686, reward 112.0, memory_length 2000, epsilon 0.5387097221369261, time 735.0, rides 131\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 687, reward -86.0, memory_length 2000, epsilon 0.5382248833870029, time 723.0, rides 121\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 688, reward 185.0, memory_length 2000, epsilon 0.5377404809919546, time 735.0, rides 128\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 689, reward 266.0, memory_length 2000, epsilon 0.5372565145590619, time 726.0, rides 130\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 690, reward 166.0, memory_length 2000, epsilon 0.5367729836959587, time 730.0, rides 147\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 691, reward 83.0, memory_length 2000, epsilon 0.5362898880106324, time 727.0, rides 138\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 692, reward 448.0, memory_length 2000, epsilon 0.5358072271114228, time 730.0, rides 117\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 693, reward 179.0, memory_length 2000, epsilon 0.5353250006070225, time 728.0, rides 122\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 694, reward 506.0, memory_length 2000, epsilon 0.5348432081064761, time 726.0, rides 134\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 695, reward 137.0, memory_length 2000, epsilon 0.5343618492191803, time 731.0, rides 138\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 696, reward 424.0, memory_length 2000, epsilon 0.533880923554883, time 734.0, rides 136\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 697, reward 270.0, memory_length 2000, epsilon 0.5334004307236836, time 735.0, rides 131\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 698, reward 272.0, memory_length 2000, epsilon 0.5329203703360322, time 732.0, rides 126\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 699, reward 156.0, memory_length 2000, epsilon 0.5324407420027298, time 728.0, rides 128\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 700, reward 181.0, memory_length 2000, epsilon 0.5319615453349273, time 730.0, rides 123\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 701, reward 188.0, memory_length 2000, epsilon 0.5314827799441258, time 732.0, rides 124\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 702, reward 286.0, memory_length 2000, epsilon 0.5310044454421762, time 724.0, rides 112\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 703, reward 294.0, memory_length 2000, epsilon 0.5305265414412782, time 731.0, rides 139\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 704, reward 327.0, memory_length 2000, epsilon 0.5300490675539811, time 730.0, rides 148\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 705, reward 284.0, memory_length 2000, epsilon 0.5295720233931824, time 723.0, rides 127\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 706, reward 322.0, memory_length 2000, epsilon 0.5290954085721286, time 737.0, rides 122\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 707, reward 348.0, memory_length 2000, epsilon 0.5286192227044136, time 732.0, rides 125\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 708, reward 33.0, memory_length 2000, epsilon 0.5281434654039796, time 735.0, rides 130\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 709, reward 267.0, memory_length 2000, epsilon 0.527668136285116, time 727.0, rides 128\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 710, reward -41.0, memory_length 2000, epsilon 0.5271932349624594, time 727.0, rides 109\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 711, reward -12.0, memory_length 2000, epsilon 0.5267187610509931, time 722.0, rides 129\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 712, reward 286.0, memory_length 2000, epsilon 0.5262447141660472, time 723.0, rides 141\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 713, reward 152.0, memory_length 2000, epsilon 0.5257710939232978, time 729.0, rides 125\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 714, reward 165.0, memory_length 2000, epsilon 0.5252978999387669, time 729.0, rides 125\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 715, reward -36.0, memory_length 2000, epsilon 0.524825131828822, time 725.0, rides 145\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 716, reward 205.0, memory_length 2000, epsilon 0.524352789210176, time 724.0, rides 118\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 717, reward 161.0, memory_length 2000, epsilon 0.5238808716998868, time 723.0, rides 122\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 718, reward 432.0, memory_length 2000, epsilon 0.5234093789153569, time 734.0, rides 124\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 719, reward 153.0, memory_length 2000, epsilon 0.522938310474333, time 726.0, rides 142\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 720, reward 68.0, memory_length 2000, epsilon 0.5224676659949061, time 724.0, rides 122\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 721, reward 123.0, memory_length 2000, epsilon 0.5219974450955107, time 727.0, rides 122\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 722, reward 225.0, memory_length 2000, epsilon 0.5215276473949247, time 726.0, rides 126\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 723, reward 248.0, memory_length 2000, epsilon 0.5210582725122693, time 727.0, rides 123\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 724, reward -145.0, memory_length 2000, epsilon 0.5205893200670083, time 734.0, rides 116\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 725, reward 392.0, memory_length 2000, epsilon 0.520120789678948, time 729.0, rides 116\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 726, reward 195.0, memory_length 2000, epsilon 0.519652680968237, time 727.0, rides 143\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 727, reward 436.0, memory_length 2000, epsilon 0.5191849935553656, time 729.0, rides 120\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 728, reward 487.0, memory_length 2000, epsilon 0.5187177270611658, time 726.0, rides 118\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 729, reward 362.0, memory_length 2000, epsilon 0.5182508811068107, time 728.0, rides 139\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 730, reward 98.0, memory_length 2000, epsilon 0.5177844553138146, time 743.0, rides 128\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 731, reward 357.0, memory_length 2000, epsilon 0.5173184493040321, time 726.0, rides 123\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 732, reward 255.0, memory_length 2000, epsilon 0.5168528626996585, time 731.0, rides 138\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 733, reward 334.0, memory_length 2000, epsilon 0.5163876951232288, time 734.0, rides 130\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 734, reward 271.0, memory_length 2000, epsilon 0.5159229461976179, time 724.0, rides 142\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 735, reward -100.0, memory_length 2000, epsilon 0.51545861554604, time 728.0, rides 132\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 736, reward 80.0, memory_length 2000, epsilon 0.5149947027920485, time 730.0, rides 126\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 737, reward 506.0, memory_length 2000, epsilon 0.5145312075595356, time 725.0, rides 117\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 738, reward 95.0, memory_length 2000, epsilon 0.5140681294727321, time 725.0, rides 129\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 739, reward 408.0, memory_length 2000, epsilon 0.5136054681562066, time 728.0, rides 122\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 740, reward 191.0, memory_length 2000, epsilon 0.5131432232348659, time 733.0, rides 137\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 741, reward 147.0, memory_length 2000, epsilon 0.5126813943339545, time 731.0, rides 125\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 742, reward 300.0, memory_length 2000, epsilon 0.512219981079054, time 730.0, rides 138\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 743, reward 175.0, memory_length 2000, epsilon 0.5117589830960828, time 722.0, rides 124\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 744, reward 389.0, memory_length 2000, epsilon 0.5112984000112963, time 728.0, rides 132\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 745, reward 1.0, memory_length 2000, epsilon 0.5108382314512862, time 730.0, rides 135\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 746, reward 298.0, memory_length 2000, epsilon 0.51037847704298, time 728.0, rides 135\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 747, reward 305.0, memory_length 2000, epsilon 0.5099191364136413, time 726.0, rides 136\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 748, reward 208.0, memory_length 2000, epsilon 0.509460209190869, time 733.0, rides 134\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 749, reward 254.0, memory_length 2000, epsilon 0.5090016950025972, time 729.0, rides 134\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 750, reward 493.0, memory_length 2000, epsilon 0.5085435934770949, time 730.0, rides 117\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 751, reward 341.0, memory_length 2000, epsilon 0.5080859042429655, time 732.0, rides 130\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 752, reward -87.0, memory_length 2000, epsilon 0.5076286269291468, time 721.0, rides 116\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 753, reward 312.0, memory_length 2000, epsilon 0.5071717611649106, time 727.0, rides 127\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 754, reward 313.0, memory_length 2000, epsilon 0.5067153065798622, time 730.0, rides 127\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 755, reward 98.0, memory_length 2000, epsilon 0.5062592628039403, time 723.0, rides 134\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 756, reward 168.0, memory_length 2000, epsilon 0.5058036294674167, time 721.0, rides 126\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 757, reward 4.0, memory_length 2000, epsilon 0.505348406200896, time 727.0, rides 122\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 758, reward 166.0, memory_length 2000, epsilon 0.5048935926353152, time 723.0, rides 144\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 759, reward 89.0, memory_length 2000, epsilon 0.5044391884019434, time 730.0, rides 113\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 760, reward 343.0, memory_length 2000, epsilon 0.5039851931323815, time 732.0, rides 115\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 761, reward 417.0, memory_length 2000, epsilon 0.5035316064585624, time 723.0, rides 119\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 762, reward 321.0, memory_length 2000, epsilon 0.5030784280127497, time 726.0, rides 125\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 763, reward 163.0, memory_length 2000, epsilon 0.5026256574275383, time 734.0, rides 115\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 764, reward -149.0, memory_length 2000, epsilon 0.5021732943358534, time 729.0, rides 124\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 765, reward 430.0, memory_length 2000, epsilon 0.5017213383709511, time 725.0, rides 128\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 766, reward 275.0, memory_length 2000, epsilon 0.5012697891664173, time 727.0, rides 132\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 767, reward 254.0, memory_length 2000, epsilon 0.5008186463561675, time 729.0, rides 124\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 768, reward 140.0, memory_length 2000, epsilon 0.5003679095744469, time 722.0, rides 110\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 769, reward 309.0, memory_length 2000, epsilon 0.49991757845582985, time 725.0, rides 125\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 770, reward 55.0, memory_length 2000, epsilon 0.4994676526352196, time 725.0, rides 126\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 771, reward -7.0, memory_length 2000, epsilon 0.49901813174784787, time 726.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 772, reward 242.0, memory_length 2000, epsilon 0.4985690154292748, time 728.0, rides 125\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 773, reward 238.0, memory_length 2000, epsilon 0.4981203033153884, time 728.0, rides 133\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 774, reward 8.0, memory_length 2000, epsilon 0.49767199504240456, time 724.0, rides 137\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 775, reward 145.0, memory_length 2000, epsilon 0.49722409024686637, time 733.0, rides 124\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 776, reward 306.0, memory_length 2000, epsilon 0.49677658856564416, time 741.0, rides 124\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 777, reward 187.0, memory_length 2000, epsilon 0.4963294896359351, time 731.0, rides 121\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 778, reward -109.0, memory_length 2000, epsilon 0.49588279309526273, time 722.0, rides 111\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 779, reward 455.0, memory_length 2000, epsilon 0.495436498581477, time 735.0, rides 131\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 780, reward 146.0, memory_length 2000, epsilon 0.49499060573275366, time 733.0, rides 138\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 781, reward 229.0, memory_length 2000, epsilon 0.49454511418759417, time 730.0, rides 121\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 782, reward 339.0, memory_length 2000, epsilon 0.49410002358482535, time 733.0, rides 130\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 783, reward 402.0, memory_length 2000, epsilon 0.49365533356359903, time 725.0, rides 124\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 784, reward 504.0, memory_length 2000, epsilon 0.4932110437633918, time 735.0, rides 131\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 785, reward 404.0, memory_length 2000, epsilon 0.49276715382400477, time 726.0, rides 140\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 786, reward -9.0, memory_length 2000, epsilon 0.49232366338556316, time 735.0, rides 117\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 787, reward 129.0, memory_length 2000, epsilon 0.49188057208851615, time 726.0, rides 127\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 788, reward 64.0, memory_length 2000, epsilon 0.4914378795736365, time 725.0, rides 135\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 789, reward 277.0, memory_length 2000, epsilon 0.4909955854820202, time 730.0, rides 120\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 790, reward 448.0, memory_length 2000, epsilon 0.4905536894550864, time 733.0, rides 134\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 791, reward 259.0, memory_length 2000, epsilon 0.49011219113457677, time 734.0, rides 137\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 792, reward 223.0, memory_length 2000, epsilon 0.48967109016255567, time 730.0, rides 123\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 793, reward -25.0, memory_length 2000, epsilon 0.48923038618140935, time 734.0, rides 132\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 794, reward 300.0, memory_length 2000, epsilon 0.48879007883384606, time 732.0, rides 124\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 795, reward 451.0, memory_length 2000, epsilon 0.4883501677628956, time 732.0, rides 121\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 796, reward 267.0, memory_length 2000, epsilon 0.48791065261190897, time 731.0, rides 127\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 797, reward 102.0, memory_length 2000, epsilon 0.48747153302455826, time 727.0, rides 126\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 798, reward 34.0, memory_length 2000, epsilon 0.48703280864483617, time 731.0, rides 134\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 799, reward 62.0, memory_length 2000, epsilon 0.48659447911705583, time 726.0, rides 115\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 800, reward 327.0, memory_length 2000, epsilon 0.48615654408585046, time 730.0, rides 146\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 801, reward 312.0, memory_length 2000, epsilon 0.48571900319617317, time 727.0, rides 121\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 802, reward 165.0, memory_length 2000, epsilon 0.4852818560932966, time 740.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 803, reward 247.0, memory_length 2000, epsilon 0.48484510242281265, time 740.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 804, reward 424.0, memory_length 2000, epsilon 0.4844087418306321, time 726.0, rides 133\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 805, reward 269.0, memory_length 2000, epsilon 0.4839727739629845, time 733.0, rides 157\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 806, reward 188.0, memory_length 2000, epsilon 0.4835371984664178, time 728.0, rides 125\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 807, reward 24.0, memory_length 2000, epsilon 0.48310201498779803, time 731.0, rides 113\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 808, reward 55.0, memory_length 2000, epsilon 0.482667223174309, time 728.0, rides 140\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 809, reward 388.0, memory_length 2000, epsilon 0.48223282267345213, time 728.0, rides 139\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 810, reward -45.0, memory_length 2000, epsilon 0.481798813133046, time 729.0, rides 133\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 811, reward 6.0, memory_length 2000, epsilon 0.48136519420122625, time 722.0, rides 146\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 812, reward 314.0, memory_length 2000, epsilon 0.4809319655264451, time 721.0, rides 131\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 813, reward 229.0, memory_length 2000, epsilon 0.4804991267574713, time 730.0, rides 125\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 814, reward 350.0, memory_length 2000, epsilon 0.48006667754338955, time 731.0, rides 128\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 815, reward 26.0, memory_length 2000, epsilon 0.4796346175336005, time 723.0, rides 130\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 816, reward 396.0, memory_length 2000, epsilon 0.47920294637782024, time 729.0, rides 115\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 817, reward 379.0, memory_length 2000, epsilon 0.4787716637260802, time 732.0, rides 130\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 818, reward 272.0, memory_length 2000, epsilon 0.47834076922872676, time 728.0, rides 128\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 819, reward -104.0, memory_length 2000, epsilon 0.4779102625364209, time 734.0, rides 123\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 820, reward 364.0, memory_length 2000, epsilon 0.4774801433001381, time 733.0, rides 135\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 821, reward 171.0, memory_length 2000, epsilon 0.477050411171168, time 732.0, rides 137\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 822, reward 225.0, memory_length 2000, epsilon 0.4766210658011139, time 727.0, rides 135\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 823, reward 277.0, memory_length 2000, epsilon 0.4761921068418929, time 729.0, rides 127\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 824, reward 90.0, memory_length 2000, epsilon 0.4757635339457352, time 724.0, rides 132\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 825, reward 144.0, memory_length 2000, epsilon 0.475335346765184, time 739.0, rides 130\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 826, reward 176.0, memory_length 2000, epsilon 0.47490754495309534, time 730.0, rides 128\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 827, reward 63.0, memory_length 2000, epsilon 0.47448012816263757, time 725.0, rides 126\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 828, reward 412.0, memory_length 2000, epsilon 0.4740530960472912, time 729.0, rides 136\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 829, reward 205.0, memory_length 2000, epsilon 0.4736264482608486, time 724.0, rides 126\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 830, reward 498.0, memory_length 2000, epsilon 0.47320018445741385, time 731.0, rides 135\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 831, reward 475.0, memory_length 2000, epsilon 0.47277430429140216, time 736.0, rides 124\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 832, reward -40.0, memory_length 2000, epsilon 0.4723488074175399, time 730.0, rides 120\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 833, reward 87.0, memory_length 2000, epsilon 0.4719236934908641, time 734.0, rides 137\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 834, reward 611.0, memory_length 2000, epsilon 0.4714989621667223, time 729.0, rides 132\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 835, reward 422.0, memory_length 2000, epsilon 0.47107461310077225, time 722.0, rides 139\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 836, reward 227.0, memory_length 2000, epsilon 0.47065064594898154, time 726.0, rides 121\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 837, reward -55.0, memory_length 2000, epsilon 0.47022706036762746, time 737.0, rides 132\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 838, reward 268.0, memory_length 2000, epsilon 0.4698038560132966, time 748.0, rides 130\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 839, reward 380.0, memory_length 2000, epsilon 0.46938103254288466, time 739.0, rides 115\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 840, reward 172.0, memory_length 2000, epsilon 0.46895858961359604, time 741.0, rides 130\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 841, reward 151.0, memory_length 2000, epsilon 0.4685365268829438, time 728.0, rides 137\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 842, reward 279.0, memory_length 2000, epsilon 0.46811484400874914, time 736.0, rides 126\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 843, reward 347.0, memory_length 2000, epsilon 0.46769354064914126, time 726.0, rides 125\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 844, reward 337.0, memory_length 2000, epsilon 0.467272616462557, time 737.0, rides 122\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 845, reward 88.0, memory_length 2000, epsilon 0.46685207110774074, time 735.0, rides 129\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 846, reward 398.0, memory_length 2000, epsilon 0.46643190424374376, time 730.0, rides 120\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 847, reward 304.0, memory_length 2000, epsilon 0.4660121155299244, time 726.0, rides 115\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 848, reward 73.0, memory_length 2000, epsilon 0.46559270462594743, time 745.0, rides 132\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 849, reward 10.0, memory_length 2000, epsilon 0.46517367119178404, time 731.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 850, reward 284.0, memory_length 2000, epsilon 0.4647550148877114, time 729.0, rides 120\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 851, reward 192.0, memory_length 2000, epsilon 0.46433673537431247, time 731.0, rides 122\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 852, reward 510.0, memory_length 2000, epsilon 0.4639188323124756, time 736.0, rides 127\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 853, reward 232.0, memory_length 2000, epsilon 0.46350130536339434, time 722.0, rides 133\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 854, reward 266.0, memory_length 2000, epsilon 0.4630841541885673, time 732.0, rides 129\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 855, reward 415.0, memory_length 2000, epsilon 0.4626673784497976, time 729.0, rides 135\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 856, reward 461.0, memory_length 2000, epsilon 0.4622509778091928, time 728.0, rides 117\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 857, reward 250.0, memory_length 2000, epsilon 0.4618349519291645, time 732.0, rides 118\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 858, reward 560.0, memory_length 2000, epsilon 0.46141930047242824, time 729.0, rides 131\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 859, reward 290.0, memory_length 2000, epsilon 0.46100402310200306, time 725.0, rides 124\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 860, reward 316.0, memory_length 2000, epsilon 0.46058911948121123, time 724.0, rides 127\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 861, reward 344.0, memory_length 2000, epsilon 0.46017458927367816, time 736.0, rides 130\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 862, reward 431.0, memory_length 2000, epsilon 0.45976043214333184, time 732.0, rides 127\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 863, reward 434.0, memory_length 2000, epsilon 0.4593466477544028, time 732.0, rides 127\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 864, reward 525.0, memory_length 2000, epsilon 0.45893323577142386, time 735.0, rides 117\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 865, reward 317.0, memory_length 2000, epsilon 0.4585201958592296, time 737.0, rides 134\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 866, reward 306.0, memory_length 2000, epsilon 0.45810752768295626, time 726.0, rides 147\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 867, reward 366.0, memory_length 2000, epsilon 0.4576952309080416, time 726.0, rides 130\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 868, reward 429.0, memory_length 2000, epsilon 0.45728330520022437, time 734.0, rides 136\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 869, reward 281.0, memory_length 2000, epsilon 0.45687175022554416, time 723.0, rides 125\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 870, reward 460.0, memory_length 2000, epsilon 0.45646056565034115, time 729.0, rides 130\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 871, reward 3.0, memory_length 2000, epsilon 0.45604975114125584, time 730.0, rides 115\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 872, reward 146.0, memory_length 2000, epsilon 0.4556393063652287, time 723.0, rides 129\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 873, reward 273.0, memory_length 2000, epsilon 0.45522923098949997, time 728.0, rides 135\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 874, reward -72.0, memory_length 2000, epsilon 0.4548195246816094, time 725.0, rides 121\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 875, reward 316.0, memory_length 2000, epsilon 0.45441018710939596, time 739.0, rides 124\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 876, reward 406.0, memory_length 2000, epsilon 0.4540012179409975, time 734.0, rides 125\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 877, reward 192.0, memory_length 2000, epsilon 0.45359261684485064, time 727.0, rides 115\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 878, reward 131.0, memory_length 2000, epsilon 0.45318438348969026, time 726.0, rides 132\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 879, reward 312.0, memory_length 2000, epsilon 0.4527765175445495, time 731.0, rides 127\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 880, reward 376.0, memory_length 2000, epsilon 0.4523690186787594, time 728.0, rides 121\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 881, reward 88.0, memory_length 2000, epsilon 0.4519618865619485, time 728.0, rides 129\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 882, reward 200.0, memory_length 2000, epsilon 0.45155512086404276, time 727.0, rides 129\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 883, reward 219.0, memory_length 2000, epsilon 0.4511487212552651, time 736.0, rides 130\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 884, reward 298.0, memory_length 2000, epsilon 0.4507426874061354, time 730.0, rides 131\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 885, reward 409.0, memory_length 2000, epsilon 0.45033701898746986, time 730.0, rides 125\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 886, reward 278.0, memory_length 2000, epsilon 0.44993171567038115, time 730.0, rides 126\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 887, reward 382.0, memory_length 2000, epsilon 0.4495267771262778, time 724.0, rides 136\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 888, reward 184.0, memory_length 2000, epsilon 0.4491222030268642, time 724.0, rides 130\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 889, reward 434.0, memory_length 2000, epsilon 0.44871799304414, time 730.0, rides 126\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 890, reward 201.0, memory_length 2000, epsilon 0.4483141468504003, time 735.0, rides 124\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 891, reward 277.0, memory_length 2000, epsilon 0.44791066411823494, time 734.0, rides 132\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 892, reward 165.0, memory_length 2000, epsilon 0.44750754452052854, time 741.0, rides 131\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 893, reward 194.0, memory_length 2000, epsilon 0.4471047877304601, time 731.0, rides 133\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 894, reward 426.0, memory_length 2000, epsilon 0.44670239342150264, time 727.0, rides 131\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 895, reward 190.0, memory_length 2000, epsilon 0.4463003612674233, time 728.0, rides 140\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 896, reward 210.0, memory_length 2000, epsilon 0.44589869094228257, time 732.0, rides 122\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 897, reward 105.0, memory_length 2000, epsilon 0.4454973821204345, time 729.0, rides 118\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 898, reward 200.0, memory_length 2000, epsilon 0.4450964344765261, time 724.0, rides 133\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 899, reward 264.0, memory_length 2000, epsilon 0.4446958476854972, time 731.0, rides 122\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 900, reward 599.0, memory_length 2000, epsilon 0.4442956214225802, time 727.0, rides 152\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 901, reward 759.0, memory_length 2000, epsilon 0.4438957553632999, time 732.0, rides 136\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 902, reward 211.0, memory_length 2000, epsilon 0.4434962491834729, time 729.0, rides 127\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 903, reward 360.0, memory_length 2000, epsilon 0.44309710255920776, time 723.0, rides 127\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 904, reward 638.0, memory_length 2000, epsilon 0.44269831516690444, time 733.0, rides 131\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 905, reward 420.0, memory_length 2000, epsilon 0.4422998866832542, time 724.0, rides 127\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 906, reward 466.0, memory_length 2000, epsilon 0.44190181678523927, time 722.0, rides 130\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 907, reward 350.0, memory_length 2000, epsilon 0.44150410515013255, time 726.0, rides 124\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 908, reward 359.0, memory_length 2000, epsilon 0.44110675145549744, time 735.0, rides 152\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 909, reward 292.0, memory_length 2000, epsilon 0.4407097553791875, time 728.0, rides 137\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 910, reward 142.0, memory_length 2000, epsilon 0.44031311659934624, time 726.0, rides 126\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 911, reward 539.0, memory_length 2000, epsilon 0.43991683479440685, time 725.0, rides 125\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 912, reward 68.0, memory_length 2000, epsilon 0.4395209096430919, time 729.0, rides 120\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 913, reward 193.0, memory_length 2000, epsilon 0.43912534082441307, time 731.0, rides 138\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 914, reward 429.0, memory_length 2000, epsilon 0.4387301280176711, time 724.0, rides 133\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 915, reward 400.0, memory_length 2000, epsilon 0.43833527090245517, time 727.0, rides 112\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 916, reward 250.0, memory_length 2000, epsilon 0.43794076915864294, time 731.0, rides 128\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 917, reward 79.0, memory_length 2000, epsilon 0.43754662246640014, time 738.0, rides 131\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 918, reward 388.0, memory_length 2000, epsilon 0.43715283050618037, time 734.0, rides 120\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 919, reward 248.0, memory_length 2000, epsilon 0.4367593929587248, time 725.0, rides 120\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 920, reward 208.0, memory_length 2000, epsilon 0.43636630950506194, time 729.0, rides 120\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 921, reward 316.0, memory_length 2000, epsilon 0.43597357982650736, time 729.0, rides 121\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 922, reward 362.0, memory_length 2000, epsilon 0.4355812036046635, time 729.0, rides 115\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 923, reward 29.0, memory_length 2000, epsilon 0.4351891805214193, time 724.0, rides 133\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 924, reward 208.0, memory_length 2000, epsilon 0.43479751025895, time 738.0, rides 126\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 925, reward 113.0, memory_length 2000, epsilon 0.43440619249971696, time 724.0, rides 122\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 926, reward 451.0, memory_length 2000, epsilon 0.4340152269264672, time 730.0, rides 125\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 927, reward 557.0, memory_length 2000, epsilon 0.4336246132222334, time 728.0, rides 124\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 928, reward 647.0, memory_length 2000, epsilon 0.43323435107033337, time 728.0, rides 143\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 929, reward 469.0, memory_length 2000, epsilon 0.43284444015437007, time 723.0, rides 148\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 930, reward 497.0, memory_length 2000, epsilon 0.43245488015823114, time 731.0, rides 127\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 931, reward 409.0, memory_length 2000, epsilon 0.4320656707660887, time 725.0, rides 132\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 932, reward 256.0, memory_length 2000, epsilon 0.43167681166239924, time 727.0, rides 138\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 933, reward 575.0, memory_length 2000, epsilon 0.4312883025319031, time 741.0, rides 131\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 934, reward 160.0, memory_length 2000, epsilon 0.4309001430596244, time 729.0, rides 139\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 935, reward 205.0, memory_length 2000, epsilon 0.4305123329308707, time 730.0, rides 130\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 936, reward 409.0, memory_length 2000, epsilon 0.43012487183123294, time 725.0, rides 132\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 937, reward 353.0, memory_length 2000, epsilon 0.4297377594465848, time 727.0, rides 119\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 938, reward 181.0, memory_length 2000, epsilon 0.42935099546308286, time 729.0, rides 121\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 939, reward 77.0, memory_length 2000, epsilon 0.4289645795671661, time 737.0, rides 129\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 940, reward 143.0, memory_length 2000, epsilon 0.42857851144555564, time 730.0, rides 132\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 941, reward 374.0, memory_length 2000, epsilon 0.42819279078525463, time 732.0, rides 129\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 942, reward 303.0, memory_length 2000, epsilon 0.4278074172735479, time 724.0, rides 127\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 943, reward 310.0, memory_length 2000, epsilon 0.4274223905980017, time 735.0, rides 123\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 944, reward 142.0, memory_length 2000, epsilon 0.4270377104464635, time 724.0, rides 119\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 945, reward 242.0, memory_length 2000, epsilon 0.42665337650706164, time 732.0, rides 145\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 946, reward 362.0, memory_length 2000, epsilon 0.4262693884682053, time 729.0, rides 121\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 947, reward 163.0, memory_length 2000, epsilon 0.42588574601858387, time 730.0, rides 128\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 948, reward 151.0, memory_length 2000, epsilon 0.42550244884716715, time 726.0, rides 133\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 949, reward 155.0, memory_length 2000, epsilon 0.4251194966432047, time 730.0, rides 118\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 950, reward 433.0, memory_length 2000, epsilon 0.4247368890962258, time 729.0, rides 130\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 951, reward 213.0, memory_length 2000, epsilon 0.42435462589603923, time 723.0, rides 114\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 952, reward 158.0, memory_length 2000, epsilon 0.4239727067327328, time 730.0, rides 124\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 953, reward 411.0, memory_length 2000, epsilon 0.4235911312966733, time 729.0, rides 115\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 954, reward 311.0, memory_length 2000, epsilon 0.4232098992785063, time 734.0, rides 130\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 955, reward 313.0, memory_length 2000, epsilon 0.4228290103691556, time 732.0, rides 118\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 956, reward 409.0, memory_length 2000, epsilon 0.42244846425982335, time 735.0, rides 128\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 957, reward -35.0, memory_length 2000, epsilon 0.4220682606419895, time 728.0, rides 126\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 958, reward 384.0, memory_length 2000, epsilon 0.4216883992074117, time 746.0, rides 136\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 959, reward 142.0, memory_length 2000, epsilon 0.421308879648125, time 721.0, rides 120\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 960, reward 264.0, memory_length 2000, epsilon 0.4209297016564417, time 739.0, rides 123\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 961, reward 531.0, memory_length 2000, epsilon 0.4205508649249509, time 728.0, rides 136\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 962, reward 512.0, memory_length 2000, epsilon 0.42017236914651845, time 724.0, rides 123\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 963, reward 281.0, memory_length 2000, epsilon 0.41979421401428657, time 729.0, rides 121\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 964, reward 194.0, memory_length 2000, epsilon 0.41941639922167373, time 733.0, rides 128\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 965, reward 416.0, memory_length 2000, epsilon 0.41903892446237423, time 724.0, rides 115\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 966, reward 295.0, memory_length 2000, epsilon 0.4186617894303581, time 728.0, rides 116\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 967, reward 343.0, memory_length 2000, epsilon 0.4182849938198708, time 723.0, rides 122\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 968, reward 228.0, memory_length 2000, epsilon 0.41790853732543287, time 728.0, rides 124\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 969, reward 181.0, memory_length 2000, epsilon 0.41753241964183996, time 728.0, rides 127\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 970, reward 319.0, memory_length 2000, epsilon 0.4171566404641623, time 727.0, rides 117\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 971, reward 154.0, memory_length 2000, epsilon 0.41678119948774456, time 732.0, rides 133\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 972, reward 512.0, memory_length 2000, epsilon 0.4164060964082056, time 728.0, rides 126\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 973, reward 84.0, memory_length 2000, epsilon 0.4160313309214382, time 722.0, rides 120\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 974, reward 337.0, memory_length 2000, epsilon 0.4156569027236089, time 729.0, rides 145\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 975, reward 544.0, memory_length 2000, epsilon 0.41528281151115765, time 737.0, rides 133\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 976, reward 197.0, memory_length 2000, epsilon 0.4149090569807976, time 730.0, rides 131\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 977, reward 437.0, memory_length 2000, epsilon 0.4145356388295149, time 726.0, rides 116\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 978, reward 485.0, memory_length 2000, epsilon 0.4141625567545683, time 728.0, rides 137\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 979, reward 54.0, memory_length 2000, epsilon 0.41378981045348917, time 731.0, rides 132\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 980, reward 491.0, memory_length 2000, epsilon 0.41341739962408103, time 728.0, rides 123\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 981, reward 329.0, memory_length 2000, epsilon 0.41304532396441934, time 723.0, rides 130\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 982, reward 271.0, memory_length 2000, epsilon 0.41267358317285135, time 733.0, rides 129\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 983, reward 409.0, memory_length 2000, epsilon 0.41230217694799576, time 724.0, rides 123\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 984, reward 557.0, memory_length 2000, epsilon 0.4119311049887426, time 731.0, rides 143\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 985, reward 593.0, memory_length 2000, epsilon 0.4115603669942527, time 724.0, rides 133\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 986, reward 553.0, memory_length 2000, epsilon 0.41118996266395785, time 734.0, rides 144\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 987, reward 452.0, memory_length 2000, epsilon 0.4108198916975603, time 726.0, rides 135\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 988, reward 477.0, memory_length 2000, epsilon 0.41045015379503247, time 732.0, rides 124\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 989, reward 169.0, memory_length 2000, epsilon 0.4100807486566169, time 723.0, rides 130\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 990, reward 350.0, memory_length 2000, epsilon 0.409711675982826, time 725.0, rides 124\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 991, reward 227.0, memory_length 2000, epsilon 0.40934293547444145, time 732.0, rides 121\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 992, reward 247.0, memory_length 2000, epsilon 0.40897452683251445, time 729.0, rides 128\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 993, reward 129.0, memory_length 2000, epsilon 0.4086064497583652, time 724.0, rides 130\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 994, reward 183.0, memory_length 2000, epsilon 0.40823870395358264, time 728.0, rides 131\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 995, reward 660.0, memory_length 2000, epsilon 0.4078712891200244, time 723.0, rides 126\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 996, reward 290.0, memory_length 2000, epsilon 0.4075042049598164, time 722.0, rides 120\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 997, reward 19.0, memory_length 2000, epsilon 0.40713745117535255, time 728.0, rides 127\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 998, reward 460.0, memory_length 2000, epsilon 0.4067710274692947, time 735.0, rides 118\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 999, reward 427.0, memory_length 2000, epsilon 0.40640493354457236, time 730.0, rides 128\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 1000, reward 653.0, memory_length 2000, epsilon 0.40603916910438226, time 735.0, rides 135\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 1001, reward 563.0, memory_length 2000, epsilon 0.4056737338521883, time 729.0, rides 115\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 1002, reward 215.0, memory_length 2000, epsilon 0.4053086274917213, time 729.0, rides 128\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 1003, reward 252.0, memory_length 2000, epsilon 0.4049438497269788, time 733.0, rides 139\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 1004, reward 300.0, memory_length 2000, epsilon 0.4045794002622245, time 731.0, rides 126\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 1005, reward 585.0, memory_length 2000, epsilon 0.4042152788019885, time 738.0, rides 129\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 1006, reward 220.0, memory_length 2000, epsilon 0.4038514850510667, time 723.0, rides 133\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 1007, reward 256.0, memory_length 2000, epsilon 0.4034880187145207, time 732.0, rides 122\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 1008, reward 508.0, memory_length 2000, epsilon 0.40312487949767767, time 728.0, rides 133\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 1009, reward 419.0, memory_length 2000, epsilon 0.4027620671061298, time 728.0, rides 126\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 1010, reward 566.0, memory_length 2000, epsilon 0.4023995812457343, time 725.0, rides 123\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 1011, reward 290.0, memory_length 2000, epsilon 0.40203742162261313, time 723.0, rides 124\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 1012, reward 524.0, memory_length 2000, epsilon 0.4016755879431528, time 723.0, rides 115\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 1013, reward 211.0, memory_length 2000, epsilon 0.4013140799140039, time 724.0, rides 141\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 1014, reward 245.0, memory_length 2000, epsilon 0.40095289724208133, time 727.0, rides 122\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 1015, reward 426.0, memory_length 2000, epsilon 0.40059203963456347, time 729.0, rides 124\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 1016, reward 384.0, memory_length 2000, epsilon 0.40023150679889236, time 733.0, rides 133\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 1017, reward 224.0, memory_length 2000, epsilon 0.39987129844277336, time 732.0, rides 142\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1018, reward 236.0, memory_length 2000, epsilon 0.39951141427417486, time 733.0, rides 120\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1019, reward 381.0, memory_length 2000, epsilon 0.3991518540013281, time 731.0, rides 127\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 1020, reward 192.0, memory_length 2000, epsilon 0.39879261733272686, time 730.0, rides 132\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 1021, reward 222.0, memory_length 2000, epsilon 0.3984337039771274, time 726.0, rides 121\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 1022, reward 584.0, memory_length 2000, epsilon 0.398075113643548, time 728.0, rides 138\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 1023, reward 29.0, memory_length 2000, epsilon 0.3977168460412688, time 732.0, rides 126\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 1024, reward 343.0, memory_length 2000, epsilon 0.3973589008798316, time 724.0, rides 127\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 1025, reward 395.0, memory_length 2000, epsilon 0.39700127786903977, time 723.0, rides 123\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 1026, reward 318.0, memory_length 2000, epsilon 0.3966439767189576, time 727.0, rides 116\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 1027, reward 205.0, memory_length 2000, epsilon 0.39628699713991056, time 730.0, rides 124\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 1028, reward 226.0, memory_length 2000, epsilon 0.39593033884248463, time 727.0, rides 135\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1029, reward 548.0, memory_length 2000, epsilon 0.39557400153752637, time 730.0, rides 137\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 1030, reward 289.0, memory_length 2000, epsilon 0.3952179849361426, time 724.0, rides 119\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1031, reward 326.0, memory_length 2000, epsilon 0.39486228874970003, time 727.0, rides 125\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 1032, reward 348.0, memory_length 2000, epsilon 0.3945069126898253, time 729.0, rides 123\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 1033, reward 463.0, memory_length 2000, epsilon 0.39415185646840445, time 731.0, rides 127\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 1034, reward 503.0, memory_length 2000, epsilon 0.39379711979758286, time 725.0, rides 121\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 1035, reward 252.0, memory_length 2000, epsilon 0.39344270238976503, time 721.0, rides 126\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 1036, reward 320.0, memory_length 2000, epsilon 0.39308860395761425, time 730.0, rides 141\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 1037, reward 247.0, memory_length 2000, epsilon 0.39273482421405237, time 741.0, rides 119\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1038, reward 725.0, memory_length 2000, epsilon 0.3923813628722597, time 738.0, rides 123\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 1039, reward 218.0, memory_length 2000, epsilon 0.3920282196456747, time 733.0, rides 118\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 1040, reward 454.0, memory_length 2000, epsilon 0.3916753942479936, time 723.0, rides 127\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 1041, reward 328.0, memory_length 2000, epsilon 0.39132288639317037, time 735.0, rides 116\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 1042, reward 169.0, memory_length 2000, epsilon 0.3909706957954165, time 731.0, rides 121\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 1043, reward 611.0, memory_length 2000, epsilon 0.39061882216920063, time 731.0, rides 121\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 1044, reward 215.0, memory_length 2000, epsilon 0.3902672652292484, time 734.0, rides 134\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 1045, reward 439.0, memory_length 2000, epsilon 0.38991602469054204, time 732.0, rides 138\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 1046, reward -18.0, memory_length 2000, epsilon 0.38956510026832053, time 739.0, rides 135\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 1047, reward 186.0, memory_length 2000, epsilon 0.38921449167807903, time 727.0, rides 134\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 1048, reward 36.0, memory_length 2000, epsilon 0.38886419863556876, time 735.0, rides 123\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 1049, reward 279.0, memory_length 2000, epsilon 0.38851422085679677, time 730.0, rides 135\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 1050, reward 530.0, memory_length 2000, epsilon 0.38816455805802563, time 731.0, rides 137\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1051, reward 245.0, memory_length 2000, epsilon 0.3878152099557734, time 729.0, rides 125\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 1052, reward 391.0, memory_length 2000, epsilon 0.3874661762668132, time 729.0, rides 131\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1053, reward 115.0, memory_length 2000, epsilon 0.38711745670817305, time 737.0, rides 127\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1054, reward 635.0, memory_length 2000, epsilon 0.3867690509971357, time 733.0, rides 137\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 1055, reward 180.0, memory_length 2000, epsilon 0.3864209588512383, time 725.0, rides 129\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 1056, reward 273.0, memory_length 2000, epsilon 0.3860731799882722, time 735.0, rides 108\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 1057, reward 35.0, memory_length 2000, epsilon 0.3857257141262827, time 724.0, rides 125\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 1058, reward 449.0, memory_length 2000, epsilon 0.38537856098356904, time 742.0, rides 134\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 1059, reward 556.0, memory_length 2000, epsilon 0.3850317202786838, time 736.0, rides 140\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1060, reward 424.0, memory_length 2000, epsilon 0.384685191730433, time 728.0, rides 137\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1061, reward 134.0, memory_length 2000, epsilon 0.38433897505787556, time 738.0, rides 141\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 1062, reward 414.0, memory_length 2000, epsilon 0.38399306998032345, time 724.0, rides 133\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1063, reward 259.0, memory_length 2000, epsilon 0.38364747621734113, time 727.0, rides 139\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 1064, reward 375.0, memory_length 2000, epsilon 0.3833021934887455, time 728.0, rides 138\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 1065, reward 253.0, memory_length 2000, epsilon 0.38295722151460565, time 736.0, rides 116\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 1066, reward -6.0, memory_length 2000, epsilon 0.3826125600152425, time 731.0, rides 129\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 1067, reward 584.0, memory_length 2000, epsilon 0.3822682087112288, time 726.0, rides 126\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 1068, reward 497.0, memory_length 2000, epsilon 0.3819241673233887, time 730.0, rides 121\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1069, reward 353.0, memory_length 2000, epsilon 0.38158043557279764, time 725.0, rides 137\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 1070, reward 187.0, memory_length 2000, epsilon 0.3812370131807821, time 730.0, rides 130\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1071, reward 416.0, memory_length 2000, epsilon 0.3808938998689194, time 725.0, rides 128\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 1072, reward 644.0, memory_length 2000, epsilon 0.38055109535903736, time 726.0, rides 136\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1073, reward 314.0, memory_length 2000, epsilon 0.3802085993732142, time 724.0, rides 134\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 1074, reward 500.0, memory_length 2000, epsilon 0.3798664116337783, time 734.0, rides 131\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 1075, reward 318.0, memory_length 2000, epsilon 0.3795245318633079, time 726.0, rides 121\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 1076, reward -42.0, memory_length 2000, epsilon 0.37918295978463096, time 724.0, rides 128\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 1077, reward 251.0, memory_length 2000, epsilon 0.3788416951208248, time 727.0, rides 131\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 1078, reward 213.0, memory_length 2000, epsilon 0.378500737595216, time 735.0, rides 126\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 1079, reward 335.0, memory_length 2000, epsilon 0.3781600869313803, time 727.0, rides 119\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 1080, reward 395.0, memory_length 2000, epsilon 0.37781974285314207, time 733.0, rides 132\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 1081, reward 756.0, memory_length 2000, epsilon 0.37747970508457424, time 725.0, rides 123\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 1082, reward 210.0, memory_length 2000, epsilon 0.3771399733499981, time 722.0, rides 130\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 1083, reward 347.0, memory_length 2000, epsilon 0.3768005473739831, time 730.0, rides 127\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 1084, reward 318.0, memory_length 2000, epsilon 0.37646142688134654, time 721.0, rides 117\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 1085, reward 406.0, memory_length 2000, epsilon 0.3761226115971533, time 730.0, rides 137\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 1086, reward 24.0, memory_length 2000, epsilon 0.3757841012467159, time 729.0, rides 133\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 1087, reward 45.0, memory_length 2000, epsilon 0.3754458955555939, time 729.0, rides 135\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 1088, reward 524.0, memory_length 2000, epsilon 0.37510799424959385, time 724.0, rides 126\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 1089, reward 445.0, memory_length 2000, epsilon 0.3747703970547692, time 728.0, rides 139\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 1090, reward 346.0, memory_length 2000, epsilon 0.37443310369741994, time 729.0, rides 133\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 1091, reward 109.0, memory_length 2000, epsilon 0.37409611390409225, time 727.0, rides 140\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 1092, reward 247.0, memory_length 2000, epsilon 0.3737594274015786, time 735.0, rides 121\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 1093, reward 637.0, memory_length 2000, epsilon 0.37342304391691716, time 735.0, rides 132\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 1094, reward 261.0, memory_length 2000, epsilon 0.37308696317739193, time 735.0, rides 145\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 1095, reward 178.0, memory_length 2000, epsilon 0.3727511849105323, time 729.0, rides 129\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 1096, reward 240.0, memory_length 2000, epsilon 0.3724157088441128, time 735.0, rides 109\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 1097, reward 623.0, memory_length 2000, epsilon 0.3720805347061531, time 737.0, rides 133\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 1098, reward 459.0, memory_length 2000, epsilon 0.37174566222491756, time 737.0, rides 143\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 1099, reward 483.0, memory_length 2000, epsilon 0.3714110911289151, time 723.0, rides 140\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1100, reward 296.0, memory_length 2000, epsilon 0.3710768211468991, time 724.0, rides 140\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 1101, reward 373.0, memory_length 2000, epsilon 0.3707428520078669, time 732.0, rides 106\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 1102, reward 50.0, memory_length 2000, epsilon 0.3704091834410598, time 735.0, rides 121\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 1103, reward 394.0, memory_length 2000, epsilon 0.37007581517596283, time 732.0, rides 118\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1104, reward 519.0, memory_length 2000, epsilon 0.36974274694230447, time 724.0, rides 146\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 1105, reward 555.0, memory_length 2000, epsilon 0.3694099784700564, time 732.0, rides 137\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 1106, reward 387.0, memory_length 2000, epsilon 0.36907750948943335, time 723.0, rides 117\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 1107, reward 301.0, memory_length 2000, epsilon 0.36874533973089285, time 731.0, rides 133\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 1108, reward 430.0, memory_length 2000, epsilon 0.36841346892513505, time 733.0, rides 113\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 1109, reward 618.0, memory_length 2000, epsilon 0.36808189680310244, time 724.0, rides 130\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 1110, reward 484.0, memory_length 2000, epsilon 0.36775062309597967, time 726.0, rides 119\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 1111, reward 180.0, memory_length 2000, epsilon 0.3674196475351933, time 726.0, rides 131\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 1112, reward 595.0, memory_length 2000, epsilon 0.36708896985241163, time 723.0, rides 116\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 1113, reward 711.0, memory_length 2000, epsilon 0.36675858977954445, time 724.0, rides 133\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 1114, reward 157.0, memory_length 2000, epsilon 0.36642850704874286, time 727.0, rides 123\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 1115, reward 70.0, memory_length 2000, epsilon 0.36609872139239896, time 735.0, rides 128\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 1116, reward 474.0, memory_length 2000, epsilon 0.3657692325431458, time 725.0, rides 131\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 1117, reward 500.0, memory_length 2000, epsilon 0.36544004023385696, time 727.0, rides 136\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 1118, reward 374.0, memory_length 2000, epsilon 0.36511114419764645, time 733.0, rides 124\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 1119, reward 598.0, memory_length 2000, epsilon 0.3647825441678686, time 724.0, rides 121\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1120, reward 385.0, memory_length 2000, epsilon 0.3644542398781175, time 726.0, rides 128\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 1121, reward 427.0, memory_length 2000, epsilon 0.3641262310622272, time 730.0, rides 127\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 1122, reward 352.0, memory_length 2000, epsilon 0.36379851745427116, time 727.0, rides 139\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 1123, reward 489.0, memory_length 2000, epsilon 0.3634710987885623, time 728.0, rides 139\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1124, reward 542.0, memory_length 2000, epsilon 0.3631439747996526, time 736.0, rides 132\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1125, reward 265.0, memory_length 2000, epsilon 0.36281714522233294, time 727.0, rides 138\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 1126, reward 309.0, memory_length 2000, epsilon 0.36249060979163283, time 726.0, rides 140\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 1127, reward 428.0, memory_length 2000, epsilon 0.36216436824282033, time 729.0, rides 123\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 1128, reward 474.0, memory_length 2000, epsilon 0.3618384203114018, time 733.0, rides 139\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 1129, reward 526.0, memory_length 2000, epsilon 0.3615127657331215, time 731.0, rides 125\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 1130, reward 536.0, memory_length 2000, epsilon 0.36118740424396173, time 733.0, rides 140\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1131, reward 94.0, memory_length 2000, epsilon 0.36086233558014214, time 722.0, rides 130\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 1132, reward 341.0, memory_length 2000, epsilon 0.36053755947812, time 733.0, rides 120\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 1133, reward 551.0, memory_length 2000, epsilon 0.36021307567458966, time 725.0, rides 131\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1134, reward 592.0, memory_length 2000, epsilon 0.3598888839064825, time 725.0, rides 146\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 1135, reward 174.0, memory_length 2000, epsilon 0.35956498391096664, time 725.0, rides 118\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 1136, reward 317.0, memory_length 2000, epsilon 0.35924137542544676, time 722.0, rides 135\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 1137, reward 593.0, memory_length 2000, epsilon 0.35891805818756384, time 728.0, rides 141\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 1138, reward 324.0, memory_length 2000, epsilon 0.35859503193519504, time 729.0, rides 149\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 1139, reward 265.0, memory_length 2000, epsilon 0.35827229640645336, time 730.0, rides 135\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 1140, reward 388.0, memory_length 2000, epsilon 0.35794985133968754, time 727.0, rides 124\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 1141, reward 498.0, memory_length 2000, epsilon 0.3576276964734818, time 724.0, rides 125\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 1142, reward 578.0, memory_length 2000, epsilon 0.3573058315466557, time 737.0, rides 122\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 1143, reward 182.0, memory_length 2000, epsilon 0.3569842562982637, time 732.0, rides 123\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 1144, reward 382.0, memory_length 2000, epsilon 0.35666297046759526, time 726.0, rides 126\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 1145, reward 231.0, memory_length 2000, epsilon 0.3563419737941744, time 732.0, rides 123\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 1146, reward 351.0, memory_length 2000, epsilon 0.3560212660177597, time 733.0, rides 132\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 1147, reward 580.0, memory_length 2000, epsilon 0.3557008468783437, time 734.0, rides 135\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 1148, reward 614.0, memory_length 2000, epsilon 0.3553807161161532, time 733.0, rides 131\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 1149, reward 526.0, memory_length 2000, epsilon 0.35506087347164866, time 724.0, rides 141\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 1150, reward 539.0, memory_length 2000, epsilon 0.35474131868552417, time 730.0, rides 131\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1151, reward 498.0, memory_length 2000, epsilon 0.3544220514987072, time 733.0, rides 134\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 1152, reward 159.0, memory_length 2000, epsilon 0.3541030716523584, time 727.0, rides 130\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 1153, reward 616.0, memory_length 2000, epsilon 0.35378437888787123, time 739.0, rides 126\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 1154, reward 461.0, memory_length 2000, epsilon 0.35346597294687215, time 733.0, rides 127\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1155, reward 214.0, memory_length 2000, epsilon 0.35314785357121997, time 738.0, rides 126\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 1156, reward 368.0, memory_length 2000, epsilon 0.3528300205030059, time 730.0, rides 125\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1157, reward 254.0, memory_length 2000, epsilon 0.35251247348455317, time 730.0, rides 120\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1158, reward 199.0, memory_length 2000, epsilon 0.35219521225841705, time 725.0, rides 119\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 1159, reward 680.0, memory_length 2000, epsilon 0.3518782365673845, time 733.0, rides 131\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 1160, reward 199.0, memory_length 2000, epsilon 0.3515615461544738, time 725.0, rides 117\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 1161, reward 197.0, memory_length 2000, epsilon 0.3512451407629348, time 723.0, rides 121\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 1162, reward 477.0, memory_length 2000, epsilon 0.35092902013624816, time 727.0, rides 122\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 1163, reward 314.0, memory_length 2000, epsilon 0.3506131840181255, time 730.0, rides 130\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1164, reward 481.0, memory_length 2000, epsilon 0.3502976321525092, time 726.0, rides 125\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 1165, reward 638.0, memory_length 2000, epsilon 0.34998236428357193, time 725.0, rides 122\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 1166, reward 222.0, memory_length 2000, epsilon 0.3496673801557167, time 724.0, rides 130\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 1167, reward 64.0, memory_length 2000, epsilon 0.3493526795135765, time 726.0, rides 125\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 1168, reward 612.0, memory_length 2000, epsilon 0.3490382621020143, time 724.0, rides 129\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 1169, reward 543.0, memory_length 2000, epsilon 0.34872412766612243, time 726.0, rides 124\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1170, reward 633.0, memory_length 2000, epsilon 0.3484102759512229, time 730.0, rides 121\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 1171, reward 378.0, memory_length 2000, epsilon 0.3480967067028668, time 729.0, rides 123\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 1172, reward 355.0, memory_length 2000, epsilon 0.34778341966683424, time 723.0, rides 123\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 1173, reward 404.0, memory_length 2000, epsilon 0.3474704145891341, time 729.0, rides 136\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 1174, reward 590.0, memory_length 2000, epsilon 0.34715769121600387, time 720.0, rides 116\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 1175, reward 593.0, memory_length 2000, epsilon 0.3468452492939095, time 729.0, rides 126\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 1176, reward 158.0, memory_length 2000, epsilon 0.34653308856954496, time 723.0, rides 112\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 1177, reward 450.0, memory_length 2000, epsilon 0.34622120878983237, time 734.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1178, reward 176.0, memory_length 2000, epsilon 0.3459096097019215, time 728.0, rides 124\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 1179, reward 568.0, memory_length 2000, epsilon 0.3455982910531898, time 728.0, rides 128\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 1180, reward 469.0, memory_length 2000, epsilon 0.34528725259124193, time 729.0, rides 118\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 1181, reward 547.0, memory_length 2000, epsilon 0.3449764940639098, time 723.0, rides 115\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 1182, reward 626.0, memory_length 2000, epsilon 0.3446660152192523, time 730.0, rides 117\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 1183, reward 131.0, memory_length 2000, epsilon 0.34435581580555497, time 727.0, rides 114\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 1184, reward 346.0, memory_length 2000, epsilon 0.34404589557133, time 740.0, rides 124\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 1185, reward 280.0, memory_length 2000, epsilon 0.3437362542653158, time 732.0, rides 115\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 1186, reward 416.0, memory_length 2000, epsilon 0.343426891636477, time 725.0, rides 112\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 1187, reward 365.0, memory_length 2000, epsilon 0.34311780743400416, time 725.0, rides 120\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 1188, reward 620.0, memory_length 2000, epsilon 0.3428090014073136, time 727.0, rides 136\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 1189, reward 533.0, memory_length 2000, epsilon 0.342500473306047, time 734.0, rides 119\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 1190, reward 114.0, memory_length 2000, epsilon 0.34219222288007156, time 737.0, rides 127\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 1191, reward 337.0, memory_length 2000, epsilon 0.3418842498794795, time 726.0, rides 134\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 1192, reward 548.0, memory_length 2000, epsilon 0.341576554054588, time 726.0, rides 139\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 1193, reward 659.0, memory_length 2000, epsilon 0.3412691351559388, time 729.0, rides 135\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 1194, reward 727.0, memory_length 2000, epsilon 0.34096199293429846, time 734.0, rides 136\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 1195, reward 392.0, memory_length 2000, epsilon 0.3406551271406576, time 725.0, rides 125\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1196, reward 4.0, memory_length 2000, epsilon 0.340348537526231, time 728.0, rides 121\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 1197, reward 592.0, memory_length 2000, epsilon 0.3400422238424574, time 726.0, rides 118\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 1198, reward 595.0, memory_length 2000, epsilon 0.3397361858409992, time 737.0, rides 141\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 1199, reward 193.0, memory_length 2000, epsilon 0.3394304232737423, time 739.0, rides 133\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 1200, reward 405.0, memory_length 2000, epsilon 0.3391249358927959, time 726.0, rides 123\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1201, reward 306.0, memory_length 2000, epsilon 0.3388197234504924, time 733.0, rides 135\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 1202, reward 394.0, memory_length 2000, epsilon 0.3385147856993869, time 727.0, rides 137\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 1203, reward 477.0, memory_length 2000, epsilon 0.33821012239225745, time 730.0, rides 137\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 1204, reward 576.0, memory_length 2000, epsilon 0.33790573328210444, time 723.0, rides 131\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 1205, reward 586.0, memory_length 2000, epsilon 0.33760161812215056, time 731.0, rides 139\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1206, reward 632.0, memory_length 2000, epsilon 0.3372977766658406, time 737.0, rides 142\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 1207, reward 321.0, memory_length 2000, epsilon 0.3369942086668413, time 730.0, rides 120\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 1208, reward 258.0, memory_length 2000, epsilon 0.33669091387904115, time 730.0, rides 136\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 1209, reward 325.0, memory_length 2000, epsilon 0.33638789205655, time 727.0, rides 124\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 1210, reward 666.0, memory_length 2000, epsilon 0.3360851429536991, time 722.0, rides 134\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 1211, reward 409.0, memory_length 2000, epsilon 0.3357826663250408, time 733.0, rides 129\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 1212, reward 630.0, memory_length 2000, epsilon 0.33548046192534825, time 731.0, rides 140\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 1213, reward 497.0, memory_length 2000, epsilon 0.3351785295096154, time 732.0, rides 141\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1214, reward 596.0, memory_length 2000, epsilon 0.33487686883305673, time 725.0, rides 139\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 1215, reward 486.0, memory_length 2000, epsilon 0.33457547965110696, time 727.0, rides 132\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 1216, reward 361.0, memory_length 2000, epsilon 0.33427436171942093, time 728.0, rides 143\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 1217, reward 399.0, memory_length 2000, epsilon 0.33397351479387344, time 724.0, rides 138\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 1218, reward 299.0, memory_length 2000, epsilon 0.33367293863055897, time 728.0, rides 148\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 1219, reward 486.0, memory_length 2000, epsilon 0.33337263298579145, time 729.0, rides 129\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 1220, reward 606.0, memory_length 2000, epsilon 0.33307259761610425, time 729.0, rides 125\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 1221, reward 442.0, memory_length 2000, epsilon 0.3327728322782498, time 726.0, rides 133\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 1222, reward 267.0, memory_length 2000, epsilon 0.3324733367291993, time 728.0, rides 126\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 1223, reward 395.0, memory_length 2000, epsilon 0.33217411072614306, time 728.0, rides 118\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 1224, reward 417.0, memory_length 2000, epsilon 0.33187515402648954, time 730.0, rides 141\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 1225, reward 719.0, memory_length 2000, epsilon 0.3315764663878657, time 728.0, rides 130\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 1226, reward 301.0, memory_length 2000, epsilon 0.33127804756811663, time 726.0, rides 126\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 1227, reward 384.0, memory_length 2000, epsilon 0.3309798973253053, time 731.0, rides 125\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 1228, reward 443.0, memory_length 2000, epsilon 0.3306820154177125, time 733.0, rides 137\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 1229, reward 222.0, memory_length 2000, epsilon 0.3303844016038366, time 725.0, rides 138\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 1230, reward 479.0, memory_length 2000, epsilon 0.33008705564239316, time 728.0, rides 128\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 1231, reward 598.0, memory_length 2000, epsilon 0.329789977292315, time 731.0, rides 136\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 1232, reward 535.0, memory_length 2000, epsilon 0.32949316631275194, time 727.0, rides 130\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 1233, reward 590.0, memory_length 2000, epsilon 0.32919662246307047, time 741.0, rides 152\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 1234, reward 338.0, memory_length 2000, epsilon 0.3289003455028537, time 729.0, rides 131\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 1235, reward 597.0, memory_length 2000, epsilon 0.32860433519190113, time 733.0, rides 139\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 1236, reward 456.0, memory_length 2000, epsilon 0.32830859129022844, time 725.0, rides 130\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 1237, reward 358.0, memory_length 2000, epsilon 0.3280131135580672, time 737.0, rides 125\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 1238, reward 524.0, memory_length 2000, epsilon 0.32771790175586496, time 733.0, rides 135\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 1239, reward 428.0, memory_length 2000, epsilon 0.3274229556442847, time 722.0, rides 128\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 1240, reward 605.0, memory_length 2000, epsilon 0.3271282749842048, time 724.0, rides 135\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 1241, reward 416.0, memory_length 2000, epsilon 0.32683385953671906, time 728.0, rides 130\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 1242, reward 566.0, memory_length 2000, epsilon 0.326539709063136, time 728.0, rides 137\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 1243, reward 712.0, memory_length 2000, epsilon 0.3262458233249792, time 731.0, rides 124\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 1244, reward 441.0, memory_length 2000, epsilon 0.32595220208398673, time 728.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 1245, reward 569.0, memory_length 2000, epsilon 0.3256588451021111, time 731.0, rides 128\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1246, reward 305.0, memory_length 2000, epsilon 0.32536575214151925, time 721.0, rides 121\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 1247, reward 377.0, memory_length 2000, epsilon 0.3250729229645919, time 732.0, rides 131\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 1248, reward 200.0, memory_length 2000, epsilon 0.32478035733392374, time 724.0, rides 134\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1249, reward 372.0, memory_length 2000, epsilon 0.3244880550123232, time 729.0, rides 131\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 1250, reward 347.0, memory_length 2000, epsilon 0.3241960157628121, time 731.0, rides 131\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 1251, reward 490.0, memory_length 2000, epsilon 0.32390423934862556, time 724.0, rides 118\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1252, reward 370.0, memory_length 2000, epsilon 0.3236127255332118, time 737.0, rides 131\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 1253, reward 406.0, memory_length 2000, epsilon 0.32332147408023193, time 734.0, rides 128\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 1254, reward 761.0, memory_length 2000, epsilon 0.3230304847535597, time 731.0, rides 135\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 1255, reward 582.0, memory_length 2000, epsilon 0.3227397573172815, time 728.0, rides 130\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 1256, reward 488.0, memory_length 2000, epsilon 0.32244929153569596, time 725.0, rides 141\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 1257, reward 609.0, memory_length 2000, epsilon 0.3221590871733138, time 737.0, rides 124\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 1258, reward 654.0, memory_length 2000, epsilon 0.32186914399485783, time 737.0, rides 131\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1259, reward 132.0, memory_length 2000, epsilon 0.3215794617652625, time 730.0, rides 137\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 1260, reward 367.0, memory_length 2000, epsilon 0.3212900402496737, time 728.0, rides 123\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 1261, reward 484.0, memory_length 2000, epsilon 0.321000879213449, time 727.0, rides 131\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 1262, reward 518.0, memory_length 2000, epsilon 0.3207119784221569, time 731.0, rides 126\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1263, reward 411.0, memory_length 2000, epsilon 0.32042333764157693, time 727.0, rides 128\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 1264, reward 607.0, memory_length 2000, epsilon 0.32013495663769953, time 729.0, rides 143\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 1265, reward 448.0, memory_length 2000, epsilon 0.3198468351767256, time 729.0, rides 134\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1266, reward 724.0, memory_length 2000, epsilon 0.31955897302506653, time 728.0, rides 124\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 1267, reward 470.0, memory_length 2000, epsilon 0.31927136994934396, time 723.0, rides 128\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 1268, reward 253.0, memory_length 2000, epsilon 0.31898402571638956, time 730.0, rides 128\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 1269, reward 325.0, memory_length 2000, epsilon 0.3186969400932448, time 724.0, rides 126\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 1270, reward 297.0, memory_length 2000, epsilon 0.31841011284716086, time 733.0, rides 125\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 1271, reward 287.0, memory_length 2000, epsilon 0.3181235437455984, time 733.0, rides 131\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 1272, reward 370.0, memory_length 2000, epsilon 0.31783723255622737, time 744.0, rides 126\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 1273, reward 607.0, memory_length 2000, epsilon 0.31755117904692676, time 725.0, rides 137\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 1274, reward 546.0, memory_length 2000, epsilon 0.3172653829857845, time 725.0, rides 130\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 1275, reward 391.0, memory_length 2000, epsilon 0.3169798441410973, time 724.0, rides 132\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1276, reward 452.0, memory_length 2000, epsilon 0.31669456228137033, time 727.0, rides 126\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 1277, reward 728.0, memory_length 2000, epsilon 0.3164095371753171, time 725.0, rides 130\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 1278, reward 274.0, memory_length 2000, epsilon 0.31612476859185934, time 727.0, rides 123\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 1279, reward 120.0, memory_length 2000, epsilon 0.3158402563001267, time 738.0, rides 131\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 1280, reward 658.0, memory_length 2000, epsilon 0.31555600006945655, time 726.0, rides 127\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 1281, reward 376.0, memory_length 2000, epsilon 0.31527199966939407, time 728.0, rides 125\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 1282, reward 347.0, memory_length 2000, epsilon 0.3149882548696916, time 723.0, rides 130\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 1283, reward 539.0, memory_length 2000, epsilon 0.3147047654403089, time 731.0, rides 141\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1284, reward 370.0, memory_length 2000, epsilon 0.31442153115141264, time 731.0, rides 122\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 1285, reward 415.0, memory_length 2000, epsilon 0.31413855177337635, time 730.0, rides 120\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1286, reward 565.0, memory_length 2000, epsilon 0.31385582707678034, time 731.0, rides 142\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 1287, reward 639.0, memory_length 2000, epsilon 0.3135733568324112, time 729.0, rides 128\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 1288, reward 354.0, memory_length 2000, epsilon 0.313291140811262, time 722.0, rides 130\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 1289, reward 627.0, memory_length 2000, epsilon 0.3130091787845319, time 726.0, rides 125\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 1290, reward 584.0, memory_length 2000, epsilon 0.3127274705236258, time 733.0, rides 117\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 1291, reward 119.0, memory_length 2000, epsilon 0.3124460158001546, time 729.0, rides 135\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 1292, reward 551.0, memory_length 2000, epsilon 0.3121648143859344, time 728.0, rides 121\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1293, reward 481.0, memory_length 2000, epsilon 0.31188386605298707, time 724.0, rides 136\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 1294, reward 458.0, memory_length 2000, epsilon 0.31160317057353937, time 729.0, rides 108\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 1295, reward 361.0, memory_length 2000, epsilon 0.3113227277200232, time 732.0, rides 132\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 1296, reward 89.0, memory_length 2000, epsilon 0.31104253726507514, time 726.0, rides 123\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1297, reward 562.0, memory_length 2000, epsilon 0.3107625989815366, time 728.0, rides 128\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1298, reward 40.0, memory_length 2000, epsilon 0.3104829126424532, time 733.0, rides 130\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 1299, reward 253.0, memory_length 2000, epsilon 0.310203478021075, time 741.0, rides 122\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1300, reward 562.0, memory_length 2000, epsilon 0.30992429489085604, time 727.0, rides 137\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 1301, reward 549.0, memory_length 2000, epsilon 0.30964536302545426, time 741.0, rides 129\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 1302, reward 329.0, memory_length 2000, epsilon 0.30936668219873137, time 726.0, rides 124\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 1303, reward 249.0, memory_length 2000, epsilon 0.3090882521847525, time 733.0, rides 138\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1304, reward 452.0, memory_length 2000, epsilon 0.3088100727577862, time 735.0, rides 139\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 1305, reward 375.0, memory_length 2000, epsilon 0.3085321436923042, time 729.0, rides 126\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1306, reward 486.0, memory_length 2000, epsilon 0.30825446476298113, time 734.0, rides 127\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 1307, reward 219.0, memory_length 2000, epsilon 0.3079770357446944, time 723.0, rides 128\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 1308, reward 502.0, memory_length 2000, epsilon 0.3076998564125242, time 730.0, rides 121\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 1309, reward 321.0, memory_length 2000, epsilon 0.3074229265417529, time 737.0, rides 117\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 1310, reward 437.0, memory_length 2000, epsilon 0.3071462459078653, time 721.0, rides 132\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1311, reward 534.0, memory_length 2000, epsilon 0.30686981428654825, time 733.0, rides 121\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 1312, reward 659.0, memory_length 2000, epsilon 0.30659363145369034, time 732.0, rides 128\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1313, reward 542.0, memory_length 2000, epsilon 0.30631769718538204, time 739.0, rides 137\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 1314, reward 686.0, memory_length 2000, epsilon 0.3060420112579152, time 723.0, rides 140\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 1315, reward 460.0, memory_length 2000, epsilon 0.3057665734477831, time 734.0, rides 126\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 1316, reward 492.0, memory_length 2000, epsilon 0.30549138353168004, time 730.0, rides 115\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 1317, reward 399.0, memory_length 2000, epsilon 0.30521644128650155, time 730.0, rides 127\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 1318, reward 306.0, memory_length 2000, epsilon 0.3049417464893437, time 728.0, rides 143\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1319, reward 395.0, memory_length 2000, epsilon 0.30466729891750327, time 726.0, rides 130\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 1320, reward 546.0, memory_length 2000, epsilon 0.3043930983484775, time 729.0, rides 135\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 1321, reward 603.0, memory_length 2000, epsilon 0.30411914455996386, time 736.0, rides 130\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 1322, reward 528.0, memory_length 2000, epsilon 0.3038454373298599, time 722.0, rides 127\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 1323, reward 515.0, memory_length 2000, epsilon 0.30357197643626305, time 723.0, rides 131\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 1324, reward 611.0, memory_length 2000, epsilon 0.3032987616574704, time 731.0, rides 129\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1325, reward 549.0, memory_length 2000, epsilon 0.30302579277197866, time 730.0, rides 131\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 1326, reward 811.0, memory_length 2000, epsilon 0.30275306955848386, time 730.0, rides 120\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 1327, reward 483.0, memory_length 2000, epsilon 0.3024805917958812, time 727.0, rides 120\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 1328, reward 312.0, memory_length 2000, epsilon 0.3022083592632649, time 736.0, rides 133\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1329, reward 438.0, memory_length 2000, epsilon 0.30193637173992793, time 732.0, rides 131\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1330, reward 779.0, memory_length 2000, epsilon 0.301664629005362, time 732.0, rides 120\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 1331, reward 744.0, memory_length 2000, epsilon 0.3013931308392572, time 722.0, rides 130\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 1332, reward 616.0, memory_length 2000, epsilon 0.30112187702150184, time 729.0, rides 141\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 1333, reward 394.0, memory_length 2000, epsilon 0.30085086733218247, time 732.0, rides 130\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1334, reward 273.0, memory_length 2000, epsilon 0.3005801015515835, time 728.0, rides 125\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 1335, reward 456.0, memory_length 2000, epsilon 0.30030957946018705, time 728.0, rides 132\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 1336, reward 617.0, memory_length 2000, epsilon 0.30003930083867286, time 730.0, rides 125\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 1337, reward 634.0, memory_length 2000, epsilon 0.29976926546791804, time 730.0, rides 134\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 1338, reward 323.0, memory_length 2000, epsilon 0.29949947312899694, time 736.0, rides 133\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1339, reward 633.0, memory_length 2000, epsilon 0.29922992360318085, time 723.0, rides 130\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 1340, reward 620.0, memory_length 2000, epsilon 0.29896061667193796, time 726.0, rides 136\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 1341, reward 599.0, memory_length 2000, epsilon 0.2986915521169332, time 734.0, rides 139\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 1342, reward 195.0, memory_length 2000, epsilon 0.298422729720028, time 732.0, rides 122\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 1343, reward 365.0, memory_length 2000, epsilon 0.29815414926327993, time 725.0, rides 128\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 1344, reward 756.0, memory_length 2000, epsilon 0.297885810528943, time 734.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1345, reward 568.0, memory_length 2000, epsilon 0.2976177132994669, time 732.0, rides 135\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 1346, reward 440.0, memory_length 2000, epsilon 0.29734985735749736, time 734.0, rides 120\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 1347, reward 275.0, memory_length 2000, epsilon 0.2970822424858756, time 729.0, rides 130\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 1348, reward 549.0, memory_length 2000, epsilon 0.2968148684676383, time 726.0, rides 128\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1349, reward 528.0, memory_length 2000, epsilon 0.29654773508601745, time 732.0, rides 128\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 1350, reward 430.0, memory_length 2000, epsilon 0.29628084212444006, time 725.0, rides 122\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 1351, reward 644.0, memory_length 2000, epsilon 0.29601418936652807, time 737.0, rides 141\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1352, reward 629.0, memory_length 2000, epsilon 0.2957477765960982, time 733.0, rides 117\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 1353, reward 553.0, memory_length 2000, epsilon 0.2954816035971617, time 725.0, rides 130\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 1354, reward 388.0, memory_length 2000, epsilon 0.29521567015392425, time 723.0, rides 130\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 1355, reward 740.0, memory_length 2000, epsilon 0.2949499760507857, time 727.0, rides 127\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 1356, reward 452.0, memory_length 2000, epsilon 0.29468452107234, time 729.0, rides 136\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1357, reward 271.0, memory_length 2000, epsilon 0.2944193050033749, time 722.0, rides 122\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 1358, reward 485.0, memory_length 2000, epsilon 0.29415432762887184, time 731.0, rides 132\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 1359, reward 520.0, memory_length 2000, epsilon 0.29388958873400584, time 727.0, rides 128\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 1360, reward 616.0, memory_length 2000, epsilon 0.2936250881041452, time 733.0, rides 136\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 1361, reward 307.0, memory_length 2000, epsilon 0.2933608255248515, time 730.0, rides 121\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 1362, reward 632.0, memory_length 2000, epsilon 0.2930968007818791, time 729.0, rides 120\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 1363, reward 572.0, memory_length 2000, epsilon 0.2928330136611754, time 726.0, rides 121\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 1364, reward 488.0, memory_length 2000, epsilon 0.29256946394888034, time 733.0, rides 123\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 1365, reward 468.0, memory_length 2000, epsilon 0.2923061514313263, time 726.0, rides 135\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1366, reward 499.0, memory_length 2000, epsilon 0.29204307589503814, time 726.0, rides 137\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 1367, reward 548.0, memory_length 2000, epsilon 0.2917802371267326, time 725.0, rides 132\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 1368, reward 556.0, memory_length 2000, epsilon 0.29151763491331856, time 720.0, rides 121\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1369, reward 359.0, memory_length 2000, epsilon 0.2912552690418966, time 728.0, rides 143\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1370, reward 675.0, memory_length 2000, epsilon 0.2909931392997589, time 735.0, rides 129\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1371, reward 394.0, memory_length 2000, epsilon 0.2907312454743891, time 732.0, rides 132\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 1372, reward 483.0, memory_length 2000, epsilon 0.2904695873534622, time 722.0, rides 124\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 1373, reward 145.0, memory_length 2000, epsilon 0.29020816472484406, time 724.0, rides 123\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 1374, reward 572.0, memory_length 2000, epsilon 0.2899469773765917, time 733.0, rides 129\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 1375, reward 409.0, memory_length 2000, epsilon 0.28968602509695274, time 729.0, rides 129\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 1376, reward 464.0, memory_length 2000, epsilon 0.2894253076743655, time 734.0, rides 120\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 1377, reward 527.0, memory_length 2000, epsilon 0.28916482489745854, time 726.0, rides 122\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 1378, reward 703.0, memory_length 2000, epsilon 0.2889045765550508, time 734.0, rides 125\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 1379, reward 844.0, memory_length 2000, epsilon 0.2886445624361513, time 728.0, rides 126\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 1380, reward 595.0, memory_length 2000, epsilon 0.28838478232995873, time 723.0, rides 130\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 1381, reward 421.0, memory_length 2000, epsilon 0.28812523602586176, time 734.0, rides 138\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 1382, reward 354.0, memory_length 2000, epsilon 0.28786592331343847, time 743.0, rides 124\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 1383, reward 687.0, memory_length 2000, epsilon 0.2876068439824564, time 730.0, rides 119\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1384, reward 470.0, memory_length 2000, epsilon 0.2873479978228722, time 726.0, rides 127\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1385, reward 657.0, memory_length 2000, epsilon 0.2870893846248316, time 724.0, rides 117\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 1386, reward 663.0, memory_length 2000, epsilon 0.28683100417866925, time 735.0, rides 135\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1387, reward 520.0, memory_length 2000, epsilon 0.2865728562749084, time 730.0, rides 128\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 1388, reward 467.0, memory_length 2000, epsilon 0.286314940704261, time 735.0, rides 122\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 1389, reward 705.0, memory_length 2000, epsilon 0.28605725725762715, time 728.0, rides 137\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 1390, reward 339.0, memory_length 2000, epsilon 0.28579980572609526, time 734.0, rides 136\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 1391, reward 629.0, memory_length 2000, epsilon 0.2855425859009418, time 733.0, rides 133\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 1392, reward 343.0, memory_length 2000, epsilon 0.2852855975736309, time 725.0, rides 137\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 1393, reward 470.0, memory_length 2000, epsilon 0.2850288405358147, time 723.0, rides 123\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1394, reward 560.0, memory_length 2000, epsilon 0.28477231457933244, time 731.0, rides 123\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 1395, reward 428.0, memory_length 2000, epsilon 0.284516019496211, time 724.0, rides 126\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 1396, reward 620.0, memory_length 2000, epsilon 0.2842599550786644, time 722.0, rides 132\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 1397, reward 769.0, memory_length 2000, epsilon 0.2840041211190936, time 727.0, rides 128\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 1398, reward 206.0, memory_length 2000, epsilon 0.28374851741008644, time 728.0, rides 140\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 1399, reward 294.0, memory_length 2000, epsilon 0.28349314374441736, time 736.0, rides 138\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 1400, reward 670.0, memory_length 2000, epsilon 0.2832379999150474, time 725.0, rides 139\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 1401, reward 877.0, memory_length 2000, epsilon 0.2829830857151238, time 739.0, rides 137\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 1402, reward 762.0, memory_length 2000, epsilon 0.2827284009379802, time 724.0, rides 123\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 1403, reward 787.0, memory_length 2000, epsilon 0.282473945377136, time 729.0, rides 128\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 1404, reward 315.0, memory_length 2000, epsilon 0.2822197188262966, time 731.0, rides 118\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 1405, reward 493.0, memory_length 2000, epsilon 0.2819657210793529, time 725.0, rides 127\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 1406, reward 681.0, memory_length 2000, epsilon 0.2817119519303815, time 732.0, rides 132\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 1407, reward 404.0, memory_length 2000, epsilon 0.2814584111736442, time 731.0, rides 120\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 1408, reward 484.0, memory_length 2000, epsilon 0.2812050986035879, time 726.0, rides 138\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 1409, reward 431.0, memory_length 2000, epsilon 0.28095201401484465, time 725.0, rides 146\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 1410, reward 305.0, memory_length 2000, epsilon 0.28069915720223126, time 731.0, rides 131\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 1411, reward 527.0, memory_length 2000, epsilon 0.28044652796074926, time 735.0, rides 109\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 1412, reward 443.0, memory_length 2000, epsilon 0.2801941260855846, time 731.0, rides 135\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1413, reward 482.0, memory_length 2000, epsilon 0.27994195137210753, time 721.0, rides 117\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 1414, reward 400.0, memory_length 2000, epsilon 0.27969000361587265, time 731.0, rides 132\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 1415, reward 423.0, memory_length 2000, epsilon 0.2794382826126184, time 727.0, rides 129\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 1416, reward 614.0, memory_length 2000, epsilon 0.27918678815826703, time 726.0, rides 127\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 1417, reward 457.0, memory_length 2000, epsilon 0.2789355200489246, time 731.0, rides 126\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 1418, reward 497.0, memory_length 2000, epsilon 0.27868447808088054, time 733.0, rides 134\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 1419, reward 519.0, memory_length 2000, epsilon 0.27843366205060777, time 731.0, rides 117\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1420, reward 504.0, memory_length 2000, epsilon 0.2781830717547622, time 729.0, rides 128\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1421, reward 323.0, memory_length 2000, epsilon 0.2779327069901829, time 737.0, rides 125\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 1422, reward 718.0, memory_length 2000, epsilon 0.27768256755389176, time 739.0, rides 132\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 1423, reward 508.0, memory_length 2000, epsilon 0.27743265324309324, time 734.0, rides 122\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 1424, reward 381.0, memory_length 2000, epsilon 0.27718296385517444, time 726.0, rides 130\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 1425, reward 417.0, memory_length 2000, epsilon 0.27693349918770477, time 734.0, rides 127\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1426, reward 628.0, memory_length 2000, epsilon 0.27668425903843585, time 725.0, rides 142\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 1427, reward 471.0, memory_length 2000, epsilon 0.2764352432053013, time 731.0, rides 140\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 1428, reward 397.0, memory_length 2000, epsilon 0.2761864514864165, time 730.0, rides 135\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 1429, reward 662.0, memory_length 2000, epsilon 0.27593788368007877, time 729.0, rides 145\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 1430, reward 233.0, memory_length 2000, epsilon 0.2756895395847667, time 723.0, rides 140\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 1431, reward 408.0, memory_length 2000, epsilon 0.27544141899914043, time 729.0, rides 127\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 1432, reward 516.0, memory_length 2000, epsilon 0.2751935217220412, time 727.0, rides 128\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 1433, reward 344.0, memory_length 2000, epsilon 0.27494584755249135, time 724.0, rides 133\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 1434, reward 381.0, memory_length 2000, epsilon 0.2746983962896941, time 732.0, rides 134\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 1435, reward 583.0, memory_length 2000, epsilon 0.2744511677330334, time 729.0, rides 129\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 1436, reward 457.0, memory_length 2000, epsilon 0.2742041616820737, time 729.0, rides 151\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 1437, reward 146.0, memory_length 2000, epsilon 0.27395737793655983, time 735.0, rides 120\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 1438, reward 553.0, memory_length 2000, epsilon 0.2737108162964169, time 731.0, rides 142\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 1439, reward 660.0, memory_length 2000, epsilon 0.27346447656175016, time 727.0, rides 134\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 1440, reward 405.0, memory_length 2000, epsilon 0.2732183585328446, time 724.0, rides 134\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1441, reward 449.0, memory_length 2000, epsilon 0.272972462010165, time 725.0, rides 125\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 1442, reward 768.0, memory_length 2000, epsilon 0.27272678679435586, time 725.0, rides 134\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 1443, reward 118.0, memory_length 2000, epsilon 0.2724813326862409, time 731.0, rides 127\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 1444, reward 707.0, memory_length 2000, epsilon 0.2722360994868233, time 735.0, rides 131\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 1445, reward 560.0, memory_length 2000, epsilon 0.2719910869972852, time 721.0, rides 142\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 1446, reward 617.0, memory_length 2000, epsilon 0.2717462950189876, time 731.0, rides 135\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 1447, reward 73.0, memory_length 2000, epsilon 0.2715017233534705, time 746.0, rides 127\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 1448, reward 539.0, memory_length 2000, epsilon 0.27125737180245235, time 722.0, rides 130\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 1449, reward 489.0, memory_length 2000, epsilon 0.2710132401678301, time 727.0, rides 125\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 1450, reward 606.0, memory_length 2000, epsilon 0.2707693282516791, time 730.0, rides 131\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 1451, reward 472.0, memory_length 2000, epsilon 0.2705256358562526, time 731.0, rides 135\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 1452, reward 351.0, memory_length 2000, epsilon 0.270282162783982, time 725.0, rides 117\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 1453, reward 382.0, memory_length 2000, epsilon 0.2700389088374764, time 731.0, rides 134\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 1454, reward 38.0, memory_length 2000, epsilon 0.26979587381952264, time 729.0, rides 127\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 1455, reward 542.0, memory_length 2000, epsilon 0.26955305753308506, time 730.0, rides 123\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 1456, reward 547.0, memory_length 2000, epsilon 0.2693104597813053, time 726.0, rides 125\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 1457, reward 550.0, memory_length 2000, epsilon 0.2690680803675021, time 734.0, rides 146\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 1458, reward 753.0, memory_length 2000, epsilon 0.2688259190951714, time 728.0, rides 123\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 1459, reward 545.0, memory_length 2000, epsilon 0.26858397576798576, time 724.0, rides 111\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 1460, reward 120.0, memory_length 2000, epsilon 0.2683422501897946, time 731.0, rides 138\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1461, reward 685.0, memory_length 2000, epsilon 0.26810074216462376, time 727.0, rides 135\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 1462, reward 723.0, memory_length 2000, epsilon 0.2678594514966756, time 726.0, rides 136\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 1463, reward 404.0, memory_length 2000, epsilon 0.2676183779903286, time 726.0, rides 123\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1464, reward 559.0, memory_length 2000, epsilon 0.2673775214501373, time 724.0, rides 124\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 1465, reward 223.0, memory_length 2000, epsilon 0.2671368816808322, time 736.0, rides 137\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 1466, reward 798.0, memory_length 2000, epsilon 0.26689645848731947, time 722.0, rides 130\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1467, reward 301.0, memory_length 2000, epsilon 0.2666562516746809, time 737.0, rides 133\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 1468, reward 506.0, memory_length 2000, epsilon 0.2664162610481737, time 731.0, rides 129\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1469, reward 601.0, memory_length 2000, epsilon 0.26617648641323033, time 733.0, rides 131\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 1470, reward 104.0, memory_length 2000, epsilon 0.2659369275754584, time 729.0, rides 141\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 1471, reward 433.0, memory_length 2000, epsilon 0.2656975843406405, time 729.0, rides 123\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1472, reward 200.0, memory_length 2000, epsilon 0.26545845651473393, time 732.0, rides 121\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1473, reward 507.0, memory_length 2000, epsilon 0.26521954390387065, time 727.0, rides 119\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1474, reward 769.0, memory_length 2000, epsilon 0.26498084631435714, time 735.0, rides 147\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 1475, reward 618.0, memory_length 2000, epsilon 0.2647423635526742, time 733.0, rides 124\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 1476, reward 490.0, memory_length 2000, epsilon 0.2645040954254768, time 733.0, rides 123\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 1477, reward 514.0, memory_length 2000, epsilon 0.2642660417395939, time 729.0, rides 139\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 1478, reward 684.0, memory_length 2000, epsilon 0.2640282023020283, time 734.0, rides 125\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1479, reward 874.0, memory_length 2000, epsilon 0.26379057691995644, time 734.0, rides 134\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1480, reward 622.0, memory_length 2000, epsilon 0.2635531654007285, time 736.0, rides 135\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 1481, reward 699.0, memory_length 2000, epsilon 0.2633159675518678, time 734.0, rides 130\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 1482, reward 296.0, memory_length 2000, epsilon 0.26307898318107115, time 729.0, rides 127\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 1483, reward 783.0, memory_length 2000, epsilon 0.26284221209620817, time 732.0, rides 130\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 1484, reward 953.0, memory_length 2000, epsilon 0.2626056541053216, time 737.0, rides 124\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 1485, reward 548.0, memory_length 2000, epsilon 0.2623693090166268, time 727.0, rides 127\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 1486, reward 211.0, memory_length 2000, epsilon 0.2621331766385118, time 733.0, rides 133\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 1487, reward 504.0, memory_length 2000, epsilon 0.2618972567795372, time 724.0, rides 127\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 1488, reward 580.0, memory_length 2000, epsilon 0.2616615492484356, time 727.0, rides 132\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 1489, reward 639.0, memory_length 2000, epsilon 0.261426053854112, time 730.0, rides 119\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 1490, reward 660.0, memory_length 2000, epsilon 0.2611907704056433, time 722.0, rides 128\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 1491, reward 448.0, memory_length 2000, epsilon 0.26095569871227825, time 724.0, rides 122\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 1492, reward 705.0, memory_length 2000, epsilon 0.2607208385834372, time 724.0, rides 131\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 1493, reward 478.0, memory_length 2000, epsilon 0.2604861898287121, time 730.0, rides 120\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 1494, reward 357.0, memory_length 2000, epsilon 0.26025175225786623, time 736.0, rides 123\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1495, reward 339.0, memory_length 2000, epsilon 0.26001752568083414, time 727.0, rides 130\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 1496, reward 510.0, memory_length 2000, epsilon 0.25978350990772137, time 735.0, rides 115\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1497, reward 856.0, memory_length 2000, epsilon 0.2595497047488044, time 735.0, rides 134\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 1498, reward 483.0, memory_length 2000, epsilon 0.2593161100145305, time 730.0, rides 136\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 1499, reward 564.0, memory_length 2000, epsilon 0.2590827255155174, time 734.0, rides 131\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 1500, reward 280.0, memory_length 2000, epsilon 0.2588495510625535, time 726.0, rides 125\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 1501, reward 428.0, memory_length 2000, epsilon 0.2586165864665972, time 723.0, rides 129\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1502, reward 598.0, memory_length 2000, epsilon 0.25838383153877725, time 738.0, rides 129\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 1503, reward 404.0, memory_length 2000, epsilon 0.25815128609039234, time 732.0, rides 130\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1504, reward 598.0, memory_length 2000, epsilon 0.257918949932911, time 727.0, rides 138\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1505, reward 267.0, memory_length 2000, epsilon 0.25768682287797134, time 725.0, rides 127\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 1506, reward 720.0, memory_length 2000, epsilon 0.25745490473738114, time 725.0, rides 134\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 1507, reward 644.0, memory_length 2000, epsilon 0.2572231953231175, time 735.0, rides 135\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 1508, reward 738.0, memory_length 2000, epsilon 0.25699169444732667, time 724.0, rides 132\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 1509, reward 831.0, memory_length 2000, epsilon 0.2567604019223241, time 734.0, rides 144\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 1510, reward 450.0, memory_length 2000, epsilon 0.256529317560594, time 721.0, rides 134\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 1511, reward 713.0, memory_length 2000, epsilon 0.25629844117478945, time 725.0, rides 135\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 1512, reward 256.0, memory_length 2000, epsilon 0.2560677725777321, time 729.0, rides 131\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 1513, reward 259.0, memory_length 2000, epsilon 0.25583731158241213, time 724.0, rides 132\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 1514, reward 671.0, memory_length 2000, epsilon 0.25560705800198796, time 729.0, rides 139\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 1515, reward 672.0, memory_length 2000, epsilon 0.25537701164978616, time 725.0, rides 136\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 1516, reward 467.0, memory_length 2000, epsilon 0.25514717233930134, time 726.0, rides 147\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 1517, reward 576.0, memory_length 2000, epsilon 0.25491753988419596, time 731.0, rides 126\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 1518, reward 623.0, memory_length 2000, epsilon 0.25468811409830017, time 724.0, rides 133\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 1519, reward 429.0, memory_length 2000, epsilon 0.2544588947956117, time 727.0, rides 136\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 1520, reward 424.0, memory_length 2000, epsilon 0.2542298817902956, time 723.0, rides 125\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 1521, reward 409.0, memory_length 2000, epsilon 0.25400107489668433, time 727.0, rides 129\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1522, reward 654.0, memory_length 2000, epsilon 0.2537724739292773, time 729.0, rides 142\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 1523, reward 339.0, memory_length 2000, epsilon 0.253544078702741, time 726.0, rides 120\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 1524, reward 438.0, memory_length 2000, epsilon 0.2533158890319085, time 732.0, rides 127\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 1525, reward 301.0, memory_length 2000, epsilon 0.2530879047317798, time 733.0, rides 137\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 1526, reward 543.0, memory_length 2000, epsilon 0.2528601256175212, time 732.0, rides 117\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 1527, reward 456.0, memory_length 2000, epsilon 0.2526325515044654, time 733.0, rides 122\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 1528, reward 183.0, memory_length 2000, epsilon 0.25240518220811137, time 735.0, rides 133\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1529, reward 325.0, memory_length 2000, epsilon 0.25217801754412406, time 728.0, rides 137\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1530, reward 567.0, memory_length 2000, epsilon 0.25195105732833434, time 728.0, rides 138\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 1531, reward 486.0, memory_length 2000, epsilon 0.25172430137673885, time 725.0, rides 134\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 1532, reward 271.0, memory_length 2000, epsilon 0.2514977495054998, time 727.0, rides 136\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 1533, reward 732.0, memory_length 2000, epsilon 0.25127140153094485, time 722.0, rides 122\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 1534, reward 343.0, memory_length 2000, epsilon 0.251045257269567, time 735.0, rides 145\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 1535, reward 566.0, memory_length 2000, epsilon 0.25081931653802436, time 728.0, rides 131\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 1536, reward 419.0, memory_length 2000, epsilon 0.2505935791531401, time 728.0, rides 119\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 1537, reward 599.0, memory_length 2000, epsilon 0.2503680449319023, time 722.0, rides 120\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 1538, reward 555.0, memory_length 2000, epsilon 0.25014271369146357, time 726.0, rides 135\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 1539, reward 514.0, memory_length 2000, epsilon 0.24991758524914126, time 733.0, rides 130\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 1540, reward 744.0, memory_length 2000, epsilon 0.24969265942241703, time 732.0, rides 129\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 1541, reward 467.0, memory_length 2000, epsilon 0.24946793602893685, time 727.0, rides 121\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 1542, reward 786.0, memory_length 2000, epsilon 0.2492434148865108, time 725.0, rides 129\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 1543, reward 363.0, memory_length 2000, epsilon 0.24901909581311293, time 726.0, rides 129\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 1544, reward 467.0, memory_length 2000, epsilon 0.24879497862688113, time 733.0, rides 130\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 1545, reward 530.0, memory_length 2000, epsilon 0.24857106314611693, time 727.0, rides 135\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 1546, reward 616.0, memory_length 2000, epsilon 0.24834734918928542, time 729.0, rides 131\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 1547, reward 483.0, memory_length 2000, epsilon 0.24812383657501505, time 736.0, rides 126\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 1548, reward 541.0, memory_length 2000, epsilon 0.24790052512209754, time 733.0, rides 123\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 1549, reward 196.0, memory_length 2000, epsilon 0.24767741464948764, time 726.0, rides 128\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 1550, reward 512.0, memory_length 2000, epsilon 0.2474545049763031, time 731.0, rides 138\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 1551, reward 879.0, memory_length 2000, epsilon 0.24723179592182443, time 728.0, rides 123\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 1552, reward 432.0, memory_length 2000, epsilon 0.2470092873054948, time 728.0, rides 125\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1553, reward 751.0, memory_length 2000, epsilon 0.24678697894691984, time 731.0, rides 115\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 1554, reward 943.0, memory_length 2000, epsilon 0.2465648706658676, time 729.0, rides 117\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 1555, reward 424.0, memory_length 2000, epsilon 0.24634296228226832, time 734.0, rides 128\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 1556, reward 410.0, memory_length 2000, epsilon 0.24612125361621429, time 726.0, rides 133\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 1557, reward 496.0, memory_length 2000, epsilon 0.2458997444879597, time 730.0, rides 122\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1558, reward 444.0, memory_length 2000, epsilon 0.24567843471792053, time 731.0, rides 131\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 1559, reward 530.0, memory_length 2000, epsilon 0.2454573241266744, time 729.0, rides 128\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 1560, reward 787.0, memory_length 2000, epsilon 0.2452364125349604, time 721.0, rides 129\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 1561, reward 386.0, memory_length 2000, epsilon 0.24501569976367893, time 725.0, rides 132\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 1562, reward 793.0, memory_length 2000, epsilon 0.2447951856338916, time 729.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1563, reward 773.0, memory_length 2000, epsilon 0.2445748699668211, time 724.0, rides 134\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 1564, reward 479.0, memory_length 2000, epsilon 0.24435475258385095, time 727.0, rides 128\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 1565, reward 427.0, memory_length 2000, epsilon 0.24413483330652547, time 733.0, rides 135\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 1566, reward 270.0, memory_length 2000, epsilon 0.24391511195654958, time 739.0, rides 133\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 1567, reward 696.0, memory_length 2000, epsilon 0.2436955883557887, time 729.0, rides 133\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 1568, reward 451.0, memory_length 2000, epsilon 0.24347626232626848, time 730.0, rides 123\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1569, reward 541.0, memory_length 2000, epsilon 0.24325713369017485, time 738.0, rides 143\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 1570, reward 480.0, memory_length 2000, epsilon 0.24303820226985368, time 726.0, rides 128\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 1571, reward 289.0, memory_length 2000, epsilon 0.2428194678878108, time 736.0, rides 123\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 1572, reward 583.0, memory_length 2000, epsilon 0.24260093036671176, time 734.0, rides 121\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 1573, reward 587.0, memory_length 2000, epsilon 0.24238258952938171, time 729.0, rides 130\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1574, reward 455.0, memory_length 2000, epsilon 0.24216444519880526, time 722.0, rides 132\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 1575, reward 526.0, memory_length 2000, epsilon 0.24194649719812633, time 740.0, rides 120\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 1576, reward 433.0, memory_length 2000, epsilon 0.241728745350648, time 733.0, rides 138\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1577, reward 271.0, memory_length 2000, epsilon 0.2415111894798324, time 740.0, rides 128\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 1578, reward 544.0, memory_length 2000, epsilon 0.24129382940930055, time 734.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 1579, reward 575.0, memory_length 2000, epsilon 0.24107666496283217, time 727.0, rides 140\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 1580, reward 520.0, memory_length 2000, epsilon 0.24085969596436563, time 730.0, rides 125\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 1581, reward 497.0, memory_length 2000, epsilon 0.2406429222379977, time 735.0, rides 123\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 1582, reward 847.0, memory_length 2000, epsilon 0.24042634360798348, time 726.0, rides 130\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 1583, reward 793.0, memory_length 2000, epsilon 0.2402099598987363, time 732.0, rides 149\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 1584, reward 447.0, memory_length 2000, epsilon 0.23999377093482743, time 723.0, rides 145\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 1585, reward 568.0, memory_length 2000, epsilon 0.2397777765409861, time 728.0, rides 139\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 1586, reward 695.0, memory_length 2000, epsilon 0.2395619765420992, time 730.0, rides 137\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 1587, reward 771.0, memory_length 2000, epsilon 0.23934637076321133, time 726.0, rides 131\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 1588, reward 801.0, memory_length 2000, epsilon 0.23913095902952444, time 726.0, rides 141\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1589, reward 700.0, memory_length 2000, epsilon 0.23891574116639785, time 730.0, rides 125\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 1590, reward 640.0, memory_length 2000, epsilon 0.23870071699934808, time 725.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 1591, reward 666.0, memory_length 2000, epsilon 0.23848588635404866, time 730.0, rides 138\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 1592, reward 372.0, memory_length 2000, epsilon 0.23827124905633001, time 733.0, rides 122\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 1593, reward 966.0, memory_length 2000, epsilon 0.23805680493217932, time 727.0, rides 129\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 1594, reward 698.0, memory_length 2000, epsilon 0.23784255380774036, time 736.0, rides 128\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 1595, reward 560.0, memory_length 2000, epsilon 0.2376284955093134, time 723.0, rides 152\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 1596, reward 753.0, memory_length 2000, epsilon 0.23741462986335501, time 726.0, rides 147\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 1597, reward 569.0, memory_length 2000, epsilon 0.237200956696478, time 727.0, rides 128\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 1598, reward 537.0, memory_length 2000, epsilon 0.23698747583545118, time 727.0, rides 123\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 1599, reward 408.0, memory_length 2000, epsilon 0.23677418710719927, time 722.0, rides 129\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 1600, reward 800.0, memory_length 2000, epsilon 0.2365610903388028, time 737.0, rides 127\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1601, reward 583.0, memory_length 2000, epsilon 0.23634818535749788, time 727.0, rides 114\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 1602, reward 404.0, memory_length 2000, epsilon 0.23613547199067614, time 723.0, rides 126\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 1603, reward 278.0, memory_length 2000, epsilon 0.23592295006588454, time 727.0, rides 131\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 1604, reward 493.0, memory_length 2000, epsilon 0.23571061941082525, time 730.0, rides 125\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 1605, reward 718.0, memory_length 2000, epsilon 0.2354984798533555, time 731.0, rides 120\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1606, reward 607.0, memory_length 2000, epsilon 0.2352865312214875, time 730.0, rides 135\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 1607, reward 722.0, memory_length 2000, epsilon 0.23507477334338814, time 736.0, rides 137\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1608, reward 646.0, memory_length 2000, epsilon 0.2348632060473791, time 735.0, rides 120\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 1609, reward 830.0, memory_length 2000, epsilon 0.23465182916193644, time 725.0, rides 129\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 1610, reward 590.0, memory_length 2000, epsilon 0.2344406425156907, time 730.0, rides 146\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 1611, reward 309.0, memory_length 2000, epsilon 0.23422964593742657, time 728.0, rides 124\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 1612, reward 519.0, memory_length 2000, epsilon 0.23401883925608288, time 728.0, rides 137\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 1613, reward 652.0, memory_length 2000, epsilon 0.2338082223007524, time 730.0, rides 138\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 1614, reward 303.0, memory_length 2000, epsilon 0.23359779490068172, time 727.0, rides 119\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 1615, reward 593.0, memory_length 2000, epsilon 0.2333875568852711, time 741.0, rides 136\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 1616, reward 617.0, memory_length 2000, epsilon 0.23317750808407436, time 725.0, rides 131\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 1617, reward 602.0, memory_length 2000, epsilon 0.2329676483267987, time 731.0, rides 127\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 1618, reward 426.0, memory_length 2000, epsilon 0.23275797744330456, time 729.0, rides 134\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 1619, reward 293.0, memory_length 2000, epsilon 0.23254849526360558, time 733.0, rides 125\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1620, reward 739.0, memory_length 2000, epsilon 0.23233920161786834, time 728.0, rides 131\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1621, reward 577.0, memory_length 2000, epsilon 0.23213009633641224, time 727.0, rides 135\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 1622, reward 732.0, memory_length 2000, epsilon 0.23192117924970945, time 732.0, rides 129\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1623, reward 734.0, memory_length 2000, epsilon 0.2317124501883847, time 730.0, rides 127\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 1624, reward 362.0, memory_length 2000, epsilon 0.23150390898321516, time 729.0, rides 131\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 1625, reward 532.0, memory_length 2000, epsilon 0.23129555546513025, time 730.0, rides 117\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 1626, reward 742.0, memory_length 2000, epsilon 0.23108738946521162, time 725.0, rides 121\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 1627, reward 710.0, memory_length 2000, epsilon 0.23087941081469293, time 728.0, rides 121\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 1628, reward 685.0, memory_length 2000, epsilon 0.2306716193449597, time 725.0, rides 131\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 1629, reward 662.0, memory_length 2000, epsilon 0.23046401488754922, time 736.0, rides 133\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 1630, reward 554.0, memory_length 2000, epsilon 0.23025659727415043, time 729.0, rides 119\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 1631, reward 429.0, memory_length 2000, epsilon 0.2300493663366037, time 722.0, rides 128\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1632, reward 503.0, memory_length 2000, epsilon 0.22984232190690074, time 730.0, rides 128\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1633, reward 466.0, memory_length 2000, epsilon 0.22963546381718453, time 728.0, rides 124\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 1634, reward 593.0, memory_length 2000, epsilon 0.22942879189974905, time 725.0, rides 138\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 1635, reward 650.0, memory_length 2000, epsilon 0.22922230598703927, time 722.0, rides 131\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 1636, reward 583.0, memory_length 2000, epsilon 0.22901600591165094, time 734.0, rides 133\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 1637, reward 708.0, memory_length 2000, epsilon 0.22880989150633047, time 729.0, rides 139\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1638, reward 384.0, memory_length 2000, epsilon 0.22860396260397475, time 728.0, rides 128\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 1639, reward 620.0, memory_length 2000, epsilon 0.22839821903763116, time 732.0, rides 130\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 1640, reward 753.0, memory_length 2000, epsilon 0.22819266064049729, time 727.0, rides 117\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1641, reward 241.0, memory_length 2000, epsilon 0.22798728724592082, time 737.0, rides 125\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 1642, reward 797.0, memory_length 2000, epsilon 0.2277820986873995, time 726.0, rides 118\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1643, reward 530.0, memory_length 2000, epsilon 0.22757709479858082, time 725.0, rides 130\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 1644, reward 736.0, memory_length 2000, epsilon 0.2273722754132621, time 728.0, rides 116\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 1645, reward 523.0, memory_length 2000, epsilon 0.22716764036539017, time 730.0, rides 130\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 1646, reward 505.0, memory_length 2000, epsilon 0.2269631894890613, time 736.0, rides 124\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 1647, reward 593.0, memory_length 2000, epsilon 0.22675892261852115, time 727.0, rides 145\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 1648, reward 291.0, memory_length 2000, epsilon 0.22655483958816447, time 720.0, rides 114\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 1649, reward 437.0, memory_length 2000, epsilon 0.22635094023253513, time 726.0, rides 122\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 1650, reward 433.0, memory_length 2000, epsilon 0.22614722438632584, time 728.0, rides 116\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 1651, reward 417.0, memory_length 2000, epsilon 0.22594369188437816, time 724.0, rides 124\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 1652, reward 470.0, memory_length 2000, epsilon 0.2257403425616822, time 735.0, rides 137\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 1653, reward 567.0, memory_length 2000, epsilon 0.2255371762533767, time 735.0, rides 118\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 1654, reward 684.0, memory_length 2000, epsilon 0.22533419279474864, time 724.0, rides 125\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 1655, reward 517.0, memory_length 2000, epsilon 0.22513139202123336, time 738.0, rides 126\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 1656, reward 552.0, memory_length 2000, epsilon 0.22492877376841425, time 726.0, rides 128\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 1657, reward 500.0, memory_length 2000, epsilon 0.22472633787202267, time 733.0, rides 129\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 1658, reward 768.0, memory_length 2000, epsilon 0.22452408416793784, time 729.0, rides 131\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 1659, reward 639.0, memory_length 2000, epsilon 0.2243220124921867, time 734.0, rides 134\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 1660, reward 722.0, memory_length 2000, epsilon 0.22412012268094372, time 728.0, rides 140\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 1661, reward 882.0, memory_length 2000, epsilon 0.22391841457053088, time 724.0, rides 133\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 1662, reward 760.0, memory_length 2000, epsilon 0.2237168879974174, time 721.0, rides 131\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 1663, reward 425.0, memory_length 2000, epsilon 0.22351554279821972, time 727.0, rides 121\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1664, reward 675.0, memory_length 2000, epsilon 0.2233143788097013, time 732.0, rides 140\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1665, reward 757.0, memory_length 2000, epsilon 0.22311339586877257, time 730.0, rides 140\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 1666, reward 551.0, memory_length 2000, epsilon 0.22291259381249068, time 739.0, rides 135\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 1667, reward 903.0, memory_length 2000, epsilon 0.22271197247805943, time 727.0, rides 127\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 1668, reward 679.0, memory_length 2000, epsilon 0.22251153170282917, time 722.0, rides 129\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 1669, reward 500.0, memory_length 2000, epsilon 0.22231127132429662, time 726.0, rides 130\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 1670, reward 611.0, memory_length 2000, epsilon 0.22211119118010475, time 729.0, rides 125\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 1671, reward 539.0, memory_length 2000, epsilon 0.22191129110804264, time 737.0, rides 134\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 1672, reward 788.0, memory_length 2000, epsilon 0.2217115709460454, time 729.0, rides 138\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 1673, reward 424.0, memory_length 2000, epsilon 0.22151203053219395, time 724.0, rides 124\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 1674, reward 770.0, memory_length 2000, epsilon 0.22131266970471497, time 729.0, rides 140\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 1675, reward 549.0, memory_length 2000, epsilon 0.22111348830198072, time 739.0, rides 130\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 1676, reward 730.0, memory_length 2000, epsilon 0.22091448616250892, time 725.0, rides 130\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 1677, reward 302.0, memory_length 2000, epsilon 0.22071566312496266, time 745.0, rides 126\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 1678, reward 823.0, memory_length 2000, epsilon 0.22051701902815019, time 730.0, rides 120\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 1679, reward 595.0, memory_length 2000, epsilon 0.22031855371102485, time 725.0, rides 142\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 1680, reward 576.0, memory_length 2000, epsilon 0.22012026701268492, time 726.0, rides 143\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 1681, reward 565.0, memory_length 2000, epsilon 0.2199221587723735, time 741.0, rides 122\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1682, reward 583.0, memory_length 2000, epsilon 0.21972422882947837, time 732.0, rides 132\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 1683, reward 767.0, memory_length 2000, epsilon 0.21952647702353184, time 733.0, rides 122\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 1684, reward 883.0, memory_length 2000, epsilon 0.21932890319421067, time 731.0, rides 135\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1685, reward 821.0, memory_length 2000, epsilon 0.21913150718133587, time 731.0, rides 123\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 1686, reward 682.0, memory_length 2000, epsilon 0.21893428882487267, time 726.0, rides 128\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 1687, reward 592.0, memory_length 2000, epsilon 0.2187372479649303, time 727.0, rides 130\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 1688, reward 532.0, memory_length 2000, epsilon 0.21854038444176185, time 727.0, rides 141\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1689, reward 246.0, memory_length 2000, epsilon 0.21834369809576426, time 729.0, rides 130\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 1690, reward 555.0, memory_length 2000, epsilon 0.21814718876747807, time 731.0, rides 140\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1691, reward 711.0, memory_length 2000, epsilon 0.21795085629758734, time 725.0, rides 121\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1692, reward 608.0, memory_length 2000, epsilon 0.2177547005269195, time 741.0, rides 132\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1693, reward 584.0, memory_length 2000, epsilon 0.21755872129644527, time 729.0, rides 139\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 1694, reward 588.0, memory_length 2000, epsilon 0.21736291844727845, time 732.0, rides 122\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 1695, reward 790.0, memory_length 2000, epsilon 0.2171672918206759, time 728.0, rides 137\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 1696, reward 324.0, memory_length 2000, epsilon 0.21697184125803728, time 736.0, rides 138\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 1697, reward 796.0, memory_length 2000, epsilon 0.21677656660090505, time 731.0, rides 122\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1698, reward 878.0, memory_length 2000, epsilon 0.21658146769096423, time 727.0, rides 142\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 1699, reward 576.0, memory_length 2000, epsilon 0.21638654437004237, time 727.0, rides 124\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 1700, reward 563.0, memory_length 2000, epsilon 0.21619179648010933, time 729.0, rides 121\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 1701, reward 710.0, memory_length 2000, epsilon 0.21599722386327724, time 734.0, rides 127\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 1702, reward 697.0, memory_length 2000, epsilon 0.2158028263618003, time 730.0, rides 133\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1703, reward 782.0, memory_length 2000, epsilon 0.21560860381807467, time 725.0, rides 128\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 1704, reward 584.0, memory_length 2000, epsilon 0.2154145560746384, time 732.0, rides 135\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1705, reward 863.0, memory_length 2000, epsilon 0.21522068297417124, time 728.0, rides 138\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 1706, reward 788.0, memory_length 2000, epsilon 0.2150269843594945, time 729.0, rides 132\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1707, reward 879.0, memory_length 2000, epsilon 0.21483346007357096, time 724.0, rides 154\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 1708, reward 509.0, memory_length 2000, epsilon 0.21464010995950475, time 726.0, rides 125\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 1709, reward 523.0, memory_length 2000, epsilon 0.2144469338605412, time 730.0, rides 128\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 1710, reward 417.0, memory_length 2000, epsilon 0.2142539316200667, time 728.0, rides 133\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 1711, reward 792.0, memory_length 2000, epsilon 0.21406110308160864, time 726.0, rides 137\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 1712, reward 592.0, memory_length 2000, epsilon 0.21386844808883518, time 726.0, rides 140\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 1713, reward 407.0, memory_length 2000, epsilon 0.21367596648555523, time 728.0, rides 108\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 1714, reward 223.0, memory_length 2000, epsilon 0.21348365811571823, time 724.0, rides 130\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 1715, reward 389.0, memory_length 2000, epsilon 0.2132915228234141, time 726.0, rides 121\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 1716, reward 563.0, memory_length 2000, epsilon 0.213099560452873, time 737.0, rides 129\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 1717, reward 793.0, memory_length 2000, epsilon 0.21290777084846543, time 730.0, rides 121\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 1718, reward 587.0, memory_length 2000, epsilon 0.2127161538547018, time 731.0, rides 142\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 1719, reward 465.0, memory_length 2000, epsilon 0.21252470931623257, time 736.0, rides 116\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1720, reward 380.0, memory_length 2000, epsilon 0.21233343707784796, time 737.0, rides 137\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 1721, reward 298.0, memory_length 2000, epsilon 0.2121423369844779, time 725.0, rides 131\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 1722, reward 658.0, memory_length 2000, epsilon 0.21195140888119188, time 728.0, rides 126\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 1723, reward 577.0, memory_length 2000, epsilon 0.2117606526131988, time 727.0, rides 128\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1724, reward 748.0, memory_length 2000, epsilon 0.2115700680258469, time 727.0, rides 137\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 1725, reward 874.0, memory_length 2000, epsilon 0.21137965496462363, time 724.0, rides 130\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 1726, reward 772.0, memory_length 2000, epsilon 0.21118941327515547, time 732.0, rides 134\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 1727, reward 748.0, memory_length 2000, epsilon 0.21099934280320784, time 728.0, rides 135\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 1728, reward 566.0, memory_length 2000, epsilon 0.21080944339468494, time 724.0, rides 114\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 1729, reward 553.0, memory_length 2000, epsilon 0.21061971489562972, time 725.0, rides 115\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 1730, reward 468.0, memory_length 2000, epsilon 0.21043015715222366, time 733.0, rides 125\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 1731, reward 365.0, memory_length 2000, epsilon 0.21024077001078664, time 728.0, rides 128\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 1732, reward 556.0, memory_length 2000, epsilon 0.21005155331777695, time 736.0, rides 132\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 1733, reward 759.0, memory_length 2000, epsilon 0.20986250691979094, time 724.0, rides 130\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 1734, reward 657.0, memory_length 2000, epsilon 0.20967363066356312, time 737.0, rides 135\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 1735, reward 557.0, memory_length 2000, epsilon 0.20948492439596592, time 729.0, rides 130\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1736, reward 544.0, memory_length 2000, epsilon 0.20929638796400954, time 726.0, rides 121\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 1737, reward 879.0, memory_length 2000, epsilon 0.20910802121484193, time 729.0, rides 122\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 1738, reward 751.0, memory_length 2000, epsilon 0.20891982399574857, time 737.0, rides 135\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 1739, reward 666.0, memory_length 2000, epsilon 0.20873179615415238, time 726.0, rides 139\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 1740, reward 907.0, memory_length 2000, epsilon 0.20854393753761363, time 733.0, rides 129\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 1741, reward 481.0, memory_length 2000, epsilon 0.2083562479938298, time 724.0, rides 136\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 1742, reward 505.0, memory_length 2000, epsilon 0.20816872737063535, time 729.0, rides 122\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 1743, reward 515.0, memory_length 2000, epsilon 0.2079813755160018, time 724.0, rides 141\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 1744, reward 911.0, memory_length 2000, epsilon 0.2077941922780374, time 731.0, rides 125\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 1745, reward 722.0, memory_length 2000, epsilon 0.20760717750498714, time 731.0, rides 137\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 1746, reward 553.0, memory_length 2000, epsilon 0.20742033104523264, time 723.0, rides 136\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1747, reward 711.0, memory_length 2000, epsilon 0.2072336527472919, time 728.0, rides 124\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 1748, reward 752.0, memory_length 2000, epsilon 0.20704714245981934, time 735.0, rides 134\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 1749, reward 820.0, memory_length 2000, epsilon 0.2068608000316055, time 729.0, rides 132\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 1750, reward 661.0, memory_length 2000, epsilon 0.20667462531157707, time 723.0, rides 119\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 1751, reward 423.0, memory_length 2000, epsilon 0.20648861814879665, time 730.0, rides 128\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 1752, reward 617.0, memory_length 2000, epsilon 0.20630277839246272, time 729.0, rides 125\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 1753, reward 885.0, memory_length 2000, epsilon 0.2061171058919095, time 733.0, rides 127\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 1754, reward 497.0, memory_length 2000, epsilon 0.2059316004966068, time 730.0, rides 118\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1755, reward 337.0, memory_length 2000, epsilon 0.20574626205615987, time 750.0, rides 128\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 1756, reward 368.0, memory_length 2000, epsilon 0.20556109042030932, time 728.0, rides 128\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1757, reward 621.0, memory_length 2000, epsilon 0.20537608543893104, time 730.0, rides 137\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1758, reward 416.0, memory_length 2000, epsilon 0.205191246962036, time 728.0, rides 123\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 1759, reward 555.0, memory_length 2000, epsilon 0.20500657483977017, time 729.0, rides 131\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 1760, reward 419.0, memory_length 2000, epsilon 0.20482206892241436, time 721.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 1761, reward 538.0, memory_length 2000, epsilon 0.2046377290603842, time 726.0, rides 129\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 1762, reward 699.0, memory_length 2000, epsilon 0.20445355510422983, time 729.0, rides 124\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 1763, reward 678.0, memory_length 2000, epsilon 0.20426954690463603, time 730.0, rides 137\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 1764, reward 932.0, memory_length 2000, epsilon 0.20408570431242185, time 732.0, rides 134\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 1765, reward 449.0, memory_length 2000, epsilon 0.20390202717854067, time 743.0, rides 126\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1766, reward 453.0, memory_length 2000, epsilon 0.20371851535407998, time 725.0, rides 122\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 1767, reward 257.0, memory_length 2000, epsilon 0.2035351686902613, time 730.0, rides 119\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 1768, reward 763.0, memory_length 2000, epsilon 0.20335198703844007, time 727.0, rides 124\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 1769, reward 569.0, memory_length 2000, epsilon 0.20316897025010547, time 729.0, rides 138\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 1770, reward 880.0, memory_length 2000, epsilon 0.20298611817688036, time 735.0, rides 136\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 1771, reward 542.0, memory_length 2000, epsilon 0.20280343067052117, time 737.0, rides 128\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 1772, reward 590.0, memory_length 2000, epsilon 0.2026209075829177, time 723.0, rides 127\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 1773, reward 663.0, memory_length 2000, epsilon 0.20243854876609307, time 727.0, rides 141\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 1774, reward 598.0, memory_length 2000, epsilon 0.20225635407220358, time 731.0, rides 136\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 1775, reward 653.0, memory_length 2000, epsilon 0.2020743233535386, time 727.0, rides 131\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 1776, reward 491.0, memory_length 2000, epsilon 0.2018924564625204, time 723.0, rides 124\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 1777, reward 482.0, memory_length 2000, epsilon 0.20171075325170415, time 734.0, rides 149\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 1778, reward 331.0, memory_length 2000, epsilon 0.20152921357377762, time 724.0, rides 121\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 1779, reward 554.0, memory_length 2000, epsilon 0.20134783728156122, time 729.0, rides 124\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 1780, reward 516.0, memory_length 2000, epsilon 0.20116662422800782, time 737.0, rides 144\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 1781, reward 885.0, memory_length 2000, epsilon 0.20098557426620262, time 726.0, rides 124\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 1782, reward 781.0, memory_length 2000, epsilon 0.20080468724936304, time 727.0, rides 135\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 1783, reward 517.0, memory_length 2000, epsilon 0.2006239630308386, time 722.0, rides 135\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 1784, reward 641.0, memory_length 2000, epsilon 0.20044340146411085, time 731.0, rides 119\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 1785, reward 598.0, memory_length 2000, epsilon 0.20026300240279316, time 730.0, rides 126\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 1786, reward 580.0, memory_length 2000, epsilon 0.20008276570063063, time 727.0, rides 124\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1787, reward 611.0, memory_length 2000, epsilon 0.19990269121150006, time 733.0, rides 114\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1788, reward 703.0, memory_length 2000, epsilon 0.19972277878940972, time 738.0, rides 136\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 1789, reward 348.0, memory_length 2000, epsilon 0.19954302828849926, time 731.0, rides 130\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 1790, reward 440.0, memory_length 2000, epsilon 0.19936343956303962, time 727.0, rides 125\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1791, reward 406.0, memory_length 2000, epsilon 0.1991840124674329, time 737.0, rides 128\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 1792, reward 536.0, memory_length 2000, epsilon 0.1990047468562122, time 732.0, rides 140\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 1793, reward 556.0, memory_length 2000, epsilon 0.1988256425840416, time 730.0, rides 131\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 1794, reward 627.0, memory_length 2000, epsilon 0.19864669950571595, time 727.0, rides 124\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 1795, reward 1118.0, memory_length 2000, epsilon 0.1984679174761608, time 727.0, rides 143\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 1796, reward 564.0, memory_length 2000, epsilon 0.19828929635043224, time 721.0, rides 147\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 1797, reward 899.0, memory_length 2000, epsilon 0.19811083598371684, time 733.0, rides 139\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1798, reward 706.0, memory_length 2000, epsilon 0.1979325362313315, time 729.0, rides 130\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 1799, reward 480.0, memory_length 2000, epsilon 0.1977543969487233, time 727.0, rides 130\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 1800, reward 240.0, memory_length 2000, epsilon 0.19757641799146944, time 725.0, rides 129\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 1801, reward 597.0, memory_length 2000, epsilon 0.1973985992152771, time 730.0, rides 129\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 1802, reward 613.0, memory_length 2000, epsilon 0.19722094047598335, time 729.0, rides 128\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 1803, reward 567.0, memory_length 2000, epsilon 0.19704344162955495, time 729.0, rides 128\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1804, reward 621.0, memory_length 2000, epsilon 0.19686610253208836, time 739.0, rides 130\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 1805, reward 570.0, memory_length 2000, epsilon 0.19668892303980948, time 732.0, rides 129\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 1806, reward 605.0, memory_length 2000, epsilon 0.19651190300907365, time 729.0, rides 134\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 1807, reward 788.0, memory_length 2000, epsilon 0.19633504229636548, time 730.0, rides 120\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 1808, reward 664.0, memory_length 2000, epsilon 0.19615834075829874, time 726.0, rides 135\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1809, reward 344.0, memory_length 2000, epsilon 0.19598179825161627, time 726.0, rides 120\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 1810, reward 283.0, memory_length 2000, epsilon 0.19580541463318982, time 730.0, rides 122\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 1811, reward 509.0, memory_length 2000, epsilon 0.19562918976001994, time 721.0, rides 138\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 1812, reward 790.0, memory_length 2000, epsilon 0.19545312348923594, time 729.0, rides 133\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 1813, reward 679.0, memory_length 2000, epsilon 0.1952772156780956, time 733.0, rides 151\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1814, reward 465.0, memory_length 2000, epsilon 0.19510146618398533, time 728.0, rides 125\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 1815, reward 639.0, memory_length 2000, epsilon 0.19492587486441973, time 735.0, rides 121\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 1816, reward 599.0, memory_length 2000, epsilon 0.19475044157704174, time 735.0, rides 133\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 1817, reward 373.0, memory_length 2000, epsilon 0.1945751661796224, time 725.0, rides 120\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1818, reward 792.0, memory_length 2000, epsilon 0.19440004853006074, time 725.0, rides 123\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 1819, reward 978.0, memory_length 2000, epsilon 0.19422508848638367, time 731.0, rides 131\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1820, reward 661.0, memory_length 2000, epsilon 0.19405028590674592, time 733.0, rides 126\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 1821, reward 747.0, memory_length 2000, epsilon 0.19387564064942983, time 728.0, rides 123\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1822, reward 1087.0, memory_length 2000, epsilon 0.19370115257284534, time 731.0, rides 127\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 1823, reward 670.0, memory_length 2000, epsilon 0.19352682153552977, time 723.0, rides 117\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 1824, reward 645.0, memory_length 2000, epsilon 0.1933526473961478, time 730.0, rides 135\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 1825, reward 709.0, memory_length 2000, epsilon 0.19317863001349125, time 732.0, rides 135\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 1826, reward 647.0, memory_length 2000, epsilon 0.1930047692464791, time 722.0, rides 125\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 1827, reward 1029.0, memory_length 2000, epsilon 0.19283106495415728, time 723.0, rides 127\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 1828, reward 662.0, memory_length 2000, epsilon 0.19265751699569852, time 722.0, rides 133\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 1829, reward 769.0, memory_length 2000, epsilon 0.1924841252304024, time 732.0, rides 130\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 1830, reward 684.0, memory_length 2000, epsilon 0.19231088951769504, time 728.0, rides 139\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 1831, reward 443.0, memory_length 2000, epsilon 0.1921378097171291, time 726.0, rides 126\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 1832, reward 619.0, memory_length 2000, epsilon 0.19196488568838369, time 730.0, rides 128\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 1833, reward 437.0, memory_length 2000, epsilon 0.19179211729126414, time 732.0, rides 121\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 1834, reward 472.0, memory_length 2000, epsilon 0.191619504385702, time 728.0, rides 133\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 1835, reward 669.0, memory_length 2000, epsilon 0.19144704683175487, time 729.0, rides 137\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 1836, reward 557.0, memory_length 2000, epsilon 0.1912747444896063, time 733.0, rides 125\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1837, reward 849.0, memory_length 2000, epsilon 0.19110259721956566, time 725.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 1838, reward 462.0, memory_length 2000, epsilon 0.19093060488206803, time 740.0, rides 136\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 1839, reward 950.0, memory_length 2000, epsilon 0.19075876733767416, time 730.0, rides 129\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 1840, reward 896.0, memory_length 2000, epsilon 0.19058708444707026, time 725.0, rides 130\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 1841, reward 507.0, memory_length 2000, epsilon 0.1904155560710679, time 726.0, rides 138\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 1842, reward 313.0, memory_length 2000, epsilon 0.19024418207060392, time 731.0, rides 118\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1843, reward 1016.0, memory_length 2000, epsilon 0.19007296230674037, time 731.0, rides 127\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1844, reward 942.0, memory_length 2000, epsilon 0.18990189664066429, time 735.0, rides 131\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 1845, reward 862.0, memory_length 2000, epsilon 0.18973098493368767, time 725.0, rides 120\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1846, reward 701.0, memory_length 2000, epsilon 0.18956022704724734, time 730.0, rides 128\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 1847, reward 895.0, memory_length 2000, epsilon 0.1893896228429048, time 727.0, rides 122\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 1848, reward 524.0, memory_length 2000, epsilon 0.18921917218234618, time 728.0, rides 137\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1849, reward 518.0, memory_length 2000, epsilon 0.18904887492738207, time 737.0, rides 122\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 1850, reward 516.0, memory_length 2000, epsilon 0.18887873093994742, time 734.0, rides 126\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 1851, reward 548.0, memory_length 2000, epsilon 0.18870874008210148, time 726.0, rides 128\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 1852, reward 628.0, memory_length 2000, epsilon 0.1885389022160276, time 729.0, rides 125\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 1853, reward 663.0, memory_length 2000, epsilon 0.18836921720403316, time 735.0, rides 131\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 1854, reward 630.0, memory_length 2000, epsilon 0.18819968490854952, time 726.0, rides 116\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 1855, reward 523.0, memory_length 2000, epsilon 0.18803030519213182, time 738.0, rides 140\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 1856, reward 920.0, memory_length 2000, epsilon 0.1878610779174589, time 728.0, rides 137\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 1857, reward 741.0, memory_length 2000, epsilon 0.18769200294733318, time 730.0, rides 128\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 1858, reward 269.0, memory_length 2000, epsilon 0.18752308014468058, time 722.0, rides 127\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 1859, reward 529.0, memory_length 2000, epsilon 0.18735430937255038, time 723.0, rides 138\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 1860, reward 941.0, memory_length 2000, epsilon 0.18718569049411507, time 724.0, rides 136\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 1861, reward 689.0, memory_length 2000, epsilon 0.18701722337267038, time 724.0, rides 120\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 1862, reward 578.0, memory_length 2000, epsilon 0.18684890787163497, time 740.0, rides 127\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 1863, reward 490.0, memory_length 2000, epsilon 0.1866807438545505, time 729.0, rides 126\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 1864, reward 605.0, memory_length 2000, epsilon 0.1865127311850814, time 736.0, rides 131\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 1865, reward 697.0, memory_length 2000, epsilon 0.18634486972701483, time 729.0, rides 121\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 1866, reward 732.0, memory_length 2000, epsilon 0.18617715934426052, time 731.0, rides 127\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 1867, reward 524.0, memory_length 2000, epsilon 0.18600959990085067, time 733.0, rides 137\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 1868, reward 496.0, memory_length 2000, epsilon 0.1858421912609399, time 734.0, rides 132\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1869, reward 372.0, memory_length 2000, epsilon 0.18567493328880505, time 725.0, rides 116\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 1870, reward 784.0, memory_length 2000, epsilon 0.18550782584884512, time 729.0, rides 148\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1871, reward 730.0, memory_length 2000, epsilon 0.18534086880558115, time 720.0, rides 130\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1872, reward 586.0, memory_length 2000, epsilon 0.18517406202365613, time 726.0, rides 127\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1873, reward 428.0, memory_length 2000, epsilon 0.18500740536783483, time 723.0, rides 122\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 1874, reward 767.0, memory_length 2000, epsilon 0.18484089870300377, time 727.0, rides 129\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 1875, reward 321.0, memory_length 2000, epsilon 0.18467454189417107, time 737.0, rides 121\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 1876, reward 812.0, memory_length 2000, epsilon 0.1845083348064663, time 728.0, rides 129\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 1877, reward 667.0, memory_length 2000, epsilon 0.1843422773051405, time 735.0, rides 116\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 1878, reward 595.0, memory_length 2000, epsilon 0.18417636925556585, time 731.0, rides 130\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 1879, reward 757.0, memory_length 2000, epsilon 0.18401061052323583, time 726.0, rides 125\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 1880, reward 956.0, memory_length 2000, epsilon 0.1838450009737649, time 723.0, rides 140\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 1881, reward 444.0, memory_length 2000, epsilon 0.1836795404728885, time 721.0, rides 119\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1882, reward 730.0, memory_length 2000, epsilon 0.1835142288864629, time 729.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 1883, reward 502.0, memory_length 2000, epsilon 0.18334906608046508, time 724.0, rides 143\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1884, reward 416.0, memory_length 2000, epsilon 0.18318405192099266, time 727.0, rides 129\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1885, reward 704.0, memory_length 2000, epsilon 0.18301918627426375, time 735.0, rides 134\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 1886, reward 702.0, memory_length 2000, epsilon 0.18285446900661692, time 730.0, rides 125\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 1887, reward 443.0, memory_length 2000, epsilon 0.18268989998451096, time 726.0, rides 126\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 1888, reward 485.0, memory_length 2000, epsilon 0.1825254790745249, time 731.0, rides 117\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1889, reward 579.0, memory_length 2000, epsilon 0.18236120614335782, time 732.0, rides 123\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 1890, reward 613.0, memory_length 2000, epsilon 0.1821970810578288, time 725.0, rides 138\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1891, reward 872.0, memory_length 2000, epsilon 0.18203310368487677, time 733.0, rides 121\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 1892, reward 466.0, memory_length 2000, epsilon 0.18186927389156038, time 725.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 1893, reward 504.0, memory_length 2000, epsilon 0.18170559154505797, time 727.0, rides 134\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 1894, reward 594.0, memory_length 2000, epsilon 0.18154205651266742, time 728.0, rides 132\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1895, reward 818.0, memory_length 2000, epsilon 0.18137866866180602, time 726.0, rides 140\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1896, reward 651.0, memory_length 2000, epsilon 0.18121542786001038, time 734.0, rides 136\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1897, reward 404.0, memory_length 2000, epsilon 0.18105233397493636, time 737.0, rides 132\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1898, reward 733.0, memory_length 2000, epsilon 0.18088938687435893, time 730.0, rides 137\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1899, reward 408.0, memory_length 2000, epsilon 0.180726586426172, time 731.0, rides 130\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 1900, reward 435.0, memory_length 2000, epsilon 0.18056393249838845, time 723.0, rides 136\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 1901, reward 590.0, memory_length 2000, epsilon 0.1804014249591399, time 725.0, rides 137\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1902, reward 602.0, memory_length 2000, epsilon 0.1802390636766767, time 730.0, rides 138\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 1903, reward 436.0, memory_length 2000, epsilon 0.18007684851936767, time 725.0, rides 128\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 1904, reward 592.0, memory_length 2000, epsilon 0.17991477935570024, time 735.0, rides 134\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1905, reward 703.0, memory_length 2000, epsilon 0.17975285605428012, time 726.0, rides 136\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 1906, reward 681.0, memory_length 2000, epsilon 0.17959107848383127, time 723.0, rides 138\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 1907, reward 749.0, memory_length 2000, epsilon 0.1794294465131958, time 731.0, rides 128\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 1908, reward 525.0, memory_length 2000, epsilon 0.17926796001133394, time 732.0, rides 118\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 1909, reward 817.0, memory_length 2000, epsilon 0.17910661884732373, time 725.0, rides 127\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 1910, reward 767.0, memory_length 2000, epsilon 0.17894542289036114, time 736.0, rides 135\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 1911, reward 203.0, memory_length 2000, epsilon 0.1787843720097598, time 730.0, rides 121\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 1912, reward 593.0, memory_length 2000, epsilon 0.17862346607495103, time 724.0, rides 122\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 1913, reward 903.0, memory_length 2000, epsilon 0.17846270495548358, time 728.0, rides 140\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 1914, reward 525.0, memory_length 2000, epsilon 0.17830208852102364, time 740.0, rides 137\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 1915, reward 895.0, memory_length 2000, epsilon 0.17814161664135472, time 726.0, rides 121\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 1916, reward 835.0, memory_length 2000, epsilon 0.1779812891863775, time 727.0, rides 128\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 1917, reward 837.0, memory_length 2000, epsilon 0.17782110602610976, time 722.0, rides 130\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 1918, reward 539.0, memory_length 2000, epsilon 0.17766106703068626, time 731.0, rides 148\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 1919, reward 404.0, memory_length 2000, epsilon 0.17750117207035865, time 721.0, rides 130\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1920, reward 837.0, memory_length 2000, epsilon 0.17734142101549533, time 732.0, rides 131\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 1921, reward 965.0, memory_length 2000, epsilon 0.17718181373658137, time 731.0, rides 130\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 1922, reward 400.0, memory_length 2000, epsilon 0.17702235010421843, time 729.0, rides 133\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 1923, reward 481.0, memory_length 2000, epsilon 0.17686302998912465, time 728.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1924, reward 750.0, memory_length 2000, epsilon 0.17670385326213445, time 731.0, rides 121\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 1925, reward 538.0, memory_length 2000, epsilon 0.17654481979419853, time 731.0, rides 138\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 1926, reward 575.0, memory_length 2000, epsilon 0.17638592945638376, time 727.0, rides 117\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 1927, reward 553.0, memory_length 2000, epsilon 0.176227182119873, time 725.0, rides 130\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 1928, reward 636.0, memory_length 2000, epsilon 0.17606857765596512, time 731.0, rides 141\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 1929, reward 606.0, memory_length 2000, epsilon 0.17591011593607475, time 725.0, rides 123\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 1930, reward 664.0, memory_length 2000, epsilon 0.17575179683173228, time 724.0, rides 123\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 1931, reward 565.0, memory_length 2000, epsilon 0.17559362021458372, time 729.0, rides 129\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 1932, reward 677.0, memory_length 2000, epsilon 0.17543558595639058, time 731.0, rides 114\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 1933, reward 515.0, memory_length 2000, epsilon 0.17527769392902984, time 727.0, rides 124\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 1934, reward 513.0, memory_length 2000, epsilon 0.1751199440044937, time 734.0, rides 134\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 1935, reward 727.0, memory_length 2000, epsilon 0.17496233605488967, time 732.0, rides 120\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 1936, reward 372.0, memory_length 2000, epsilon 0.17480486995244027, time 723.0, rides 143\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 1937, reward 601.0, memory_length 2000, epsilon 0.17464754556948306, time 726.0, rides 131\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1938, reward 698.0, memory_length 2000, epsilon 0.17449036277847052, time 741.0, rides 129\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 1939, reward 737.0, memory_length 2000, epsilon 0.1743333214519699, time 730.0, rides 133\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 1940, reward 706.0, memory_length 2000, epsilon 0.17417642146266313, time 729.0, rides 141\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1941, reward 574.0, memory_length 2000, epsilon 0.17401966268334673, time 735.0, rides 126\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1942, reward 638.0, memory_length 2000, epsilon 0.17386304498693173, time 732.0, rides 124\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 1943, reward 646.0, memory_length 2000, epsilon 0.17370656824644348, time 733.0, rides 128\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 1944, reward 503.0, memory_length 2000, epsilon 0.17355023233502168, time 729.0, rides 128\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 1945, reward 694.0, memory_length 2000, epsilon 0.17339403712592016, time 724.0, rides 125\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 1946, reward 533.0, memory_length 2000, epsilon 0.17323798249250683, time 732.0, rides 133\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 1947, reward 493.0, memory_length 2000, epsilon 0.17308206830826356, time 728.0, rides 121\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 1948, reward 626.0, memory_length 2000, epsilon 0.17292629444678612, time 737.0, rides 130\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1949, reward 763.0, memory_length 2000, epsilon 0.17277066078178402, time 733.0, rides 134\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 1950, reward 534.0, memory_length 2000, epsilon 0.17261516718708042, time 722.0, rides 119\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 1951, reward 643.0, memory_length 2000, epsilon 0.17245981353661205, time 730.0, rides 125\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 1952, reward 590.0, memory_length 2000, epsilon 0.1723045997044291, time 721.0, rides 129\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 1953, reward 685.0, memory_length 2000, epsilon 0.17214952556469512, time 729.0, rides 129\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 1954, reward 677.0, memory_length 2000, epsilon 0.1719945909916869, time 726.0, rides 127\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 1955, reward 877.0, memory_length 2000, epsilon 0.1718397958597944, time 722.0, rides 133\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 1956, reward 746.0, memory_length 2000, epsilon 0.17168514004352056, time 723.0, rides 129\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 1957, reward 646.0, memory_length 2000, epsilon 0.1715306234174814, time 737.0, rides 129\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 1958, reward 747.0, memory_length 2000, epsilon 0.17137624585640568, time 739.0, rides 130\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 1959, reward 503.0, memory_length 2000, epsilon 0.17122200723513492, time 727.0, rides 129\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1960, reward 758.0, memory_length 2000, epsilon 0.1710679074286233, time 730.0, rides 125\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 1961, reward 692.0, memory_length 2000, epsilon 0.17091394631193754, time 734.0, rides 144\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 1962, reward 630.0, memory_length 2000, epsilon 0.1707601237602568, time 742.0, rides 146\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 1963, reward 540.0, memory_length 2000, epsilon 0.17060643964887257, time 730.0, rides 116\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 1964, reward 439.0, memory_length 2000, epsilon 0.17045289385318857, time 735.0, rides 126\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 1965, reward 626.0, memory_length 2000, epsilon 0.1702994862487207, time 723.0, rides 122\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 1966, reward 577.0, memory_length 2000, epsilon 0.17014621671109686, time 729.0, rides 141\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 1967, reward 844.0, memory_length 2000, epsilon 0.16999308511605687, time 725.0, rides 130\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 1968, reward 914.0, memory_length 2000, epsilon 0.1698400913394524, time 732.0, rides 119\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 1969, reward 714.0, memory_length 2000, epsilon 0.1696872352572469, time 731.0, rides 132\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 1970, reward 862.0, memory_length 2000, epsilon 0.1695345167455154, time 727.0, rides 143\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 1971, reward 419.0, memory_length 2000, epsilon 0.16938193568044443, time 732.0, rides 128\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 1972, reward 587.0, memory_length 2000, epsilon 0.16922949193833203, time 727.0, rides 139\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 1973, reward 731.0, memory_length 2000, epsilon 0.16907718539558753, time 724.0, rides 140\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 1974, reward 701.0, memory_length 2000, epsilon 0.1689250159287315, time 722.0, rides 121\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 1975, reward 581.0, memory_length 2000, epsilon 0.16877298341439564, time 725.0, rides 131\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 1976, reward 778.0, memory_length 2000, epsilon 0.1686210877293227, time 732.0, rides 131\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 1977, reward 765.0, memory_length 2000, epsilon 0.1684693287503663, time 724.0, rides 136\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 1978, reward 877.0, memory_length 2000, epsilon 0.16831770635449098, time 730.0, rides 131\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 1979, reward 698.0, memory_length 2000, epsilon 0.16816622041877194, time 727.0, rides 150\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 1980, reward 499.0, memory_length 2000, epsilon 0.16801487082039504, time 727.0, rides 121\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 1981, reward 855.0, memory_length 2000, epsilon 0.16786365743665668, time 725.0, rides 127\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 1982, reward 755.0, memory_length 2000, epsilon 0.16771258014496368, time 726.0, rides 128\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1983, reward 787.0, memory_length 2000, epsilon 0.1675616388228332, time 722.0, rides 129\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 1984, reward 410.0, memory_length 2000, epsilon 0.16741083334789264, time 730.0, rides 115\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 1985, reward 527.0, memory_length 2000, epsilon 0.16726016359787954, time 730.0, rides 127\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 1986, reward 635.0, memory_length 2000, epsilon 0.16710962945064145, time 723.0, rides 136\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 1987, reward 735.0, memory_length 2000, epsilon 0.16695923078413588, time 723.0, rides 136\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 1988, reward 1001.0, memory_length 2000, epsilon 0.16680896747643015, time 727.0, rides 125\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 1989, reward 679.0, memory_length 2000, epsilon 0.16665883940570136, time 731.0, rides 117\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1990, reward 747.0, memory_length 2000, epsilon 0.16650884645023623, time 732.0, rides 137\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 1991, reward 738.0, memory_length 2000, epsilon 0.166358988488431, time 731.0, rides 122\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 1992, reward 811.0, memory_length 2000, epsilon 0.1662092653987914, time 726.0, rides 135\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 1993, reward 861.0, memory_length 2000, epsilon 0.1660596770599325, time 737.0, rides 131\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 1994, reward 653.0, memory_length 2000, epsilon 0.16591022335057856, time 735.0, rides 137\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 1995, reward 399.0, memory_length 2000, epsilon 0.16576090414956304, time 737.0, rides 129\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 1996, reward 645.0, memory_length 2000, epsilon 0.16561171933582844, time 731.0, rides 128\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 1997, reward 771.0, memory_length 2000, epsilon 0.1654626687884262, time 731.0, rides 145\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 1998, reward 592.0, memory_length 2000, epsilon 0.1653137523865166, time 727.0, rides 129\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 1999, reward 633.0, memory_length 2000, epsilon 0.16516497000936875, time 723.0, rides 141\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2000, reward 810.0, memory_length 2000, epsilon 0.1650163215363603, time 730.0, rides 129\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 2001, reward 698.0, memory_length 2000, epsilon 0.16486780684697758, time 731.0, rides 130\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 2002, reward 738.0, memory_length 2000, epsilon 0.1647194258208153, time 733.0, rides 122\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 2003, reward 827.0, memory_length 2000, epsilon 0.16457117833757656, time 738.0, rides 130\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 2004, reward 376.0, memory_length 2000, epsilon 0.16442306427707273, time 723.0, rides 130\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 2005, reward 897.0, memory_length 2000, epsilon 0.16427508351922337, time 732.0, rides 124\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 2006, reward 389.0, memory_length 2000, epsilon 0.16412723594405607, time 722.0, rides 133\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 2007, reward 408.0, memory_length 2000, epsilon 0.1639795214317064, time 726.0, rides 134\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 2008, reward 449.0, memory_length 2000, epsilon 0.16383193986241787, time 727.0, rides 120\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 2009, reward 981.0, memory_length 2000, epsilon 0.16368449111654168, time 731.0, rides 134\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 2010, reward 620.0, memory_length 2000, epsilon 0.1635371750745368, time 725.0, rides 132\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 2011, reward 931.0, memory_length 2000, epsilon 0.1633899916169697, time 734.0, rides 136\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 2012, reward 402.0, memory_length 2000, epsilon 0.16324294062451444, time 732.0, rides 126\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 2013, reward 808.0, memory_length 2000, epsilon 0.16309602197795237, time 723.0, rides 134\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 2014, reward 453.0, memory_length 2000, epsilon 0.1629492355581722, time 724.0, rides 127\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 2015, reward 695.0, memory_length 2000, epsilon 0.16280258124616984, time 730.0, rides 130\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 2016, reward 892.0, memory_length 2000, epsilon 0.16265605892304827, time 735.0, rides 131\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 2017, reward 707.0, memory_length 2000, epsilon 0.16250966847001752, time 723.0, rides 128\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 2018, reward 469.0, memory_length 2000, epsilon 0.1623634097683945, time 731.0, rides 137\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 2019, reward 642.0, memory_length 2000, epsilon 0.16221728269960295, time 728.0, rides 129\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 2020, reward 581.0, memory_length 2000, epsilon 0.1620712871451733, time 727.0, rides 135\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 2021, reward 670.0, memory_length 2000, epsilon 0.16192542298674265, time 732.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 2022, reward 693.0, memory_length 2000, epsilon 0.16177969010605459, time 737.0, rides 154\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2023, reward 807.0, memory_length 2000, epsilon 0.16163408838495913, time 734.0, rides 129\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 2024, reward 680.0, memory_length 2000, epsilon 0.16148861770541267, time 727.0, rides 131\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 2025, reward 755.0, memory_length 2000, epsilon 0.1613432779494778, time 727.0, rides 118\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 2026, reward 815.0, memory_length 2000, epsilon 0.1611980689993233, time 726.0, rides 138\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 2027, reward 639.0, memory_length 2000, epsilon 0.1610529907372239, time 724.0, rides 133\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 2028, reward 634.0, memory_length 2000, epsilon 0.1609080430455604, time 726.0, rides 129\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 2029, reward 898.0, memory_length 2000, epsilon 0.16076322580681937, time 725.0, rides 141\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2030, reward 785.0, memory_length 2000, epsilon 0.16061853890359323, time 727.0, rides 133\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 2031, reward 748.0, memory_length 2000, epsilon 0.16047398221858, time 730.0, rides 141\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 2032, reward 708.0, memory_length 2000, epsilon 0.1603295556345833, time 730.0, rides 140\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 2033, reward 530.0, memory_length 2000, epsilon 0.16018525903451217, time 730.0, rides 120\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 2034, reward 699.0, memory_length 2000, epsilon 0.1600410923013811, time 729.0, rides 140\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 2035, reward 852.0, memory_length 2000, epsilon 0.15989705531830986, time 726.0, rides 118\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2036, reward 552.0, memory_length 2000, epsilon 0.15975314796852338, time 722.0, rides 120\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 2037, reward 739.0, memory_length 2000, epsilon 0.1596093701353517, time 729.0, rides 122\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 2038, reward 796.0, memory_length 2000, epsilon 0.1594657217022299, time 733.0, rides 126\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 2039, reward 976.0, memory_length 2000, epsilon 0.15932220255269788, time 732.0, rides 135\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 2040, reward 592.0, memory_length 2000, epsilon 0.15917881257040045, time 731.0, rides 140\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 2041, reward 681.0, memory_length 2000, epsilon 0.15903555163908709, time 724.0, rides 123\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 2042, reward 443.0, memory_length 2000, epsilon 0.15889241964261192, time 727.0, rides 118\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 2043, reward 734.0, memory_length 2000, epsilon 0.15874941646493357, time 731.0, rides 140\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 2044, reward 694.0, memory_length 2000, epsilon 0.15860654199011512, time 724.0, rides 121\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 2045, reward 864.0, memory_length 2000, epsilon 0.158463796102324, time 732.0, rides 130\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 2046, reward 727.0, memory_length 2000, epsilon 0.1583211786858319, time 728.0, rides 120\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 2047, reward 606.0, memory_length 2000, epsilon 0.15817868962501463, time 727.0, rides 133\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 2048, reward 331.0, memory_length 2000, epsilon 0.15803632880435212, time 726.0, rides 132\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 2049, reward 655.0, memory_length 2000, epsilon 0.1578940961084282, time 728.0, rides 127\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 2050, reward 888.0, memory_length 2000, epsilon 0.1577519914219306, time 729.0, rides 137\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 2051, reward 1007.0, memory_length 2000, epsilon 0.15761001462965088, time 734.0, rides 128\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2052, reward 730.0, memory_length 2000, epsilon 0.1574681656164842, time 727.0, rides 137\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 2053, reward 784.0, memory_length 2000, epsilon 0.15732644426742937, time 728.0, rides 122\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 2054, reward 624.0, memory_length 2000, epsilon 0.15718485046758868, time 734.0, rides 125\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 2055, reward 546.0, memory_length 2000, epsilon 0.15704338410216784, time 730.0, rides 138\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 2056, reward 496.0, memory_length 2000, epsilon 0.1569020450564759, time 730.0, rides 146\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 2057, reward 437.0, memory_length 2000, epsilon 0.15676083321592507, time 726.0, rides 124\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2058, reward 1044.0, memory_length 2000, epsilon 0.15661974846603074, time 733.0, rides 129\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2059, reward 816.0, memory_length 2000, epsilon 0.1564787906924113, time 731.0, rides 132\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 2060, reward 601.0, memory_length 2000, epsilon 0.15633795978078813, time 725.0, rides 122\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 2061, reward 586.0, memory_length 2000, epsilon 0.15619725561698541, time 732.0, rides 144\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 2062, reward 851.0, memory_length 2000, epsilon 0.15605667808693013, time 728.0, rides 140\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 2063, reward 772.0, memory_length 2000, epsilon 0.1559162270766519, time 726.0, rides 132\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 2064, reward 367.0, memory_length 2000, epsilon 0.1557759024722829, time 726.0, rides 125\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 2065, reward 582.0, memory_length 2000, epsilon 0.15563570416005784, time 726.0, rides 125\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 2066, reward 892.0, memory_length 2000, epsilon 0.15549563202631378, time 730.0, rides 127\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 2067, reward 826.0, memory_length 2000, epsilon 0.1553556859574901, time 732.0, rides 136\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 2068, reward 719.0, memory_length 2000, epsilon 0.15521586584012836, time 733.0, rides 144\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 2069, reward 613.0, memory_length 2000, epsilon 0.15507617156087225, time 721.0, rides 120\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 2070, reward 374.0, memory_length 2000, epsilon 0.15493660300646747, time 731.0, rides 123\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 2071, reward 938.0, memory_length 2000, epsilon 0.15479716006376165, time 730.0, rides 125\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 2072, reward 884.0, memory_length 2000, epsilon 0.15465784261970428, time 729.0, rides 140\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 2073, reward 798.0, memory_length 2000, epsilon 0.15451865056134653, time 732.0, rides 130\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 2074, reward 596.0, memory_length 2000, epsilon 0.15437958377584132, time 723.0, rides 127\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 2075, reward 578.0, memory_length 2000, epsilon 0.15424064215044306, time 724.0, rides 134\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 2076, reward 544.0, memory_length 2000, epsilon 0.15410182557250765, time 728.0, rides 130\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 2077, reward 806.0, memory_length 2000, epsilon 0.1539631339294924, time 729.0, rides 129\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 2078, reward 714.0, memory_length 2000, epsilon 0.15382456710895587, time 728.0, rides 134\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2079, reward 681.0, memory_length 2000, epsilon 0.1536861249985578, time 728.0, rides 136\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 2080, reward 924.0, memory_length 2000, epsilon 0.1535478074860591, time 729.0, rides 119\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 2081, reward 767.0, memory_length 2000, epsilon 0.15340961445932164, time 721.0, rides 114\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 2082, reward 849.0, memory_length 2000, epsilon 0.15327154580630825, time 727.0, rides 130\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 2083, reward 805.0, memory_length 2000, epsilon 0.15313360141508256, time 730.0, rides 124\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 2084, reward 1020.0, memory_length 2000, epsilon 0.152995781173809, time 736.0, rides 136\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 2085, reward 723.0, memory_length 2000, epsilon 0.15285808497075257, time 729.0, rides 139\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 2086, reward 631.0, memory_length 2000, epsilon 0.1527205126942789, time 728.0, rides 119\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 2087, reward 548.0, memory_length 2000, epsilon 0.15258306423285403, time 728.0, rides 123\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 2088, reward 439.0, memory_length 2000, epsilon 0.15244573947504447, time 731.0, rides 134\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 2089, reward 834.0, memory_length 2000, epsilon 0.15230853830951693, time 728.0, rides 136\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 2090, reward 540.0, memory_length 2000, epsilon 0.15217146062503836, time 728.0, rides 131\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 2091, reward 848.0, memory_length 2000, epsilon 0.15203450631047583, time 735.0, rides 133\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 2092, reward 797.0, memory_length 2000, epsilon 0.1518976752547964, time 728.0, rides 141\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 2093, reward 1083.0, memory_length 2000, epsilon 0.15176096734706707, time 728.0, rides 134\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 2094, reward 847.0, memory_length 2000, epsilon 0.1516243824764547, time 723.0, rides 134\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 2095, reward 751.0, memory_length 2000, epsilon 0.1514879205322259, time 725.0, rides 133\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 2096, reward 876.0, memory_length 2000, epsilon 0.15135158140374688, time 730.0, rides 120\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 2097, reward 919.0, memory_length 2000, epsilon 0.15121536498048352, time 741.0, rides 138\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 2098, reward 992.0, memory_length 2000, epsilon 0.1510792711520011, time 724.0, rides 149\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 2099, reward 901.0, memory_length 2000, epsilon 0.15094329980796428, time 724.0, rides 133\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 2100, reward 982.0, memory_length 2000, epsilon 0.15080745083813712, time 728.0, rides 139\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 2101, reward 850.0, memory_length 2000, epsilon 0.1506717241323828, time 723.0, rides 132\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 2102, reward 524.0, memory_length 2000, epsilon 0.15053611958066365, time 726.0, rides 135\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 2103, reward 546.0, memory_length 2000, epsilon 0.15040063707304105, time 727.0, rides 130\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 2104, reward 512.0, memory_length 2000, epsilon 0.1502652764996753, time 725.0, rides 130\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 2105, reward 886.0, memory_length 2000, epsilon 0.1501300377508256, time 727.0, rides 148\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 2106, reward 986.0, memory_length 2000, epsilon 0.14999492071684983, time 733.0, rides 135\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 2107, reward 945.0, memory_length 2000, epsilon 0.14985992528820466, time 722.0, rides 140\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 2108, reward 701.0, memory_length 2000, epsilon 0.14972505135544528, time 726.0, rides 121\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2109, reward 691.0, memory_length 2000, epsilon 0.1495902988092254, time 724.0, rides 131\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 2110, reward 647.0, memory_length 2000, epsilon 0.1494556675402971, time 727.0, rides 126\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 2111, reward 1031.0, memory_length 2000, epsilon 0.14932115743951083, time 729.0, rides 135\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 2112, reward 716.0, memory_length 2000, epsilon 0.14918676839781528, time 731.0, rides 128\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 2113, reward 734.0, memory_length 2000, epsilon 0.14905250030625725, time 722.0, rides 126\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2114, reward 599.0, memory_length 2000, epsilon 0.1489183530559816, time 724.0, rides 128\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 2115, reward 693.0, memory_length 2000, epsilon 0.14878432653823123, time 728.0, rides 135\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 2116, reward 783.0, memory_length 2000, epsilon 0.14865042064434683, time 729.0, rides 122\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2117, reward 432.0, memory_length 2000, epsilon 0.14851663526576692, time 734.0, rides 130\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 2118, reward 1237.0, memory_length 2000, epsilon 0.14838297029402772, time 727.0, rides 127\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2119, reward 743.0, memory_length 2000, epsilon 0.1482494256207631, time 732.0, rides 132\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 2120, reward 502.0, memory_length 2000, epsilon 0.1481160011377044, time 733.0, rides 139\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 2121, reward 948.0, memory_length 2000, epsilon 0.14798269673668046, time 739.0, rides 127\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 2122, reward 563.0, memory_length 2000, epsilon 0.14784951230961746, time 731.0, rides 115\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 2123, reward 830.0, memory_length 2000, epsilon 0.14771644774853881, time 728.0, rides 137\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 2124, reward 763.0, memory_length 2000, epsilon 0.14758350294556513, time 728.0, rides 135\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 2125, reward 720.0, memory_length 2000, epsilon 0.14745067779291413, time 734.0, rides 121\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 2126, reward 596.0, memory_length 2000, epsilon 0.1473179721829005, time 729.0, rides 116\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 2127, reward 595.0, memory_length 2000, epsilon 0.14718538600793588, time 733.0, rides 140\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 2128, reward 722.0, memory_length 2000, epsilon 0.14705291916052873, time 726.0, rides 132\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 2129, reward 847.0, memory_length 2000, epsilon 0.14692057153328425, time 730.0, rides 123\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 2130, reward 1036.0, memory_length 2000, epsilon 0.14678834301890428, time 722.0, rides 129\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 2131, reward 584.0, memory_length 2000, epsilon 0.14665623351018728, time 728.0, rides 141\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 2132, reward 671.0, memory_length 2000, epsilon 0.1465242429000281, time 737.0, rides 122\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 2133, reward 566.0, memory_length 2000, epsilon 0.1463923710814181, time 725.0, rides 127\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 2134, reward 813.0, memory_length 2000, epsilon 0.1462606179474448, time 728.0, rides 128\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 2135, reward 608.0, memory_length 2000, epsilon 0.1461289833912921, time 734.0, rides 124\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 2136, reward 486.0, memory_length 2000, epsilon 0.14599746730623994, time 724.0, rides 139\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 2137, reward 507.0, memory_length 2000, epsilon 0.14586606958566434, time 733.0, rides 130\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2138, reward 774.0, memory_length 2000, epsilon 0.14573479012303725, time 726.0, rides 145\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 2139, reward 726.0, memory_length 2000, epsilon 0.1456036288119265, time 727.0, rides 121\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 2140, reward 963.0, memory_length 2000, epsilon 0.14547258554599576, time 724.0, rides 137\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 2141, reward 880.0, memory_length 2000, epsilon 0.14534166021900435, time 732.0, rides 136\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 2142, reward 712.0, memory_length 2000, epsilon 0.14521085272480724, time 724.0, rides 130\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2143, reward 655.0, memory_length 2000, epsilon 0.1450801629573549, time 725.0, rides 130\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 2144, reward 747.0, memory_length 2000, epsilon 0.14494959081069328, time 728.0, rides 127\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 2145, reward 762.0, memory_length 2000, epsilon 0.14481913617896366, time 739.0, rides 143\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 2146, reward 816.0, memory_length 2000, epsilon 0.1446887989564026, time 729.0, rides 143\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 2147, reward 982.0, memory_length 2000, epsilon 0.14455857903734184, time 729.0, rides 135\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 2148, reward 763.0, memory_length 2000, epsilon 0.14442847631620823, time 731.0, rides 145\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 2149, reward 676.0, memory_length 2000, epsilon 0.14429849068752365, time 727.0, rides 121\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 2150, reward 779.0, memory_length 2000, epsilon 0.1441686220459049, time 723.0, rides 140\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 2151, reward 762.0, memory_length 2000, epsilon 0.14403887028606358, time 722.0, rides 134\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 2152, reward 635.0, memory_length 2000, epsilon 0.1439092353028061, time 726.0, rides 129\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 2153, reward 748.0, memory_length 2000, epsilon 0.1437797169910336, time 732.0, rides 121\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 2154, reward 796.0, memory_length 2000, epsilon 0.14365031524574165, time 722.0, rides 125\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 2155, reward 701.0, memory_length 2000, epsilon 0.14352102996202049, time 721.0, rides 131\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 2156, reward 731.0, memory_length 2000, epsilon 0.14339186103505466, time 725.0, rides 129\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 2157, reward 329.0, memory_length 2000, epsilon 0.14326280836012312, time 731.0, rides 119\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 2158, reward 693.0, memory_length 2000, epsilon 0.143133871832599, time 728.0, rides 128\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 2159, reward 688.0, memory_length 2000, epsilon 0.14300505134794966, time 729.0, rides 127\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 2160, reward 1041.0, memory_length 2000, epsilon 0.1428763468017365, time 730.0, rides 126\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 2161, reward 930.0, memory_length 2000, epsilon 0.14274775808961493, time 733.0, rides 130\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2162, reward 960.0, memory_length 2000, epsilon 0.14261928510733426, time 727.0, rides 128\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 2163, reward 797.0, memory_length 2000, epsilon 0.14249092775073766, time 736.0, rides 131\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2164, reward 960.0, memory_length 2000, epsilon 0.14236268591576198, time 728.0, rides 122\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2165, reward 639.0, memory_length 2000, epsilon 0.1422345594984378, time 734.0, rides 132\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 2166, reward 959.0, memory_length 2000, epsilon 0.1421065483948892, time 724.0, rides 128\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 2167, reward 592.0, memory_length 2000, epsilon 0.1419786525013338, time 728.0, rides 130\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 2168, reward 685.0, memory_length 2000, epsilon 0.1418508717140826, time 727.0, rides 117\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 2169, reward 734.0, memory_length 2000, epsilon 0.1417232059295399, time 738.0, rides 130\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 2170, reward 765.0, memory_length 2000, epsilon 0.14159565504420332, time 735.0, rides 128\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2171, reward 711.0, memory_length 2000, epsilon 0.14146821895466355, time 726.0, rides 129\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 2172, reward 987.0, memory_length 2000, epsilon 0.14134089755760434, time 736.0, rides 127\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2173, reward 779.0, memory_length 2000, epsilon 0.1412136907498025, time 729.0, rides 138\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2174, reward 698.0, memory_length 2000, epsilon 0.14108659842812768, time 737.0, rides 130\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 2175, reward 877.0, memory_length 2000, epsilon 0.14095962048954236, time 728.0, rides 122\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 2176, reward 607.0, memory_length 2000, epsilon 0.14083275683110177, time 729.0, rides 134\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 2177, reward 531.0, memory_length 2000, epsilon 0.14070600734995378, time 724.0, rides 122\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2178, reward 808.0, memory_length 2000, epsilon 0.14057937194333883, time 733.0, rides 125\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 2179, reward 517.0, memory_length 2000, epsilon 0.14045285050858983, time 729.0, rides 124\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 2180, reward 709.0, memory_length 2000, epsilon 0.1403264429431321, time 725.0, rides 118\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 2181, reward 707.0, memory_length 2000, epsilon 0.14020014914448328, time 735.0, rides 121\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 2182, reward 532.0, memory_length 2000, epsilon 0.14007396901025324, time 721.0, rides 128\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 2183, reward 898.0, memory_length 2000, epsilon 0.139947902438144, time 730.0, rides 128\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 2184, reward 883.0, memory_length 2000, epsilon 0.13982194932594968, time 743.0, rides 124\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 2185, reward 667.0, memory_length 2000, epsilon 0.13969610957155632, time 734.0, rides 126\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 2186, reward 874.0, memory_length 2000, epsilon 0.13957038307294192, time 726.0, rides 135\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 2187, reward 391.0, memory_length 2000, epsilon 0.13944476972817627, time 728.0, rides 138\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 2188, reward 599.0, memory_length 2000, epsilon 0.13931926943542092, time 727.0, rides 130\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 2189, reward 523.0, memory_length 2000, epsilon 0.13919388209292904, time 730.0, rides 128\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 2190, reward 914.0, memory_length 2000, epsilon 0.1390686075990454, time 727.0, rides 134\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 2191, reward 640.0, memory_length 2000, epsilon 0.13894344585220628, time 726.0, rides 132\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 2192, reward 876.0, memory_length 2000, epsilon 0.1388183967509393, time 731.0, rides 130\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 2193, reward 761.0, memory_length 2000, epsilon 0.13869346019386344, time 729.0, rides 125\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 2194, reward 637.0, memory_length 2000, epsilon 0.13856863607968897, time 723.0, rides 126\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 2195, reward 740.0, memory_length 2000, epsilon 0.13844392430721725, time 728.0, rides 119\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 2196, reward 737.0, memory_length 2000, epsilon 0.13831932477534076, time 722.0, rides 116\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2197, reward 741.0, memory_length 2000, epsilon 0.13819483738304295, time 730.0, rides 131\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2198, reward 699.0, memory_length 2000, epsilon 0.1380704620293982, time 726.0, rides 127\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 2199, reward 773.0, memory_length 2000, epsilon 0.13794619861357174, time 724.0, rides 131\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 2200, reward 398.0, memory_length 2000, epsilon 0.1378220470348195, time 722.0, rides 123\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 2201, reward 712.0, memory_length 2000, epsilon 0.13769800719248818, time 723.0, rides 134\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 2202, reward 861.0, memory_length 2000, epsilon 0.13757407898601492, time 725.0, rides 132\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 2203, reward 590.0, memory_length 2000, epsilon 0.13745026231492752, time 733.0, rides 134\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 2204, reward 887.0, memory_length 2000, epsilon 0.13732655707884409, time 727.0, rides 132\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 2205, reward 692.0, memory_length 2000, epsilon 0.13720296317747313, time 729.0, rides 121\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 2206, reward 777.0, memory_length 2000, epsilon 0.13707948051061342, time 727.0, rides 134\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 2207, reward 914.0, memory_length 2000, epsilon 0.13695610897815386, time 736.0, rides 135\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 2208, reward 700.0, memory_length 2000, epsilon 0.13683284848007352, time 732.0, rides 128\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 2209, reward 852.0, memory_length 2000, epsilon 0.13670969891644144, time 741.0, rides 140\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2210, reward 768.0, memory_length 2000, epsilon 0.13658666018741664, time 736.0, rides 130\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 2211, reward 820.0, memory_length 2000, epsilon 0.13646373219324795, time 730.0, rides 150\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 2212, reward 742.0, memory_length 2000, epsilon 0.13634091483427402, time 728.0, rides 140\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 2213, reward 707.0, memory_length 2000, epsilon 0.13621820801092316, time 727.0, rides 134\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 2214, reward 957.0, memory_length 2000, epsilon 0.13609561162371334, time 728.0, rides 142\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2215, reward 694.0, memory_length 2000, epsilon 0.135973125573252, time 728.0, rides 135\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 2216, reward 626.0, memory_length 2000, epsilon 0.13585074976023606, time 723.0, rides 124\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 2217, reward 625.0, memory_length 2000, epsilon 0.13572848408545185, time 724.0, rides 135\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 2218, reward 1002.0, memory_length 2000, epsilon 0.13560632844977494, time 730.0, rides 133\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 2219, reward 831.0, memory_length 2000, epsilon 0.13548428275417013, time 733.0, rides 135\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 2220, reward 984.0, memory_length 2000, epsilon 0.13536234689969137, time 732.0, rides 125\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2221, reward 869.0, memory_length 2000, epsilon 0.13524052078748164, time 728.0, rides 129\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2222, reward 726.0, memory_length 2000, epsilon 0.1351188043187729, time 728.0, rides 127\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 2223, reward 628.0, memory_length 2000, epsilon 0.134997197394886, time 732.0, rides 134\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 2224, reward 696.0, memory_length 2000, epsilon 0.1348756999172306, time 731.0, rides 125\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 2225, reward 684.0, memory_length 2000, epsilon 0.1347543117873051, time 724.0, rides 130\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 2226, reward 439.0, memory_length 2000, epsilon 0.1346330329066965, time 738.0, rides 123\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 2227, reward 561.0, memory_length 2000, epsilon 0.13451186317708047, time 737.0, rides 133\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 2228, reward 649.0, memory_length 2000, epsilon 0.1343908025002211, time 730.0, rides 135\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 2229, reward 379.0, memory_length 2000, epsilon 0.13426985077797088, time 731.0, rides 127\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 2230, reward 687.0, memory_length 2000, epsilon 0.1341490079122707, time 733.0, rides 131\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 2231, reward 511.0, memory_length 2000, epsilon 0.13402827380514964, time 724.0, rides 132\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 2232, reward 972.0, memory_length 2000, epsilon 0.133907648358725, time 730.0, rides 131\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 2233, reward 330.0, memory_length 2000, epsilon 0.13378713147520216, time 723.0, rides 124\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2234, reward 818.0, memory_length 2000, epsilon 0.13366672305687446, time 727.0, rides 120\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 2235, reward 727.0, memory_length 2000, epsilon 0.13354642300612327, time 725.0, rides 145\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 2236, reward 678.0, memory_length 2000, epsilon 0.13342623122541775, time 724.0, rides 130\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 2237, reward 970.0, memory_length 2000, epsilon 0.13330614761731488, time 733.0, rides 133\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 2238, reward 622.0, memory_length 2000, epsilon 0.1331861720844593, time 726.0, rides 134\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 2239, reward 862.0, memory_length 2000, epsilon 0.1330663045295833, time 733.0, rides 137\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 2240, reward 808.0, memory_length 2000, epsilon 0.13294654485550667, time 729.0, rides 122\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 2241, reward 730.0, memory_length 2000, epsilon 0.1328268929651367, time 726.0, rides 136\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 2242, reward 692.0, memory_length 2000, epsilon 0.13270734876146806, time 734.0, rides 130\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2243, reward 730.0, memory_length 2000, epsilon 0.13258791214758273, time 722.0, rides 130\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 2244, reward 654.0, memory_length 2000, epsilon 0.1324685830266499, time 732.0, rides 140\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2245, reward 512.0, memory_length 2000, epsilon 0.13234936130192593, time 734.0, rides 145\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2246, reward 557.0, memory_length 2000, epsilon 0.1322302468767542, time 724.0, rides 130\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2247, reward 577.0, memory_length 2000, epsilon 0.13211123965456512, time 730.0, rides 129\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 2248, reward 746.0, memory_length 2000, epsilon 0.131992339538876, time 721.0, rides 125\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 2249, reward 969.0, memory_length 2000, epsilon 0.13187354643329102, time 730.0, rides 140\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 2250, reward 608.0, memory_length 2000, epsilon 0.13175486024150107, time 728.0, rides 137\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 2251, reward 723.0, memory_length 2000, epsilon 0.1316362808672837, time 730.0, rides 133\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 2252, reward 630.0, memory_length 2000, epsilon 0.13151780821450315, time 729.0, rides 128\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 2253, reward 793.0, memory_length 2000, epsilon 0.1313994421871101, time 729.0, rides 145\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 2254, reward 598.0, memory_length 2000, epsilon 0.1312811826891417, time 723.0, rides 118\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 2255, reward 613.0, memory_length 2000, epsilon 0.13116302962472148, time 729.0, rides 113\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2256, reward 728.0, memory_length 2000, epsilon 0.13104498289805924, time 735.0, rides 132\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 2257, reward 932.0, memory_length 2000, epsilon 0.130927042413451, time 731.0, rides 131\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 2258, reward 347.0, memory_length 2000, epsilon 0.13080920807527888, time 734.0, rides 130\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 2259, reward 693.0, memory_length 2000, epsilon 0.13069147978801113, time 725.0, rides 123\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 2260, reward 620.0, memory_length 2000, epsilon 0.13057385745620192, time 727.0, rides 149\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2261, reward 697.0, memory_length 2000, epsilon 0.13045634098449135, time 724.0, rides 123\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 2262, reward 843.0, memory_length 2000, epsilon 0.13033893027760532, time 731.0, rides 120\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 2263, reward 808.0, memory_length 2000, epsilon 0.13022162524035547, time 735.0, rides 121\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 2264, reward 698.0, memory_length 2000, epsilon 0.13010442577763914, time 725.0, rides 135\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 2265, reward 686.0, memory_length 2000, epsilon 0.12998733179443928, time 729.0, rides 135\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 2266, reward 550.0, memory_length 2000, epsilon 0.12987034319582427, time 735.0, rides 130\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 2267, reward 798.0, memory_length 2000, epsilon 0.12975345988694803, time 730.0, rides 130\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 2268, reward 1186.0, memory_length 2000, epsilon 0.12963668177304977, time 729.0, rides 127\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2269, reward 641.0, memory_length 2000, epsilon 0.12952000875945402, time 730.0, rides 124\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 2270, reward 590.0, memory_length 2000, epsilon 0.1294034407515705, time 728.0, rides 128\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 2271, reward 703.0, memory_length 2000, epsilon 0.12928697765489408, time 730.0, rides 126\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 2272, reward 663.0, memory_length 2000, epsilon 0.12917061937500468, time 725.0, rides 141\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 2273, reward 980.0, memory_length 2000, epsilon 0.12905436581756718, time 730.0, rides 124\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 2274, reward 518.0, memory_length 2000, epsilon 0.12893821688833138, time 724.0, rides 120\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 2275, reward 586.0, memory_length 2000, epsilon 0.12882217249313188, time 739.0, rides 124\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 2276, reward 740.0, memory_length 2000, epsilon 0.12870623253788807, time 726.0, rides 127\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 2277, reward 519.0, memory_length 2000, epsilon 0.12859039692860397, time 730.0, rides 135\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 2278, reward 757.0, memory_length 2000, epsilon 0.12847466557136822, time 722.0, rides 142\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 2279, reward 688.0, memory_length 2000, epsilon 0.128359038372354, time 731.0, rides 123\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2280, reward 695.0, memory_length 2000, epsilon 0.12824351523781888, time 731.0, rides 133\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 2281, reward 792.0, memory_length 2000, epsilon 0.12812809607410483, time 725.0, rides 119\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 2282, reward 594.0, memory_length 2000, epsilon 0.12801278078763814, time 720.0, rides 121\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 2283, reward 669.0, memory_length 2000, epsilon 0.12789756928492926, time 732.0, rides 120\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 2284, reward 401.0, memory_length 2000, epsilon 0.12778246147257283, time 731.0, rides 113\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 2285, reward 951.0, memory_length 2000, epsilon 0.1276674572572475, time 735.0, rides 136\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 2286, reward 887.0, memory_length 2000, epsilon 0.12755255654571598, time 724.0, rides 125\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 2287, reward 772.0, memory_length 2000, epsilon 0.12743775924482484, time 725.0, rides 130\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 2288, reward 1070.0, memory_length 2000, epsilon 0.1273230652615045, time 730.0, rides 126\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 2289, reward 884.0, memory_length 2000, epsilon 0.12720847450276915, time 728.0, rides 128\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 2290, reward 658.0, memory_length 2000, epsilon 0.12709398687571666, time 731.0, rides 130\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 2291, reward 669.0, memory_length 2000, epsilon 0.1269796022875285, time 738.0, rides 124\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 2292, reward 911.0, memory_length 2000, epsilon 0.1268653206454697, time 731.0, rides 123\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 2293, reward 834.0, memory_length 2000, epsilon 0.1267511418568888, time 727.0, rides 129\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 2294, reward 681.0, memory_length 2000, epsilon 0.1266370658292176, time 722.0, rides 120\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 2295, reward 1082.0, memory_length 2000, epsilon 0.12652309246997132, time 733.0, rides 125\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 2296, reward 872.0, memory_length 2000, epsilon 0.12640922168674834, time 727.0, rides 133\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 2297, reward 822.0, memory_length 2000, epsilon 0.12629545338723028, time 734.0, rides 134\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 2298, reward 753.0, memory_length 2000, epsilon 0.12618178747918177, time 729.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 2299, reward 904.0, memory_length 2000, epsilon 0.1260682238704505, time 726.0, rides 137\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2300, reward 612.0, memory_length 2000, epsilon 0.12595476246896709, time 734.0, rides 136\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 2301, reward 779.0, memory_length 2000, epsilon 0.125841403182745, time 722.0, rides 137\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 2302, reward 536.0, memory_length 2000, epsilon 0.12572814591988052, time 729.0, rides 136\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 2303, reward 822.0, memory_length 2000, epsilon 0.12561499058855263, time 730.0, rides 128\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 2304, reward 780.0, memory_length 2000, epsilon 0.12550193709702293, time 727.0, rides 133\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 2305, reward 754.0, memory_length 2000, epsilon 0.1253889853536356, time 727.0, rides 136\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 2306, reward 509.0, memory_length 2000, epsilon 0.12527613526681733, time 728.0, rides 131\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 2307, reward 462.0, memory_length 2000, epsilon 0.12516338674507718, time 728.0, rides 136\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 2308, reward 594.0, memory_length 2000, epsilon 0.1250507396970066, time 727.0, rides 134\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 2309, reward 311.0, memory_length 2000, epsilon 0.1249381940312793, time 740.0, rides 117\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 2310, reward 459.0, memory_length 2000, epsilon 0.12482574965665115, time 740.0, rides 134\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 2311, reward 761.0, memory_length 2000, epsilon 0.12471340648196017, time 732.0, rides 123\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 2312, reward 872.0, memory_length 2000, epsilon 0.1246011644161264, time 729.0, rides 129\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 2313, reward 1183.0, memory_length 2000, epsilon 0.12448902336815189, time 721.0, rides 136\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 2314, reward 576.0, memory_length 2000, epsilon 0.12437698324712056, time 728.0, rides 120\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 2315, reward 905.0, memory_length 2000, epsilon 0.12426504396219815, time 727.0, rides 133\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 2316, reward 698.0, memory_length 2000, epsilon 0.12415320542263217, time 729.0, rides 137\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 2317, reward 562.0, memory_length 2000, epsilon 0.1240414675377518, time 735.0, rides 124\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 2318, reward 354.0, memory_length 2000, epsilon 0.12392983021696782, time 732.0, rides 131\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 2319, reward 887.0, memory_length 2000, epsilon 0.12381829336977256, time 733.0, rides 148\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 2320, reward 716.0, memory_length 2000, epsilon 0.12370685690573976, time 724.0, rides 124\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 2321, reward 623.0, memory_length 2000, epsilon 0.1235955207345246, time 739.0, rides 135\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 2322, reward 855.0, memory_length 2000, epsilon 0.12348428476586353, time 731.0, rides 137\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 2323, reward 805.0, memory_length 2000, epsilon 0.12337314890957425, time 725.0, rides 127\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 2324, reward 1050.0, memory_length 2000, epsilon 0.12326211307555564, time 730.0, rides 138\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 2325, reward 398.0, memory_length 2000, epsilon 0.12315117717378764, time 724.0, rides 123\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 2326, reward 696.0, memory_length 2000, epsilon 0.12304034111433122, time 733.0, rides 121\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 2327, reward 771.0, memory_length 2000, epsilon 0.12292960480732833, time 736.0, rides 127\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2328, reward 656.0, memory_length 2000, epsilon 0.12281896816300172, time 725.0, rides 129\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 2329, reward 780.0, memory_length 2000, epsilon 0.12270843109165502, time 730.0, rides 130\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 2330, reward 807.0, memory_length 2000, epsilon 0.12259799350367254, time 729.0, rides 140\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 2331, reward 587.0, memory_length 2000, epsilon 0.12248765530951923, time 731.0, rides 136\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 2332, reward 706.0, memory_length 2000, epsilon 0.12237741641974066, time 734.0, rides 145\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 2333, reward 763.0, memory_length 2000, epsilon 0.12226727674496289, time 728.0, rides 134\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 2334, reward 367.0, memory_length 2000, epsilon 0.12215723619589243, time 727.0, rides 122\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 2335, reward 914.0, memory_length 2000, epsilon 0.12204729468331613, time 733.0, rides 122\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 2336, reward 671.0, memory_length 2000, epsilon 0.12193745211810114, time 732.0, rides 132\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 2337, reward 562.0, memory_length 2000, epsilon 0.12182770841119485, time 726.0, rides 133\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 2338, reward 382.0, memory_length 2000, epsilon 0.12171806347362477, time 734.0, rides 131\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 2339, reward 618.0, memory_length 2000, epsilon 0.1216085172164985, time 729.0, rides 127\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 2340, reward 781.0, memory_length 2000, epsilon 0.12149906955100365, time 723.0, rides 128\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 2341, reward 832.0, memory_length 2000, epsilon 0.12138972038840774, time 727.0, rides 130\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 2342, reward 681.0, memory_length 2000, epsilon 0.12128046964005817, time 735.0, rides 129\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 2343, reward 668.0, memory_length 2000, epsilon 0.12117131721738213, time 732.0, rides 131\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 2344, reward 407.0, memory_length 2000, epsilon 0.12106226303188648, time 724.0, rides 125\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 2345, reward 678.0, memory_length 2000, epsilon 0.12095330699515779, time 725.0, rides 126\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 2346, reward 754.0, memory_length 2000, epsilon 0.12084444901886214, time 730.0, rides 121\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 2347, reward 948.0, memory_length 2000, epsilon 0.12073568901474516, time 731.0, rides 133\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 2348, reward 770.0, memory_length 2000, epsilon 0.12062702689463188, time 732.0, rides 123\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 2349, reward 351.0, memory_length 2000, epsilon 0.12051846257042671, time 724.0, rides 124\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 2350, reward 914.0, memory_length 2000, epsilon 0.12040999595411332, time 732.0, rides 135\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 2351, reward 1006.0, memory_length 2000, epsilon 0.12030162695775462, time 729.0, rides 128\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 2352, reward 719.0, memory_length 2000, epsilon 0.12019335549349264, time 724.0, rides 122\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 2353, reward 1026.0, memory_length 2000, epsilon 0.12008518147354849, time 731.0, rides 129\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 2354, reward 755.0, memory_length 2000, epsilon 0.1199771048102223, time 727.0, rides 135\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 2355, reward 774.0, memory_length 2000, epsilon 0.11986912541589309, time 746.0, rides 139\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2356, reward 856.0, memory_length 2000, epsilon 0.11976124320301879, time 728.0, rides 126\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 2357, reward 584.0, memory_length 2000, epsilon 0.11965345808413606, time 727.0, rides 133\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 2358, reward 761.0, memory_length 2000, epsilon 0.11954576997186034, time 738.0, rides 138\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 2359, reward 1100.0, memory_length 2000, epsilon 0.11943817877888566, time 732.0, rides 132\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 2360, reward 806.0, memory_length 2000, epsilon 0.11933068441798465, time 727.0, rides 127\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 2361, reward 604.0, memory_length 2000, epsilon 0.11922328680200847, time 731.0, rides 123\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2362, reward 1028.0, memory_length 2000, epsilon 0.11911598584388666, time 732.0, rides 144\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2363, reward 712.0, memory_length 2000, epsilon 0.11900878145662716, time 735.0, rides 145\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2364, reward 944.0, memory_length 2000, epsilon 0.1189016735533162, time 729.0, rides 132\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 2365, reward 948.0, memory_length 2000, epsilon 0.11879466204711821, time 729.0, rides 132\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2366, reward 994.0, memory_length 2000, epsilon 0.1186877468512758, time 739.0, rides 134\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 2367, reward 819.0, memory_length 2000, epsilon 0.11858092787910965, time 724.0, rides 135\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 2368, reward 681.0, memory_length 2000, epsilon 0.11847420504401845, time 730.0, rides 129\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 2369, reward 771.0, memory_length 2000, epsilon 0.11836757825947884, time 724.0, rides 134\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 2370, reward 949.0, memory_length 2000, epsilon 0.11826104743904531, time 733.0, rides 136\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 2371, reward 740.0, memory_length 2000, epsilon 0.11815461249635016, time 726.0, rides 138\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 2372, reward 483.0, memory_length 2000, epsilon 0.11804827334510344, time 735.0, rides 131\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 2373, reward 954.0, memory_length 2000, epsilon 0.11794202989909285, time 727.0, rides 123\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2374, reward 690.0, memory_length 2000, epsilon 0.11783588207218366, time 734.0, rides 129\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 2375, reward 855.0, memory_length 2000, epsilon 0.1177298297783187, time 732.0, rides 132\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 2376, reward 708.0, memory_length 2000, epsilon 0.1176238729315182, time 729.0, rides 125\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 2377, reward 635.0, memory_length 2000, epsilon 0.11751801144587984, time 726.0, rides 128\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 2378, reward 970.0, memory_length 2000, epsilon 0.11741224523557854, time 729.0, rides 137\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2379, reward 686.0, memory_length 2000, epsilon 0.11730657421486652, time 730.0, rides 138\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 2380, reward 461.0, memory_length 2000, epsilon 0.11720099829807314, time 728.0, rides 127\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 2381, reward 802.0, memory_length 2000, epsilon 0.11709551739960487, time 728.0, rides 125\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 2382, reward 703.0, memory_length 2000, epsilon 0.11699013143394522, time 728.0, rides 135\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 2383, reward 917.0, memory_length 2000, epsilon 0.11688484031565467, time 735.0, rides 125\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 2384, reward 933.0, memory_length 2000, epsilon 0.11677964395937059, time 724.0, rides 129\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 2385, reward 859.0, memory_length 2000, epsilon 0.11667454227980716, time 726.0, rides 138\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 2386, reward 756.0, memory_length 2000, epsilon 0.11656953519175532, time 728.0, rides 142\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 2387, reward 680.0, memory_length 2000, epsilon 0.11646462261008274, time 722.0, rides 137\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 2388, reward 830.0, memory_length 2000, epsilon 0.11635980444973366, time 728.0, rides 127\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2389, reward 786.0, memory_length 2000, epsilon 0.1162550806257289, time 721.0, rides 129\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2390, reward 884.0, memory_length 2000, epsilon 0.11615045105316574, time 727.0, rides 138\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2391, reward 884.0, memory_length 2000, epsilon 0.11604591564721789, time 729.0, rides 144\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 2392, reward 858.0, memory_length 2000, epsilon 0.1159414743231354, time 732.0, rides 138\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 2393, reward 902.0, memory_length 2000, epsilon 0.11583712699624457, time 726.0, rides 116\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 2394, reward 1208.0, memory_length 2000, epsilon 0.11573287358194795, time 727.0, rides 133\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 2395, reward 720.0, memory_length 2000, epsilon 0.11562871399572419, time 728.0, rides 137\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 2396, reward 618.0, memory_length 2000, epsilon 0.11552464815312803, time 740.0, rides 136\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 2397, reward 557.0, memory_length 2000, epsilon 0.11542067596979022, time 727.0, rides 118\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 2398, reward 679.0, memory_length 2000, epsilon 0.11531679736141741, time 728.0, rides 124\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 2399, reward 994.0, memory_length 2000, epsilon 0.11521301224379213, time 729.0, rides 142\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 2400, reward 920.0, memory_length 2000, epsilon 0.11510932053277272, time 737.0, rides 126\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 2401, reward 772.0, memory_length 2000, epsilon 0.11500572214429322, time 731.0, rides 128\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2402, reward 853.0, memory_length 2000, epsilon 0.11490221699436336, time 732.0, rides 132\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 2403, reward 673.0, memory_length 2000, epsilon 0.11479880499906843, time 726.0, rides 134\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 2404, reward 983.0, memory_length 2000, epsilon 0.11469548607456927, time 733.0, rides 135\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 2405, reward 713.0, memory_length 2000, epsilon 0.11459226013710215, time 733.0, rides 142\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 2406, reward 794.0, memory_length 2000, epsilon 0.11448912710297876, time 727.0, rides 138\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 2407, reward 921.0, memory_length 2000, epsilon 0.11438608688858608, time 739.0, rides 141\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 2408, reward 951.0, memory_length 2000, epsilon 0.11428313941038636, time 731.0, rides 125\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 2409, reward 609.0, memory_length 2000, epsilon 0.11418028458491701, time 740.0, rides 137\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 2410, reward 964.0, memory_length 2000, epsilon 0.11407752232879058, time 732.0, rides 144\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2411, reward 827.0, memory_length 2000, epsilon 0.11397485255869466, time 731.0, rides 143\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 2412, reward 873.0, memory_length 2000, epsilon 0.11387227519139184, time 722.0, rides 135\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 2413, reward 614.0, memory_length 2000, epsilon 0.11376979014371959, time 725.0, rides 138\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 2414, reward 695.0, memory_length 2000, epsilon 0.11366739733259024, time 729.0, rides 134\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 2415, reward 684.0, memory_length 2000, epsilon 0.1135650966749909, time 738.0, rides 133\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 2416, reward 754.0, memory_length 2000, epsilon 0.11346288808798341, time 731.0, rides 127\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 2417, reward 1092.0, memory_length 2000, epsilon 0.11336077148870423, time 728.0, rides 133\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 2418, reward 527.0, memory_length 2000, epsilon 0.11325874679436439, time 725.0, rides 125\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 2419, reward 578.0, memory_length 2000, epsilon 0.11315681392224945, time 727.0, rides 124\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 2420, reward 556.0, memory_length 2000, epsilon 0.11305497278971943, time 722.0, rides 132\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 2421, reward 686.0, memory_length 2000, epsilon 0.11295322331420868, time 729.0, rides 131\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 2422, reward 647.0, memory_length 2000, epsilon 0.11285156541322588, time 728.0, rides 126\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 2423, reward 877.0, memory_length 2000, epsilon 0.11274999900435398, time 725.0, rides 141\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 2424, reward 571.0, memory_length 2000, epsilon 0.11264852400525006, time 724.0, rides 127\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 2425, reward 685.0, memory_length 2000, epsilon 0.11254714033364534, time 725.0, rides 118\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2426, reward 677.0, memory_length 2000, epsilon 0.11244584790734506, time 725.0, rides 139\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 2427, reward 574.0, memory_length 2000, epsilon 0.11234464664422845, time 728.0, rides 139\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 2428, reward 825.0, memory_length 2000, epsilon 0.11224353646224865, time 727.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 2429, reward 502.0, memory_length 2000, epsilon 0.11214251727943263, time 722.0, rides 121\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 2430, reward 1091.0, memory_length 2000, epsilon 0.11204158901388113, time 728.0, rides 125\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 2431, reward 776.0, memory_length 2000, epsilon 0.11194075158376864, time 733.0, rides 128\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 2432, reward 837.0, memory_length 2000, epsilon 0.11184000490734325, time 730.0, rides 123\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 2433, reward 420.0, memory_length 2000, epsilon 0.11173934890292664, time 727.0, rides 120\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 2434, reward 898.0, memory_length 2000, epsilon 0.111638783488914, time 730.0, rides 135\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 2435, reward 921.0, memory_length 2000, epsilon 0.11153830858377398, time 730.0, rides 143\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 2436, reward 814.0, memory_length 2000, epsilon 0.11143792410604858, time 727.0, rides 131\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 2437, reward 920.0, memory_length 2000, epsilon 0.11133762997435313, time 737.0, rides 141\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 2438, reward 667.0, memory_length 2000, epsilon 0.11123742610737622, time 728.0, rides 128\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 2439, reward 649.0, memory_length 2000, epsilon 0.11113731242387959, time 731.0, rides 128\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 2440, reward 527.0, memory_length 2000, epsilon 0.11103728884269809, time 732.0, rides 140\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 2441, reward 843.0, memory_length 2000, epsilon 0.11093735528273967, time 733.0, rides 113\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 2442, reward 542.0, memory_length 2000, epsilon 0.1108375116629852, time 732.0, rides 133\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2443, reward 643.0, memory_length 2000, epsilon 0.1107377579024885, time 732.0, rides 126\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 2444, reward 493.0, memory_length 2000, epsilon 0.11063809392037627, time 731.0, rides 120\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 2445, reward 898.0, memory_length 2000, epsilon 0.11053851963584793, time 725.0, rides 137\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 2446, reward 376.0, memory_length 2000, epsilon 0.11043903496817567, time 723.0, rides 123\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 2447, reward 1024.0, memory_length 2000, epsilon 0.1103396398367043, time 726.0, rides 134\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2448, reward 616.0, memory_length 2000, epsilon 0.11024033416085127, time 738.0, rides 124\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 2449, reward 620.0, memory_length 2000, epsilon 0.11014111786010651, time 724.0, rides 128\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 2450, reward 750.0, memory_length 2000, epsilon 0.1100419908540324, time 726.0, rides 120\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 2451, reward 836.0, memory_length 2000, epsilon 0.10994295306226377, time 730.0, rides 132\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2452, reward 839.0, memory_length 2000, epsilon 0.10984400440450773, time 733.0, rides 128\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2453, reward 874.0, memory_length 2000, epsilon 0.10974514480054368, time 732.0, rides 120\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 2454, reward 835.0, memory_length 2000, epsilon 0.10964637417022319, time 727.0, rides 137\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 2455, reward 621.0, memory_length 2000, epsilon 0.10954769243346998, time 732.0, rides 135\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 2456, reward 570.0, memory_length 2000, epsilon 0.10944909951027985, time 728.0, rides 121\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2457, reward 759.0, memory_length 2000, epsilon 0.1093505953207206, time 732.0, rides 117\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2458, reward 605.0, memory_length 2000, epsilon 0.10925217978493194, time 734.0, rides 125\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 2459, reward 897.0, memory_length 2000, epsilon 0.10915385282312551, time 730.0, rides 128\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 2460, reward 827.0, memory_length 2000, epsilon 0.1090556143555847, time 722.0, rides 132\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 2461, reward 698.0, memory_length 2000, epsilon 0.10895746430266467, time 730.0, rides 121\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 2462, reward 884.0, memory_length 2000, epsilon 0.10885940258479228, time 725.0, rides 120\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 2463, reward 788.0, memory_length 2000, epsilon 0.10876142912246596, time 725.0, rides 122\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 2464, reward 546.0, memory_length 2000, epsilon 0.10866354383625575, time 728.0, rides 124\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 2465, reward 695.0, memory_length 2000, epsilon 0.10856574664680312, time 723.0, rides 121\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 2466, reward 344.0, memory_length 2000, epsilon 0.10846803747482099, time 729.0, rides 131\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2467, reward 522.0, memory_length 2000, epsilon 0.10837041624109366, time 729.0, rides 122\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 2468, reward 497.0, memory_length 2000, epsilon 0.10827288286647667, time 730.0, rides 127\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 2469, reward 835.0, memory_length 2000, epsilon 0.10817543727189684, time 729.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 2470, reward 583.0, memory_length 2000, epsilon 0.10807807937835213, time 734.0, rides 126\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 2471, reward 832.0, memory_length 2000, epsilon 0.10798080910691162, time 732.0, rides 124\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 2472, reward 456.0, memory_length 2000, epsilon 0.10788362637871539, time 732.0, rides 119\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2473, reward 666.0, memory_length 2000, epsilon 0.10778653111497455, time 724.0, rides 130\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 2474, reward 911.0, memory_length 2000, epsilon 0.10768952323697108, time 724.0, rides 131\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 2475, reward 857.0, memory_length 2000, epsilon 0.1075926026660578, time 734.0, rides 135\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 2476, reward 776.0, memory_length 2000, epsilon 0.10749576932365836, time 734.0, rides 120\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 2477, reward 646.0, memory_length 2000, epsilon 0.10739902313126706, time 724.0, rides 114\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 2478, reward 381.0, memory_length 2000, epsilon 0.10730236401044892, time 728.0, rides 121\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 2479, reward 657.0, memory_length 2000, epsilon 0.10720579188283952, time 731.0, rides 117\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 2480, reward 893.0, memory_length 2000, epsilon 0.10710930667014495, time 730.0, rides 135\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 2481, reward 729.0, memory_length 2000, epsilon 0.10701290829414183, time 726.0, rides 136\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 2482, reward 537.0, memory_length 2000, epsilon 0.10691659667667709, time 726.0, rides 131\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 2483, reward 604.0, memory_length 2000, epsilon 0.10682037173966809, time 724.0, rides 129\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2484, reward 802.0, memory_length 2000, epsilon 0.10672423340510238, time 722.0, rides 130\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 2485, reward 827.0, memory_length 2000, epsilon 0.10662818159503779, time 739.0, rides 137\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 2486, reward 822.0, memory_length 2000, epsilon 0.10653221623160225, time 727.0, rides 128\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 2487, reward 694.0, memory_length 2000, epsilon 0.1064363372369938, time 727.0, rides 127\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 2488, reward 588.0, memory_length 2000, epsilon 0.1063405445334805, time 724.0, rides 140\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 2489, reward 995.0, memory_length 2000, epsilon 0.10624483804340037, time 733.0, rides 127\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2490, reward 655.0, memory_length 2000, epsilon 0.10614921768916132, time 730.0, rides 134\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 2491, reward 941.0, memory_length 2000, epsilon 0.10605368339324107, time 729.0, rides 137\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 2492, reward 866.0, memory_length 2000, epsilon 0.10595823507818716, time 725.0, rides 138\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 2493, reward 673.0, memory_length 2000, epsilon 0.10586287266661679, time 724.0, rides 133\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 2494, reward 810.0, memory_length 2000, epsilon 0.10576759608121683, time 730.0, rides 145\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 2495, reward 620.0, memory_length 2000, epsilon 0.10567240524474374, time 729.0, rides 133\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 2496, reward 875.0, memory_length 2000, epsilon 0.10557730008002346, time 726.0, rides 121\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 2497, reward 992.0, memory_length 2000, epsilon 0.10548228050995144, time 725.0, rides 131\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 2498, reward 922.0, memory_length 2000, epsilon 0.10538734645749248, time 725.0, rides 128\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 2499, reward 539.0, memory_length 2000, epsilon 0.10529249784568073, time 731.0, rides 140\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 2500, reward 697.0, memory_length 2000, epsilon 0.10519773459761962, time 724.0, rides 129\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 2501, reward 726.0, memory_length 2000, epsilon 0.10510305663648176, time 730.0, rides 147\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 2502, reward 855.0, memory_length 2000, epsilon 0.10500846388550893, time 730.0, rides 131\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 2503, reward 744.0, memory_length 2000, epsilon 0.10491395626801196, time 731.0, rides 136\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 2504, reward 535.0, memory_length 2000, epsilon 0.10481953370737075, time 731.0, rides 136\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 2505, reward 603.0, memory_length 2000, epsilon 0.10472519612703411, time 726.0, rides 120\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 2506, reward 893.0, memory_length 2000, epsilon 0.10463094345051978, time 730.0, rides 129\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 2507, reward 890.0, memory_length 2000, epsilon 0.1045367756014143, time 733.0, rides 126\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 2508, reward 495.0, memory_length 2000, epsilon 0.10444269250337303, time 724.0, rides 123\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 2509, reward 395.0, memory_length 2000, epsilon 0.10434869408011999, time 732.0, rides 123\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 2510, reward 926.0, memory_length 2000, epsilon 0.10425478025544788, time 730.0, rides 130\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 2511, reward 640.0, memory_length 2000, epsilon 0.10416095095321798, time 722.0, rides 134\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2512, reward 588.0, memory_length 2000, epsilon 0.10406720609736009, time 724.0, rides 130\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 2513, reward 615.0, memory_length 2000, epsilon 0.10397354561187246, time 727.0, rides 126\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 2514, reward 852.0, memory_length 2000, epsilon 0.10387996942082177, time 726.0, rides 128\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 2515, reward 1092.0, memory_length 2000, epsilon 0.10378647744834303, time 732.0, rides 132\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 2516, reward 720.0, memory_length 2000, epsilon 0.10369306961863953, time 727.0, rides 129\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 2517, reward 955.0, memory_length 2000, epsilon 0.10359974585598275, time 721.0, rides 134\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 2518, reward 785.0, memory_length 2000, epsilon 0.10350650608471236, time 728.0, rides 131\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2519, reward 728.0, memory_length 2000, epsilon 0.10341335022923612, time 723.0, rides 133\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 2520, reward 510.0, memory_length 2000, epsilon 0.10332027821402981, time 731.0, rides 123\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 2521, reward 898.0, memory_length 2000, epsilon 0.10322728996363718, time 734.0, rides 126\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 2522, reward 834.0, memory_length 2000, epsilon 0.1031343854026699, time 733.0, rides 130\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 2523, reward 849.0, memory_length 2000, epsilon 0.1030415644558075, time 735.0, rides 126\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 2524, reward 648.0, memory_length 2000, epsilon 0.10294882704779727, time 724.0, rides 136\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2525, reward 743.0, memory_length 2000, epsilon 0.10285617310345425, time 724.0, rides 130\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 2526, reward 1047.0, memory_length 2000, epsilon 0.10276360254766115, time 729.0, rides 131\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 2527, reward 853.0, memory_length 2000, epsilon 0.10267111530536825, time 730.0, rides 127\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 2528, reward 645.0, memory_length 2000, epsilon 0.10257871130159342, time 722.0, rides 122\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 2529, reward 785.0, memory_length 2000, epsilon 0.10248639046142198, time 726.0, rides 126\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 2530, reward 897.0, memory_length 2000, epsilon 0.1023941527100067, time 735.0, rides 137\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 2531, reward 407.0, memory_length 2000, epsilon 0.10230199797256768, time 727.0, rides 128\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 2532, reward 791.0, memory_length 2000, epsilon 0.10220992617439237, time 729.0, rides 126\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 2533, reward 682.0, memory_length 2000, epsilon 0.10211793724083541, time 725.0, rides 131\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 2534, reward 694.0, memory_length 2000, epsilon 0.10202603109731866, time 730.0, rides 130\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 2535, reward 960.0, memory_length 2000, epsilon 0.10193420766933106, time 729.0, rides 150\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 2536, reward 843.0, memory_length 2000, epsilon 0.10184246688242866, time 731.0, rides 132\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 2537, reward 802.0, memory_length 2000, epsilon 0.10175080866223447, time 727.0, rides 130\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 2538, reward 928.0, memory_length 2000, epsilon 0.10165923293443846, time 731.0, rides 117\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2539, reward 601.0, memory_length 2000, epsilon 0.10156773962479747, time 739.0, rides 118\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 2540, reward 613.0, memory_length 2000, epsilon 0.10147632865913515, time 730.0, rides 126\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 2541, reward 742.0, memory_length 2000, epsilon 0.10138499996334194, time 722.0, rides 119\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2542, reward 684.0, memory_length 2000, epsilon 0.10129375346337492, time 731.0, rides 127\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 2543, reward 729.0, memory_length 2000, epsilon 0.10120258908525788, time 726.0, rides 125\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 2544, reward 734.0, memory_length 2000, epsilon 0.10111150675508114, time 726.0, rides 121\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 2545, reward 549.0, memory_length 2000, epsilon 0.10102050639900156, time 732.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2546, reward 739.0, memory_length 2000, epsilon 0.10092958794324246, time 725.0, rides 127\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 2547, reward 904.0, memory_length 2000, epsilon 0.10083875131409353, time 730.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 2548, reward 663.0, memory_length 2000, epsilon 0.10074799643791085, time 732.0, rides 117\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 2549, reward 837.0, memory_length 2000, epsilon 0.10065732324111673, time 726.0, rides 131\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 2550, reward 610.0, memory_length 2000, epsilon 0.10056673165019972, time 733.0, rides 121\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 2551, reward 469.0, memory_length 2000, epsilon 0.10047622159171454, time 726.0, rides 126\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2552, reward 995.0, memory_length 2000, epsilon 0.100385792992282, time 730.0, rides 128\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2553, reward 554.0, memory_length 2000, epsilon 0.10029544577858894, time 729.0, rides 125\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 2554, reward 840.0, memory_length 2000, epsilon 0.10020517987738821, time 727.0, rides 128\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 2555, reward 612.0, memory_length 2000, epsilon 0.10011499521549856, time 730.0, rides 131\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 2556, reward 602.0, memory_length 2000, epsilon 0.10002489171980461, time 728.0, rides 126\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 2557, reward 627.0, memory_length 2000, epsilon 0.09993486931725679, time 734.0, rides 137\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 2558, reward 831.0, memory_length 2000, epsilon 0.09984492793487125, time 734.0, rides 119\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 2559, reward 923.0, memory_length 2000, epsilon 0.09975506749972987, time 732.0, rides 130\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 2560, reward 981.0, memory_length 2000, epsilon 0.09966528793898011, time 731.0, rides 134\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 2561, reward 461.0, memory_length 2000, epsilon 0.09957558917983503, time 731.0, rides 137\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 2562, reward 1047.0, memory_length 2000, epsilon 0.09948597114957318, time 731.0, rides 133\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 2563, reward 820.0, memory_length 2000, epsilon 0.09939643377553856, time 733.0, rides 135\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 2564, reward 789.0, memory_length 2000, epsilon 0.09930697698514057, time 732.0, rides 121\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 2565, reward 1133.0, memory_length 2000, epsilon 0.09921760070585395, time 734.0, rides 141\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 2566, reward 1117.0, memory_length 2000, epsilon 0.09912830486521867, time 726.0, rides 141\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 2567, reward 749.0, memory_length 2000, epsilon 0.09903908939083998, time 729.0, rides 127\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2568, reward 754.0, memory_length 2000, epsilon 0.09894995421038823, time 726.0, rides 147\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 2569, reward 681.0, memory_length 2000, epsilon 0.09886089925159888, time 725.0, rides 136\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2570, reward 1072.0, memory_length 2000, epsilon 0.09877192444227244, time 732.0, rides 124\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2571, reward 677.0, memory_length 2000, epsilon 0.09868302971027439, time 723.0, rides 131\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 2572, reward 853.0, memory_length 2000, epsilon 0.09859421498353514, time 730.0, rides 126\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 2573, reward 1081.0, memory_length 2000, epsilon 0.09850548019004995, time 724.0, rides 125\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 2574, reward 595.0, memory_length 2000, epsilon 0.09841682525787891, time 736.0, rides 127\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 2575, reward 832.0, memory_length 2000, epsilon 0.09832825011514681, time 730.0, rides 121\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 2576, reward 906.0, memory_length 2000, epsilon 0.09823975469004319, time 732.0, rides 128\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 2577, reward 775.0, memory_length 2000, epsilon 0.09815133891082214, time 726.0, rides 134\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 2578, reward 627.0, memory_length 2000, epsilon 0.0980630027058024, time 725.0, rides 130\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 2579, reward 589.0, memory_length 2000, epsilon 0.09797474600336717, time 734.0, rides 129\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 2580, reward 647.0, memory_length 2000, epsilon 0.09788656873196414, time 724.0, rides 120\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 2581, reward 860.0, memory_length 2000, epsilon 0.09779847082010537, time 725.0, rides 137\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 2582, reward 681.0, memory_length 2000, epsilon 0.09771045219636727, time 735.0, rides 130\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 2583, reward 594.0, memory_length 2000, epsilon 0.09762251278939055, time 726.0, rides 123\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 2584, reward 349.0, memory_length 2000, epsilon 0.0975346525278801, time 727.0, rides 133\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 2585, reward 536.0, memory_length 2000, epsilon 0.097446871340605, time 730.0, rides 133\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 2586, reward 796.0, memory_length 2000, epsilon 0.09735916915639846, time 726.0, rides 128\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2587, reward 790.0, memory_length 2000, epsilon 0.0972715459041577, time 730.0, rides 126\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 2588, reward 766.0, memory_length 2000, epsilon 0.09718400151284395, time 728.0, rides 113\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 2589, reward 835.0, memory_length 2000, epsilon 0.09709653591148239, time 734.0, rides 128\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 2590, reward 965.0, memory_length 2000, epsilon 0.09700914902916205, time 727.0, rides 130\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 2591, reward 1057.0, memory_length 2000, epsilon 0.09692184079503581, time 725.0, rides 127\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 2592, reward 760.0, memory_length 2000, epsilon 0.09683461113832027, time 723.0, rides 116\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 2593, reward 707.0, memory_length 2000, epsilon 0.09674745998829579, time 736.0, rides 130\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 2594, reward 790.0, memory_length 2000, epsilon 0.09666038727430631, time 733.0, rides 133\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 2595, reward 717.0, memory_length 2000, epsilon 0.09657339292575944, time 729.0, rides 122\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 2596, reward 620.0, memory_length 2000, epsilon 0.09648647687212625, time 726.0, rides 124\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 2597, reward 525.0, memory_length 2000, epsilon 0.09639963904294133, time 723.0, rides 126\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 2598, reward 657.0, memory_length 2000, epsilon 0.09631287936780268, time 728.0, rides 125\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 2599, reward 556.0, memory_length 2000, epsilon 0.09622619777637166, time 733.0, rides 129\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2600, reward 703.0, memory_length 2000, epsilon 0.09613959419837292, time 731.0, rides 131\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 2601, reward 909.0, memory_length 2000, epsilon 0.09605306856359438, time 739.0, rides 132\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2602, reward 1108.0, memory_length 2000, epsilon 0.09596662080188714, time 729.0, rides 128\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2603, reward 832.0, memory_length 2000, epsilon 0.09588025084316544, time 727.0, rides 126\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 2604, reward 729.0, memory_length 2000, epsilon 0.0957939586174066, time 726.0, rides 125\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 2605, reward 784.0, memory_length 2000, epsilon 0.09570774405465093, time 727.0, rides 118\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 2606, reward 611.0, memory_length 2000, epsilon 0.09562160708500175, time 728.0, rides 128\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 2607, reward 762.0, memory_length 2000, epsilon 0.09553554763862525, time 731.0, rides 134\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 2608, reward 934.0, memory_length 2000, epsilon 0.09544956564575048, time 730.0, rides 135\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2609, reward 762.0, memory_length 2000, epsilon 0.09536366103666931, time 726.0, rides 134\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 2610, reward 1002.0, memory_length 2000, epsilon 0.0952778337417363, time 729.0, rides 131\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 2611, reward 1063.0, memory_length 2000, epsilon 0.09519208369136874, time 725.0, rides 130\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 2612, reward 498.0, memory_length 2000, epsilon 0.09510641081604651, time 722.0, rides 135\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 2613, reward 507.0, memory_length 2000, epsilon 0.09502081504631207, time 730.0, rides 119\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 2614, reward 815.0, memory_length 2000, epsilon 0.0949352963127704, time 724.0, rides 125\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 2615, reward 829.0, memory_length 2000, epsilon 0.09484985454608891, time 723.0, rides 139\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 2616, reward 554.0, memory_length 2000, epsilon 0.09476448967699742, time 731.0, rides 134\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 2617, reward 684.0, memory_length 2000, epsilon 0.09467920163628812, time 725.0, rides 117\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 2618, reward 794.0, memory_length 2000, epsilon 0.09459399035481546, time 727.0, rides 126\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2619, reward 832.0, memory_length 2000, epsilon 0.09450885576349612, time 734.0, rides 117\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 2620, reward 819.0, memory_length 2000, epsilon 0.09442379779330896, time 735.0, rides 132\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 2621, reward 825.0, memory_length 2000, epsilon 0.09433881637529498, time 723.0, rides 127\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 2622, reward 702.0, memory_length 2000, epsilon 0.09425391144055721, time 722.0, rides 138\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 2623, reward 881.0, memory_length 2000, epsilon 0.0941690829202607, time 729.0, rides 117\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 2624, reward 798.0, memory_length 2000, epsilon 0.09408433074563247, time 733.0, rides 118\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 2625, reward 1010.0, memory_length 2000, epsilon 0.0939996548479614, time 730.0, rides 130\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 2626, reward 500.0, memory_length 2000, epsilon 0.09391505515859823, time 733.0, rides 121\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2627, reward 835.0, memory_length 2000, epsilon 0.09383053160895549, time 728.0, rides 126\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 2628, reward 832.0, memory_length 2000, epsilon 0.09374608413050743, time 725.0, rides 124\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 2629, reward 782.0, memory_length 2000, epsilon 0.09366171265478998, time 728.0, rides 120\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 2630, reward 767.0, memory_length 2000, epsilon 0.09357741711340067, time 732.0, rides 134\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 2631, reward 878.0, memory_length 2000, epsilon 0.09349319743799861, time 733.0, rides 125\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 2632, reward 887.0, memory_length 2000, epsilon 0.0934090535603044, time 730.0, rides 118\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2633, reward 591.0, memory_length 2000, epsilon 0.09332498541210013, time 722.0, rides 130\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 2634, reward 727.0, memory_length 2000, epsilon 0.09324099292522924, time 741.0, rides 133\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 2635, reward 622.0, memory_length 2000, epsilon 0.09315707603159652, time 738.0, rides 131\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 2636, reward 1069.0, memory_length 2000, epsilon 0.09307323466316808, time 727.0, rides 125\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 2637, reward 914.0, memory_length 2000, epsilon 0.09298946875197123, time 731.0, rides 132\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 2638, reward 866.0, memory_length 2000, epsilon 0.09290577823009445, time 724.0, rides 135\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2639, reward 613.0, memory_length 2000, epsilon 0.09282216302968736, time 730.0, rides 119\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 2640, reward 1004.0, memory_length 2000, epsilon 0.09273862308296064, time 726.0, rides 132\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 2641, reward 670.0, memory_length 2000, epsilon 0.09265515832218597, time 724.0, rides 123\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 2642, reward 1043.0, memory_length 2000, epsilon 0.092571768679696, time 734.0, rides 129\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2643, reward 949.0, memory_length 2000, epsilon 0.09248845408788428, time 728.0, rides 136\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 2644, reward 900.0, memory_length 2000, epsilon 0.09240521447920519, time 724.0, rides 130\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 2645, reward 1202.0, memory_length 2000, epsilon 0.09232204978617391, time 732.0, rides 130\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2646, reward 488.0, memory_length 2000, epsilon 0.09223895994136636, time 731.0, rides 131\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2647, reward 651.0, memory_length 2000, epsilon 0.09215594487741913, time 731.0, rides 129\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 2648, reward 763.0, memory_length 2000, epsilon 0.09207300452702945, time 730.0, rides 128\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 2649, reward 872.0, memory_length 2000, epsilon 0.09199013882295512, time 727.0, rides 127\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 2650, reward 989.0, memory_length 2000, epsilon 0.09190734769801447, time 730.0, rides 131\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 2651, reward 805.0, memory_length 2000, epsilon 0.09182463108508625, time 725.0, rides 127\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 2652, reward 941.0, memory_length 2000, epsilon 0.09174198891710966, time 728.0, rides 133\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 2653, reward 636.0, memory_length 2000, epsilon 0.09165942112708426, time 732.0, rides 137\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 2654, reward 1066.0, memory_length 2000, epsilon 0.09157692764806989, time 720.0, rides 120\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 2655, reward 854.0, memory_length 2000, epsilon 0.09149450841318663, time 732.0, rides 130\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 2656, reward 624.0, memory_length 2000, epsilon 0.09141216335561475, time 728.0, rides 120\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 2657, reward 868.0, memory_length 2000, epsilon 0.0913298924085947, time 729.0, rides 135\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 2658, reward 946.0, memory_length 2000, epsilon 0.09124769550542695, time 738.0, rides 129\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 2659, reward 687.0, memory_length 2000, epsilon 0.09116557257947207, time 728.0, rides 127\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 2660, reward 761.0, memory_length 2000, epsilon 0.09108352356415055, time 725.0, rides 138\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2661, reward 723.0, memory_length 2000, epsilon 0.0910015483929428, time 726.0, rides 123\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 2662, reward 542.0, memory_length 2000, epsilon 0.09091964699938916, time 729.0, rides 138\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 2663, reward 396.0, memory_length 2000, epsilon 0.09083781931708972, time 726.0, rides 132\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 2664, reward 697.0, memory_length 2000, epsilon 0.09075606527970434, time 732.0, rides 132\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 2665, reward 761.0, memory_length 2000, epsilon 0.09067438482095261, time 730.0, rides 122\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 2666, reward 818.0, memory_length 2000, epsilon 0.09059277787461376, time 735.0, rides 118\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 2667, reward 1066.0, memory_length 2000, epsilon 0.09051124437452661, time 727.0, rides 136\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 2668, reward 879.0, memory_length 2000, epsilon 0.09042978425458953, time 727.0, rides 142\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 2669, reward 1001.0, memory_length 2000, epsilon 0.0903483974487604, time 727.0, rides 146\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 2670, reward 968.0, memory_length 2000, epsilon 0.09026708389105652, time 735.0, rides 142\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 2671, reward 712.0, memory_length 2000, epsilon 0.09018584351555457, time 731.0, rides 134\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 2672, reward 906.0, memory_length 2000, epsilon 0.09010467625639057, time 732.0, rides 117\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2673, reward 886.0, memory_length 2000, epsilon 0.09002358204775981, time 728.0, rides 132\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 2674, reward 466.0, memory_length 2000, epsilon 0.08994256082391683, time 722.0, rides 131\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 2675, reward 550.0, memory_length 2000, epsilon 0.08986161251917531, time 732.0, rides 155\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 2676, reward 947.0, memory_length 2000, epsilon 0.08978073706790805, time 729.0, rides 119\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 2677, reward 555.0, memory_length 2000, epsilon 0.08969993440454693, time 730.0, rides 146\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 2678, reward 1192.0, memory_length 2000, epsilon 0.08961920446358283, time 735.0, rides 131\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 2679, reward 745.0, memory_length 2000, epsilon 0.08953854717956561, time 732.0, rides 126\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 2680, reward 819.0, memory_length 2000, epsilon 0.089457962487104, time 733.0, rides 124\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 2681, reward 1045.0, memory_length 2000, epsilon 0.08937745032086561, time 728.0, rides 132\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2682, reward 716.0, memory_length 2000, epsilon 0.08929701061557684, time 732.0, rides 137\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2683, reward 420.0, memory_length 2000, epsilon 0.08921664330602282, time 725.0, rides 130\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 2684, reward 501.0, memory_length 2000, epsilon 0.0891363483270474, time 724.0, rides 138\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 2685, reward 896.0, memory_length 2000, epsilon 0.08905612561355306, time 735.0, rides 127\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 2686, reward 837.0, memory_length 2000, epsilon 0.08897597510050086, time 725.0, rides 131\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2687, reward 644.0, memory_length 2000, epsilon 0.0888958967229104, time 727.0, rides 119\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 2688, reward 800.0, memory_length 2000, epsilon 0.08881589041585979, time 729.0, rides 123\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 2689, reward 648.0, memory_length 2000, epsilon 0.08873595611448551, time 720.0, rides 119\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 2690, reward 837.0, memory_length 2000, epsilon 0.08865609375398247, time 728.0, rides 124\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 2691, reward 938.0, memory_length 2000, epsilon 0.08857630326960388, time 726.0, rides 122\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 2692, reward 836.0, memory_length 2000, epsilon 0.08849658459666124, time 726.0, rides 135\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 2693, reward 949.0, memory_length 2000, epsilon 0.08841693767052423, time 730.0, rides 136\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 2694, reward 807.0, memory_length 2000, epsilon 0.08833736242662076, time 734.0, rides 125\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 2695, reward 995.0, memory_length 2000, epsilon 0.0882578588004368, time 737.0, rides 133\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2696, reward 803.0, memory_length 2000, epsilon 0.0881784267275164, time 730.0, rides 139\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2697, reward 1041.0, memory_length 2000, epsilon 0.08809906614346164, time 723.0, rides 129\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 2698, reward 675.0, memory_length 2000, epsilon 0.08801977698393251, time 729.0, rides 123\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 2699, reward 877.0, memory_length 2000, epsilon 0.08794055918464697, time 736.0, rides 130\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 2700, reward 1010.0, memory_length 2000, epsilon 0.08786141268138078, time 730.0, rides 133\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 2701, reward 960.0, memory_length 2000, epsilon 0.08778233740996755, time 731.0, rides 150\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 2702, reward 1121.0, memory_length 2000, epsilon 0.08770333330629858, time 733.0, rides 128\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 2703, reward 950.0, memory_length 2000, epsilon 0.0876244003063229, time 729.0, rides 140\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 2704, reward 688.0, memory_length 2000, epsilon 0.08754553834604721, time 731.0, rides 118\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 2705, reward 676.0, memory_length 2000, epsilon 0.08746674736153577, time 731.0, rides 118\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2706, reward 724.0, memory_length 2000, epsilon 0.08738802728891039, time 723.0, rides 118\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 2707, reward 1247.0, memory_length 2000, epsilon 0.08730937806435037, time 728.0, rides 137\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 2708, reward 845.0, memory_length 2000, epsilon 0.08723079962409244, time 729.0, rides 128\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 2709, reward 975.0, memory_length 2000, epsilon 0.08715229190443076, time 730.0, rides 129\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 2710, reward 896.0, memory_length 2000, epsilon 0.08707385484171677, time 728.0, rides 131\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2711, reward 723.0, memory_length 2000, epsilon 0.08699548837235922, time 729.0, rides 144\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2712, reward 1274.0, memory_length 2000, epsilon 0.0869171924328241, time 727.0, rides 138\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 2713, reward 1173.0, memory_length 2000, epsilon 0.08683896695963456, time 732.0, rides 124\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 2714, reward 820.0, memory_length 2000, epsilon 0.08676081188937089, time 727.0, rides 134\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 2715, reward 469.0, memory_length 2000, epsilon 0.08668272715867045, time 730.0, rides 130\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 2716, reward 997.0, memory_length 2000, epsilon 0.08660471270422765, time 729.0, rides 130\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 2717, reward 747.0, memory_length 2000, epsilon 0.08652676846279385, time 728.0, rides 138\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 2718, reward 907.0, memory_length 2000, epsilon 0.08644889437117734, time 733.0, rides 136\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 2719, reward 810.0, memory_length 2000, epsilon 0.08637109036624328, time 734.0, rides 131\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 2720, reward 848.0, memory_length 2000, epsilon 0.08629335638491366, time 721.0, rides 139\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 2721, reward 686.0, memory_length 2000, epsilon 0.08621569236416723, time 728.0, rides 123\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 2722, reward 1085.0, memory_length 2000, epsilon 0.08613809824103948, time 733.0, rides 138\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 2723, reward 689.0, memory_length 2000, epsilon 0.08606057395262254, time 729.0, rides 136\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 2724, reward 729.0, memory_length 2000, epsilon 0.08598311943606518, time 724.0, rides 125\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2725, reward 1016.0, memory_length 2000, epsilon 0.08590573462857272, time 737.0, rides 134\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 2726, reward 813.0, memory_length 2000, epsilon 0.085828419467407, time 735.0, rides 126\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 2727, reward 874.0, memory_length 2000, epsilon 0.08575117388988633, time 725.0, rides 136\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 2728, reward 862.0, memory_length 2000, epsilon 0.08567399783338543, time 724.0, rides 135\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 2729, reward 882.0, memory_length 2000, epsilon 0.08559689123533538, time 724.0, rides 120\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 2730, reward 638.0, memory_length 2000, epsilon 0.08551985403322358, time 728.0, rides 119\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 2731, reward 835.0, memory_length 2000, epsilon 0.08544288616459368, time 728.0, rides 143\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 2732, reward 981.0, memory_length 2000, epsilon 0.08536598756704554, time 724.0, rides 130\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 2733, reward 835.0, memory_length 2000, epsilon 0.0852891581782352, time 733.0, rides 126\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2734, reward 939.0, memory_length 2000, epsilon 0.08521239793587478, time 729.0, rides 138\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 2735, reward 778.0, memory_length 2000, epsilon 0.08513570677773248, time 729.0, rides 140\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 2736, reward 827.0, memory_length 2000, epsilon 0.08505908464163252, time 722.0, rides 131\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 2737, reward 725.0, memory_length 2000, epsilon 0.08498253146545505, time 729.0, rides 132\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2738, reward 829.0, memory_length 2000, epsilon 0.08490604718713614, time 728.0, rides 139\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 2739, reward 928.0, memory_length 2000, epsilon 0.08482963174466772, time 739.0, rides 120\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 2740, reward 820.0, memory_length 2000, epsilon 0.08475328507609751, time 734.0, rides 130\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 2741, reward 769.0, memory_length 2000, epsilon 0.08467700711952902, time 733.0, rides 129\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 2742, reward 1031.0, memory_length 2000, epsilon 0.08460079781312145, time 731.0, rides 127\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2743, reward 821.0, memory_length 2000, epsilon 0.08452465709508963, time 723.0, rides 118\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 2744, reward 820.0, memory_length 2000, epsilon 0.08444858490370405, time 732.0, rides 130\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 2745, reward 813.0, memory_length 2000, epsilon 0.08437258117729071, time 734.0, rides 131\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 2746, reward 1039.0, memory_length 2000, epsilon 0.08429664585423115, time 720.0, rides 138\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 2747, reward 605.0, memory_length 2000, epsilon 0.08422077887296234, time 734.0, rides 136\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 2748, reward 1115.0, memory_length 2000, epsilon 0.08414498017197668, time 731.0, rides 133\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 2749, reward 675.0, memory_length 2000, epsilon 0.08406924968982189, time 736.0, rides 145\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 2750, reward 663.0, memory_length 2000, epsilon 0.08399358736510106, time 731.0, rides 145\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 2751, reward 1057.0, memory_length 2000, epsilon 0.08391799313647247, time 726.0, rides 136\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 2752, reward 748.0, memory_length 2000, epsilon 0.08384246694264964, time 726.0, rides 137\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2753, reward 790.0, memory_length 2000, epsilon 0.08376700872240125, time 740.0, rides 141\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 2754, reward 798.0, memory_length 2000, epsilon 0.0836916184145511, time 727.0, rides 140\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 2755, reward 812.0, memory_length 2000, epsilon 0.083616295957978, time 722.0, rides 130\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 2756, reward 891.0, memory_length 2000, epsilon 0.08354104129161581, time 728.0, rides 131\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 2757, reward 966.0, memory_length 2000, epsilon 0.08346585435445336, time 727.0, rides 130\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 2758, reward 925.0, memory_length 2000, epsilon 0.08339073508553435, time 732.0, rides 141\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 2759, reward 814.0, memory_length 2000, epsilon 0.08331568342395737, time 742.0, rides 124\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 2760, reward 802.0, memory_length 2000, epsilon 0.0832406993088758, time 728.0, rides 129\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 2761, reward 912.0, memory_length 2000, epsilon 0.08316578267949781, time 727.0, rides 140\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 2762, reward 910.0, memory_length 2000, epsilon 0.08309093347508627, time 726.0, rides 134\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 2763, reward 959.0, memory_length 2000, epsilon 0.0830161516349587, time 735.0, rides 124\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2764, reward 898.0, memory_length 2000, epsilon 0.08294143709848723, time 733.0, rides 139\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 2765, reward 456.0, memory_length 2000, epsilon 0.08286678980509858, time 724.0, rides 129\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2766, reward 879.0, memory_length 2000, epsilon 0.08279220969427399, time 726.0, rides 134\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 2767, reward 856.0, memory_length 2000, epsilon 0.08271769670554914, time 726.0, rides 140\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 2768, reward 968.0, memory_length 2000, epsilon 0.08264325077851414, time 732.0, rides 133\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 2769, reward 748.0, memory_length 2000, epsilon 0.08256887185281347, time 725.0, rides 138\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 2770, reward 877.0, memory_length 2000, epsilon 0.08249455986814594, time 726.0, rides 134\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 2771, reward 537.0, memory_length 2000, epsilon 0.0824203147642646, time 729.0, rides 130\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 2772, reward 631.0, memory_length 2000, epsilon 0.08234613648097676, time 722.0, rides 126\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 2773, reward 712.0, memory_length 2000, epsilon 0.08227202495814388, time 727.0, rides 152\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 2774, reward 813.0, memory_length 2000, epsilon 0.08219798013568155, time 724.0, rides 134\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 2775, reward 746.0, memory_length 2000, epsilon 0.08212400195355944, time 730.0, rides 139\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 2776, reward 745.0, memory_length 2000, epsilon 0.08205009035180123, time 729.0, rides 122\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 2777, reward 936.0, memory_length 2000, epsilon 0.08197624527048461, time 727.0, rides 129\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 2778, reward 1172.0, memory_length 2000, epsilon 0.08190246664974117, time 726.0, rides 133\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 2779, reward 990.0, memory_length 2000, epsilon 0.0818287544297564, time 729.0, rides 144\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 2780, reward 677.0, memory_length 2000, epsilon 0.08175510855076962, time 728.0, rides 131\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 2781, reward 826.0, memory_length 2000, epsilon 0.08168152895307393, time 732.0, rides 141\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 2782, reward 771.0, memory_length 2000, epsilon 0.08160801557701616, time 723.0, rides 125\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 2783, reward 788.0, memory_length 2000, epsilon 0.08153456836299684, time 730.0, rides 131\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2784, reward 679.0, memory_length 2000, epsilon 0.08146118725147014, time 728.0, rides 134\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 2785, reward 852.0, memory_length 2000, epsilon 0.08138787218294381, time 725.0, rides 132\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 2786, reward 1002.0, memory_length 2000, epsilon 0.08131462309797917, time 736.0, rides 136\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 2787, reward 682.0, memory_length 2000, epsilon 0.08124143993719099, time 730.0, rides 129\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2788, reward 794.0, memory_length 2000, epsilon 0.08116832264124751, time 731.0, rides 125\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 2789, reward 942.0, memory_length 2000, epsilon 0.0810952711508704, time 728.0, rides 133\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 2790, reward 660.0, memory_length 2000, epsilon 0.08102228540683461, time 740.0, rides 135\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 2791, reward 836.0, memory_length 2000, epsilon 0.08094936534996845, time 729.0, rides 126\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 2792, reward 897.0, memory_length 2000, epsilon 0.08087651092115349, time 734.0, rides 140\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 2793, reward 897.0, memory_length 2000, epsilon 0.08080372206132444, time 731.0, rides 139\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 2794, reward 851.0, memory_length 2000, epsilon 0.08073099871146924, time 722.0, rides 127\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 2795, reward 785.0, memory_length 2000, epsilon 0.08065834081262892, time 735.0, rides 136\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 2796, reward 795.0, memory_length 2000, epsilon 0.08058574830589756, time 722.0, rides 136\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 2797, reward 373.0, memory_length 2000, epsilon 0.08051322113242225, time 735.0, rides 138\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 2798, reward 909.0, memory_length 2000, epsilon 0.08044075923340308, time 725.0, rides 129\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 2799, reward 934.0, memory_length 2000, epsilon 0.08036836255009301, time 721.0, rides 148\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 2800, reward 1009.0, memory_length 2000, epsilon 0.08029603102379793, time 730.0, rides 133\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2801, reward 816.0, memory_length 2000, epsilon 0.0802237645958765, time 730.0, rides 130\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 2802, reward 947.0, memory_length 2000, epsilon 0.08015156320774021, time 728.0, rides 127\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 2803, reward 510.0, memory_length 2000, epsilon 0.08007942680085324, time 729.0, rides 121\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 2804, reward 826.0, memory_length 2000, epsilon 0.08000735531673248, time 732.0, rides 125\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 2805, reward 725.0, memory_length 2000, epsilon 0.07993534869694742, time 734.0, rides 139\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 2806, reward 956.0, memory_length 2000, epsilon 0.07986340688312017, time 729.0, rides 129\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 2807, reward 1018.0, memory_length 2000, epsilon 0.07979152981692536, time 732.0, rides 138\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 2808, reward 575.0, memory_length 2000, epsilon 0.07971971744009013, time 720.0, rides 123\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 2809, reward 618.0, memory_length 2000, epsilon 0.07964796969439404, time 732.0, rides 132\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 2810, reward 1209.0, memory_length 2000, epsilon 0.07957628652166908, time 732.0, rides 126\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 2811, reward 968.0, memory_length 2000, epsilon 0.07950466786379957, time 725.0, rides 131\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 2812, reward 888.0, memory_length 2000, epsilon 0.07943311366272215, time 737.0, rides 126\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 2813, reward 1086.0, memory_length 2000, epsilon 0.07936162386042571, time 725.0, rides 135\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2814, reward 817.0, memory_length 2000, epsilon 0.07929019839895132, time 726.0, rides 138\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 2815, reward 911.0, memory_length 2000, epsilon 0.07921883722039226, time 730.0, rides 126\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 2816, reward 1108.0, memory_length 2000, epsilon 0.07914754026689391, time 731.0, rides 128\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 2817, reward 640.0, memory_length 2000, epsilon 0.07907630748065371, time 731.0, rides 122\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 2818, reward 996.0, memory_length 2000, epsilon 0.07900513880392113, time 726.0, rides 127\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 2819, reward 781.0, memory_length 2000, epsilon 0.0789340341789976, time 727.0, rides 135\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2820, reward 908.0, memory_length 2000, epsilon 0.07886299354823649, time 726.0, rides 132\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 2821, reward 1185.0, memory_length 2000, epsilon 0.07879201685404308, time 724.0, rides 133\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 2822, reward 821.0, memory_length 2000, epsilon 0.07872110403887445, time 734.0, rides 136\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2823, reward 738.0, memory_length 2000, epsilon 0.07865025504523945, time 725.0, rides 127\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 2824, reward 613.0, memory_length 2000, epsilon 0.07857946981569874, time 732.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2825, reward 750.0, memory_length 2000, epsilon 0.07850874829286461, time 727.0, rides 137\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 2826, reward 1138.0, memory_length 2000, epsilon 0.07843809041940103, time 722.0, rides 136\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 2827, reward 921.0, memory_length 2000, epsilon 0.07836749613802357, time 730.0, rides 132\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 2828, reward 1196.0, memory_length 2000, epsilon 0.07829696539149936, time 727.0, rides 132\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 2829, reward 987.0, memory_length 2000, epsilon 0.07822649812264701, time 729.0, rides 140\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2830, reward 644.0, memory_length 2000, epsilon 0.07815609427433663, time 726.0, rides 135\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 2831, reward 644.0, memory_length 2000, epsilon 0.07808575378948973, time 733.0, rides 123\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2832, reward 1061.0, memory_length 2000, epsilon 0.07801547661107919, time 738.0, rides 119\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 2833, reward 932.0, memory_length 2000, epsilon 0.07794526268212922, time 740.0, rides 130\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 2834, reward 766.0, memory_length 2000, epsilon 0.0778751119457153, time 725.0, rides 140\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 2835, reward 782.0, memory_length 2000, epsilon 0.07780502434496415, time 726.0, rides 123\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 2836, reward 775.0, memory_length 2000, epsilon 0.07773499982305368, time 721.0, rides 123\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 2837, reward 540.0, memory_length 2000, epsilon 0.07766503832321293, time 728.0, rides 124\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 2838, reward 946.0, memory_length 2000, epsilon 0.07759513978872204, time 725.0, rides 122\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 2839, reward 860.0, memory_length 2000, epsilon 0.07752530416291219, time 732.0, rides 124\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 2840, reward 858.0, memory_length 2000, epsilon 0.07745553138916557, time 732.0, rides 130\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 2841, reward 861.0, memory_length 2000, epsilon 0.07738582141091532, time 727.0, rides 134\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 2842, reward 655.0, memory_length 2000, epsilon 0.0773161741716455, time 724.0, rides 116\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 2843, reward 683.0, memory_length 2000, epsilon 0.07724658961489102, time 722.0, rides 120\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 2844, reward 1264.0, memory_length 2000, epsilon 0.07717706768423761, time 729.0, rides 114\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2845, reward 1054.0, memory_length 2000, epsilon 0.0771076083233218, time 729.0, rides 141\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 2846, reward 606.0, memory_length 2000, epsilon 0.0770382114758308, time 728.0, rides 133\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 2847, reward 1149.0, memory_length 2000, epsilon 0.07696887708550255, time 723.0, rides 136\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 2848, reward 752.0, memory_length 2000, epsilon 0.0768996050961256, time 725.0, rides 138\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2849, reward 814.0, memory_length 2000, epsilon 0.0768303954515391, time 723.0, rides 120\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 2850, reward 1236.0, memory_length 2000, epsilon 0.07676124809563271, time 735.0, rides 129\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 2851, reward 855.0, memory_length 2000, epsilon 0.07669216297234664, time 738.0, rides 121\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 2852, reward 705.0, memory_length 2000, epsilon 0.07662314002567153, time 724.0, rides 109\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 2853, reward 770.0, memory_length 2000, epsilon 0.07655417919964842, time 726.0, rides 137\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 2854, reward 927.0, memory_length 2000, epsilon 0.07648528043836873, time 722.0, rides 121\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 2855, reward 658.0, memory_length 2000, epsilon 0.0764164436859742, time 726.0, rides 120\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 2856, reward 941.0, memory_length 2000, epsilon 0.07634766888665681, time 730.0, rides 144\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 2857, reward 1276.0, memory_length 2000, epsilon 0.07627895598465882, time 727.0, rides 125\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2858, reward 858.0, memory_length 2000, epsilon 0.07621030492427262, time 727.0, rides 127\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 2859, reward 815.0, memory_length 2000, epsilon 0.07614171564984078, time 733.0, rides 131\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 2860, reward 759.0, memory_length 2000, epsilon 0.07607318810575592, time 729.0, rides 116\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 2861, reward 621.0, memory_length 2000, epsilon 0.07600472223646074, time 732.0, rides 112\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 2862, reward 956.0, memory_length 2000, epsilon 0.07593631798644793, time 729.0, rides 121\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 2863, reward 892.0, memory_length 2000, epsilon 0.07586797530026013, time 727.0, rides 127\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 2864, reward 867.0, memory_length 2000, epsilon 0.0757996941224899, time 721.0, rides 118\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2865, reward 1007.0, memory_length 2000, epsilon 0.07573147439777965, time 730.0, rides 113\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 2866, reward 750.0, memory_length 2000, epsilon 0.07566331607082165, time 727.0, rides 119\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 2867, reward 912.0, memory_length 2000, epsilon 0.07559521908635791, time 726.0, rides 141\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 2868, reward 852.0, memory_length 2000, epsilon 0.07552718338918019, time 731.0, rides 122\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 2869, reward 746.0, memory_length 2000, epsilon 0.07545920892412993, time 734.0, rides 125\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 2870, reward 1090.0, memory_length 2000, epsilon 0.07539129563609821, time 730.0, rides 128\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 2871, reward 833.0, memory_length 2000, epsilon 0.07532344347002572, time 739.0, rides 123\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 2872, reward 705.0, memory_length 2000, epsilon 0.07525565237090269, time 721.0, rides 127\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 2873, reward 766.0, memory_length 2000, epsilon 0.07518792228376887, time 728.0, rides 140\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 2874, reward 901.0, memory_length 2000, epsilon 0.07512025315371348, time 728.0, rides 133\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 2875, reward 672.0, memory_length 2000, epsilon 0.07505264492587514, time 735.0, rides 127\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 2876, reward 509.0, memory_length 2000, epsilon 0.07498509754544186, time 735.0, rides 110\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 2877, reward 857.0, memory_length 2000, epsilon 0.07491761095765095, time 723.0, rides 125\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 2878, reward 756.0, memory_length 2000, epsilon 0.07485018510778907, time 736.0, rides 123\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 2879, reward 1085.0, memory_length 2000, epsilon 0.07478281994119206, time 731.0, rides 123\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 2880, reward 1002.0, memory_length 2000, epsilon 0.07471551540324498, time 730.0, rides 141\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2881, reward 941.0, memory_length 2000, epsilon 0.07464827143938206, time 728.0, rides 132\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 2882, reward 477.0, memory_length 2000, epsilon 0.07458108799508661, time 734.0, rides 126\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 2883, reward 803.0, memory_length 2000, epsilon 0.07451396501589104, time 723.0, rides 138\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2884, reward 869.0, memory_length 2000, epsilon 0.07444690244737674, time 732.0, rides 124\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 2885, reward 765.0, memory_length 2000, epsilon 0.0743799002351741, time 736.0, rides 125\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2886, reward 929.0, memory_length 2000, epsilon 0.07431295832496244, time 729.0, rides 137\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 2887, reward 599.0, memory_length 2000, epsilon 0.07424607666246998, time 728.0, rides 124\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2888, reward 619.0, memory_length 2000, epsilon 0.07417925519347375, time 732.0, rides 130\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 2889, reward 763.0, memory_length 2000, epsilon 0.07411249386379962, time 723.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2890, reward 779.0, memory_length 2000, epsilon 0.07404579261932219, time 729.0, rides 122\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 2891, reward 831.0, memory_length 2000, epsilon 0.0739791514059648, time 723.0, rides 137\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 2892, reward 1020.0, memory_length 2000, epsilon 0.07391257016969943, time 723.0, rides 134\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 2893, reward 954.0, memory_length 2000, epsilon 0.0738460488565467, time 723.0, rides 122\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2894, reward 788.0, memory_length 2000, epsilon 0.07377958741257581, time 723.0, rides 132\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 2895, reward 871.0, memory_length 2000, epsilon 0.0737131857839045, time 725.0, rides 124\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 2896, reward 866.0, memory_length 2000, epsilon 0.07364684391669898, time 735.0, rides 143\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 2897, reward 697.0, memory_length 2000, epsilon 0.07358056175717395, time 731.0, rides 120\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 2898, reward 753.0, memory_length 2000, epsilon 0.0735143392515925, time 725.0, rides 120\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 2899, reward 852.0, memory_length 2000, epsilon 0.07344817634626606, time 738.0, rides 144\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 2900, reward 832.0, memory_length 2000, epsilon 0.07338207298755442, time 731.0, rides 124\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 2901, reward 898.0, memory_length 2000, epsilon 0.07331602912186562, time 727.0, rides 129\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2902, reward 640.0, memory_length 2000, epsilon 0.07325004469565594, time 727.0, rides 126\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 2903, reward 1212.0, memory_length 2000, epsilon 0.07318411965542984, time 728.0, rides 125\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2904, reward 909.0, memory_length 2000, epsilon 0.07311825394773995, time 727.0, rides 128\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 2905, reward 585.0, memory_length 2000, epsilon 0.07305244751918698, time 722.0, rides 134\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 2906, reward 830.0, memory_length 2000, epsilon 0.07298670031641971, time 729.0, rides 118\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 2907, reward 714.0, memory_length 2000, epsilon 0.07292101228613493, time 725.0, rides 122\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 2908, reward 614.0, memory_length 2000, epsilon 0.07285538337507741, time 723.0, rides 127\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 2909, reward 937.0, memory_length 2000, epsilon 0.07278981353003984, time 727.0, rides 132\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 2910, reward 1013.0, memory_length 2000, epsilon 0.0727243026978628, time 725.0, rides 145\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2911, reward 939.0, memory_length 2000, epsilon 0.07265885082543472, time 728.0, rides 123\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 2912, reward 413.0, memory_length 2000, epsilon 0.07259345785969183, time 738.0, rides 124\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2913, reward 606.0, memory_length 2000, epsilon 0.0725281237476181, time 729.0, rides 116\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 2914, reward 826.0, memory_length 2000, epsilon 0.07246284843624524, time 731.0, rides 127\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 2915, reward 1019.0, memory_length 2000, epsilon 0.07239763187265262, time 727.0, rides 121\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 2916, reward 910.0, memory_length 2000, epsilon 0.07233247400396724, time 725.0, rides 127\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 2917, reward 962.0, memory_length 2000, epsilon 0.07226737477736367, time 732.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2918, reward 854.0, memory_length 2000, epsilon 0.07220233414006404, time 724.0, rides 122\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 2919, reward 585.0, memory_length 2000, epsilon 0.07213735203933798, time 729.0, rides 117\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 2920, reward 670.0, memory_length 2000, epsilon 0.07207242842250257, time 737.0, rides 138\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 2921, reward 613.0, memory_length 2000, epsilon 0.07200756323692231, time 725.0, rides 132\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 2922, reward 452.0, memory_length 2000, epsilon 0.07194275643000908, time 726.0, rides 140\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 2923, reward 611.0, memory_length 2000, epsilon 0.07187800794922207, time 723.0, rides 132\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2924, reward 828.0, memory_length 2000, epsilon 0.07181331774206777, time 734.0, rides 126\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 2925, reward 779.0, memory_length 2000, epsilon 0.07174868575609991, time 731.0, rides 131\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2926, reward 979.0, memory_length 2000, epsilon 0.07168411193891942, time 747.0, rides 137\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 2927, reward 876.0, memory_length 2000, epsilon 0.07161959623817439, time 726.0, rides 128\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 2928, reward 930.0, memory_length 2000, epsilon 0.07155513860156003, time 732.0, rides 130\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 2929, reward 1091.0, memory_length 2000, epsilon 0.07149073897681862, time 723.0, rides 145\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2930, reward 818.0, memory_length 2000, epsilon 0.07142639731173948, time 723.0, rides 127\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 2931, reward 684.0, memory_length 2000, epsilon 0.07136211355415892, time 733.0, rides 135\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 2932, reward 793.0, memory_length 2000, epsilon 0.07129788765196017, time 729.0, rides 130\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2933, reward 672.0, memory_length 2000, epsilon 0.07123371955307341, time 721.0, rides 133\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 2934, reward 958.0, memory_length 2000, epsilon 0.07116960920547565, time 729.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2935, reward 741.0, memory_length 2000, epsilon 0.07110555655719071, time 726.0, rides 130\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 2936, reward 889.0, memory_length 2000, epsilon 0.07104156155628924, time 726.0, rides 117\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 2937, reward 688.0, memory_length 2000, epsilon 0.07097762415088858, time 728.0, rides 118\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 2938, reward 1077.0, memory_length 2000, epsilon 0.07091374428915279, time 728.0, rides 136\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 2939, reward 1257.0, memory_length 2000, epsilon 0.07084992191929254, time 732.0, rides 126\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 2940, reward 675.0, memory_length 2000, epsilon 0.07078615698956518, time 724.0, rides 135\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 2941, reward 548.0, memory_length 2000, epsilon 0.07072244944827458, time 730.0, rides 134\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 2942, reward 724.0, memory_length 2000, epsilon 0.07065879924377112, time 728.0, rides 131\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 2943, reward 481.0, memory_length 2000, epsilon 0.07059520632445172, time 722.0, rides 123\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 2944, reward 978.0, memory_length 2000, epsilon 0.07053167063875972, time 728.0, rides 124\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 2945, reward 848.0, memory_length 2000, epsilon 0.07046819213518483, time 726.0, rides 116\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 2946, reward 785.0, memory_length 2000, epsilon 0.07040477076226316, time 732.0, rides 133\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 2947, reward 677.0, memory_length 2000, epsilon 0.07034140646857712, time 727.0, rides 133\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 2948, reward 836.0, memory_length 2000, epsilon 0.07027809920275539, time 727.0, rides 132\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 2949, reward 1098.0, memory_length 2000, epsilon 0.07021484891347292, time 738.0, rides 134\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 2950, reward 875.0, memory_length 2000, epsilon 0.0701516555494508, time 734.0, rides 144\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 2951, reward 779.0, memory_length 2000, epsilon 0.07008851905945629, time 728.0, rides 130\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2952, reward 927.0, memory_length 2000, epsilon 0.07002543939230278, time 730.0, rides 131\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 2953, reward 694.0, memory_length 2000, epsilon 0.06996241649684971, time 724.0, rides 118\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 2954, reward 906.0, memory_length 2000, epsilon 0.06989945032200255, time 730.0, rides 122\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 2955, reward 834.0, memory_length 2000, epsilon 0.06983654081671274, time 727.0, rides 134\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 2956, reward 973.0, memory_length 2000, epsilon 0.06977368792997769, time 736.0, rides 127\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 2957, reward 1077.0, memory_length 2000, epsilon 0.06971089161084071, time 733.0, rides 133\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 2958, reward 1249.0, memory_length 2000, epsilon 0.06964815180839096, time 723.0, rides 127\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 2959, reward 936.0, memory_length 2000, epsilon 0.0695854684717634, time 734.0, rides 139\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 2960, reward 802.0, memory_length 2000, epsilon 0.06952284155013881, time 732.0, rides 126\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 2961, reward 1039.0, memory_length 2000, epsilon 0.06946027099274368, time 730.0, rides 126\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 2962, reward 814.0, memory_length 2000, epsilon 0.06939775674885021, time 726.0, rides 126\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 2963, reward 945.0, memory_length 2000, epsilon 0.06933529876777625, time 729.0, rides 132\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 2964, reward 622.0, memory_length 2000, epsilon 0.06927289699888525, time 728.0, rides 142\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 2965, reward 770.0, memory_length 2000, epsilon 0.06921055139158626, time 729.0, rides 130\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2966, reward 672.0, memory_length 2000, epsilon 0.06914826189533382, time 721.0, rides 130\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 2967, reward 980.0, memory_length 2000, epsilon 0.06908602845962802, time 727.0, rides 118\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 2968, reward 990.0, memory_length 2000, epsilon 0.06902385103401436, time 727.0, rides 125\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 2969, reward 1210.0, memory_length 2000, epsilon 0.06896172956808375, time 737.0, rides 135\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 2970, reward 990.0, memory_length 2000, epsilon 0.06889966401147248, time 725.0, rides 140\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 2971, reward 1234.0, memory_length 2000, epsilon 0.06883765431386214, time 727.0, rides 137\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 2972, reward 547.0, memory_length 2000, epsilon 0.06877570042497967, time 726.0, rides 128\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 2973, reward 608.0, memory_length 2000, epsilon 0.06871380229459718, time 732.0, rides 134\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 2974, reward 825.0, memory_length 2000, epsilon 0.06865195987253205, time 731.0, rides 124\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 2975, reward 964.0, memory_length 2000, epsilon 0.06859017310864676, time 725.0, rides 142\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 2976, reward 871.0, memory_length 2000, epsilon 0.06852844195284898, time 722.0, rides 129\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 2977, reward 872.0, memory_length 2000, epsilon 0.06846676635509141, time 730.0, rides 123\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2978, reward 781.0, memory_length 2000, epsilon 0.06840514626537184, time 731.0, rides 127\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 2979, reward 667.0, memory_length 2000, epsilon 0.068343581633733, time 722.0, rides 131\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 2980, reward 783.0, memory_length 2000, epsilon 0.06828207241026264, time 720.0, rides 124\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2981, reward 615.0, memory_length 2000, epsilon 0.06822061854509341, time 720.0, rides 123\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 2982, reward 1124.0, memory_length 2000, epsilon 0.06815921998840282, time 729.0, rides 130\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 2983, reward 1068.0, memory_length 2000, epsilon 0.06809787669041326, time 726.0, rides 117\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 2984, reward 976.0, memory_length 2000, epsilon 0.06803658860139189, time 733.0, rides 129\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2985, reward 816.0, memory_length 2000, epsilon 0.06797535567165064, time 730.0, rides 115\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 2986, reward 723.0, memory_length 2000, epsilon 0.06791417785154616, time 723.0, rides 119\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 2987, reward 966.0, memory_length 2000, epsilon 0.06785305509147976, time 734.0, rides 125\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 2988, reward 907.0, memory_length 2000, epsilon 0.06779198734189743, time 722.0, rides 144\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 2989, reward 883.0, memory_length 2000, epsilon 0.06773097455328972, time 726.0, rides 132\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 2990, reward 888.0, memory_length 2000, epsilon 0.06767001667619175, time 739.0, rides 130\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2991, reward 560.0, memory_length 2000, epsilon 0.06760911366118318, time 732.0, rides 135\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 2992, reward 696.0, memory_length 2000, epsilon 0.0675482654588881, time 725.0, rides 119\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 2993, reward 933.0, memory_length 2000, epsilon 0.0674874720199751, time 726.0, rides 138\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 2994, reward 975.0, memory_length 2000, epsilon 0.06742673329515712, time 728.0, rides 121\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 2995, reward 931.0, memory_length 2000, epsilon 0.06736604923519147, time 734.0, rides 128\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 2996, reward 762.0, memory_length 2000, epsilon 0.0673054197908798, time 730.0, rides 126\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 2997, reward 666.0, memory_length 2000, epsilon 0.06724484491306801, time 732.0, rides 129\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 2998, reward 780.0, memory_length 2000, epsilon 0.06718432455264625, time 735.0, rides 127\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 2999, reward 1069.0, memory_length 2000, epsilon 0.06712385866054887, time 724.0, rides 116\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 3000, reward 845.0, memory_length 2000, epsilon 0.06706344718775438, time 738.0, rides 132\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3001, reward 540.0, memory_length 2000, epsilon 0.0670030900852854, time 722.0, rides 120\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 3002, reward 927.0, memory_length 2000, epsilon 0.06694278730420865, time 727.0, rides 118\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3003, reward 913.0, memory_length 2000, epsilon 0.06688253879563485, time 730.0, rides 140\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 3004, reward 760.0, memory_length 2000, epsilon 0.06682234451071878, time 726.0, rides 138\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 3005, reward 884.0, memory_length 2000, epsilon 0.06676220440065914, time 728.0, rides 127\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 3006, reward 818.0, memory_length 2000, epsilon 0.06670211841669854, time 733.0, rides 123\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 3007, reward 852.0, memory_length 2000, epsilon 0.06664208651012352, time 734.0, rides 124\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 3008, reward 798.0, memory_length 2000, epsilon 0.06658210863226441, time 730.0, rides 108\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 3009, reward 1025.0, memory_length 2000, epsilon 0.06652218473449537, time 726.0, rides 133\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3010, reward 546.0, memory_length 2000, epsilon 0.06646231476823432, time 729.0, rides 127\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3011, reward 846.0, memory_length 2000, epsilon 0.06640249868494291, time 730.0, rides 124\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 3012, reward 827.0, memory_length 2000, epsilon 0.06634273643612647, time 730.0, rides 116\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 3013, reward 933.0, memory_length 2000, epsilon 0.06628302797333395, time 733.0, rides 117\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 3014, reward 864.0, memory_length 2000, epsilon 0.06622337324815795, time 733.0, rides 123\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3015, reward 793.0, memory_length 2000, epsilon 0.06616377221223461, time 729.0, rides 130\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 3016, reward 1123.0, memory_length 2000, epsilon 0.06610422481724361, time 735.0, rides 150\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3017, reward 835.0, memory_length 2000, epsilon 0.06604473101490808, time 731.0, rides 129\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3018, reward 858.0, memory_length 2000, epsilon 0.06598529075699466, time 730.0, rides 144\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 3019, reward 873.0, memory_length 2000, epsilon 0.06592590399531337, time 738.0, rides 128\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 3020, reward 862.0, memory_length 2000, epsilon 0.06586657068171758, time 735.0, rides 126\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 3021, reward 824.0, memory_length 2000, epsilon 0.06580729076810404, time 730.0, rides 138\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 3022, reward 845.0, memory_length 2000, epsilon 0.06574806420641274, time 732.0, rides 125\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 3023, reward 836.0, memory_length 2000, epsilon 0.06568889094862697, time 731.0, rides 124\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 3024, reward 881.0, memory_length 2000, epsilon 0.0656297709467732, time 731.0, rides 118\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 3025, reward 904.0, memory_length 2000, epsilon 0.06557070415292111, time 724.0, rides 135\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3026, reward 726.0, memory_length 2000, epsilon 0.06551169051918349, time 725.0, rides 121\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3027, reward 694.0, memory_length 2000, epsilon 0.06545272999771622, time 728.0, rides 130\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 3028, reward 1105.0, memory_length 2000, epsilon 0.06539382254071827, time 723.0, rides 130\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 3029, reward 941.0, memory_length 2000, epsilon 0.06533496810043161, time 727.0, rides 132\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 3030, reward 693.0, memory_length 2000, epsilon 0.06527616662914122, time 731.0, rides 145\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 3031, reward 654.0, memory_length 2000, epsilon 0.065217418079175, time 726.0, rides 131\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 3032, reward 849.0, memory_length 2000, epsilon 0.06515872240290374, time 733.0, rides 130\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 3033, reward 559.0, memory_length 2000, epsilon 0.06510007955274112, time 730.0, rides 124\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 3034, reward 972.0, memory_length 2000, epsilon 0.06504148948114366, time 738.0, rides 144\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 3035, reward 833.0, memory_length 2000, epsilon 0.06498295214061063, time 732.0, rides 125\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 3036, reward 1071.0, memory_length 2000, epsilon 0.06492446748368408, time 733.0, rides 142\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 3037, reward 546.0, memory_length 2000, epsilon 0.06486603546294877, time 738.0, rides 125\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3038, reward 536.0, memory_length 2000, epsilon 0.06480765603103211, time 728.0, rides 122\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 3039, reward 828.0, memory_length 2000, epsilon 0.06474932914060419, time 735.0, rides 129\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 3040, reward 752.0, memory_length 2000, epsilon 0.06469105474437764, time 732.0, rides 120\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 3041, reward 989.0, memory_length 2000, epsilon 0.0646328327951077, time 725.0, rides 131\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 3042, reward 977.0, memory_length 2000, epsilon 0.0645746632455921, time 728.0, rides 134\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 3043, reward 1221.0, memory_length 2000, epsilon 0.06451654604867108, time 723.0, rides 137\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 3044, reward 771.0, memory_length 2000, epsilon 0.06445848115722727, time 724.0, rides 127\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 3045, reward 824.0, memory_length 2000, epsilon 0.06440046852418577, time 731.0, rides 131\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 3046, reward 1013.0, memory_length 2000, epsilon 0.064342508102514, time 722.0, rides 143\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 3047, reward 1099.0, memory_length 2000, epsilon 0.06428459984522174, time 727.0, rides 139\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 3048, reward 1249.0, memory_length 2000, epsilon 0.06422674370536104, time 724.0, rides 134\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3049, reward 700.0, memory_length 2000, epsilon 0.06416893963602621, time 725.0, rides 131\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3050, reward 897.0, memory_length 2000, epsilon 0.0641111875903538, time 728.0, rides 133\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 3051, reward 1414.0, memory_length 2000, epsilon 0.06405348752152247, time 725.0, rides 124\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 3052, reward 850.0, memory_length 2000, epsilon 0.0639958393827531, time 729.0, rides 122\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 3053, reward 711.0, memory_length 2000, epsilon 0.06393824312730863, time 733.0, rides 138\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 3054, reward 882.0, memory_length 2000, epsilon 0.06388069870849405, time 729.0, rides 129\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3055, reward 748.0, memory_length 2000, epsilon 0.06382320607965641, time 727.0, rides 130\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 3056, reward 719.0, memory_length 2000, epsilon 0.06376576519418473, time 731.0, rides 130\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 3057, reward 747.0, memory_length 2000, epsilon 0.06370837600550996, time 727.0, rides 128\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3058, reward 959.0, memory_length 2000, epsilon 0.063651038467105, time 732.0, rides 135\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 3059, reward 1013.0, memory_length 2000, epsilon 0.0635937525324846, time 728.0, rides 129\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 3060, reward 699.0, memory_length 2000, epsilon 0.06353651815520536, time 724.0, rides 124\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 3061, reward 812.0, memory_length 2000, epsilon 0.06347933528886568, time 735.0, rides 138\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 3062, reward 668.0, memory_length 2000, epsilon 0.0634222038871057, time 732.0, rides 130\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 3063, reward 556.0, memory_length 2000, epsilon 0.06336512390360731, time 733.0, rides 129\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 3064, reward 692.0, memory_length 2000, epsilon 0.06330809529209407, time 728.0, rides 129\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 3065, reward 779.0, memory_length 2000, epsilon 0.06325111800633118, time 734.0, rides 124\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 3066, reward 712.0, memory_length 2000, epsilon 0.06319419200012548, time 729.0, rides 126\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 3067, reward 924.0, memory_length 2000, epsilon 0.06313731722732537, time 732.0, rides 120\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 3068, reward 909.0, memory_length 2000, epsilon 0.06308049364182078, time 727.0, rides 132\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 3069, reward 960.0, memory_length 2000, epsilon 0.06302372119754314, time 729.0, rides 125\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3070, reward 677.0, memory_length 2000, epsilon 0.06296699984846535, time 724.0, rides 123\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 3071, reward 887.0, memory_length 2000, epsilon 0.06291032954860173, time 737.0, rides 128\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3072, reward 1018.0, memory_length 2000, epsilon 0.06285371025200799, time 729.0, rides 124\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3073, reward 939.0, memory_length 2000, epsilon 0.06279714191278118, time 725.0, rides 145\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 3074, reward 657.0, memory_length 2000, epsilon 0.06274062448505968, time 730.0, rides 134\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3075, reward 791.0, memory_length 2000, epsilon 0.06268415792302312, time 729.0, rides 130\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 3076, reward 1000.0, memory_length 2000, epsilon 0.0626277421808924, time 725.0, rides 132\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 3077, reward 1120.0, memory_length 2000, epsilon 0.06257137721292959, time 727.0, rides 134\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 3078, reward 880.0, memory_length 2000, epsilon 0.06251506297343795, time 728.0, rides 127\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 3079, reward 855.0, memory_length 2000, epsilon 0.06245879941676186, time 731.0, rides 130\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3080, reward 644.0, memory_length 2000, epsilon 0.06240258649728677, time 735.0, rides 128\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 3081, reward 848.0, memory_length 2000, epsilon 0.06234642416943921, time 726.0, rides 125\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 3082, reward 962.0, memory_length 2000, epsilon 0.062290312387686717, time 731.0, rides 124\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 3083, reward 1034.0, memory_length 2000, epsilon 0.0622342511065378, time 734.0, rides 117\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 3084, reward 448.0, memory_length 2000, epsilon 0.06217824028054191, time 734.0, rides 122\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 3085, reward 667.0, memory_length 2000, epsilon 0.06212227986428942, time 728.0, rides 135\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3086, reward 723.0, memory_length 2000, epsilon 0.06206636981241156, time 736.0, rides 141\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 3087, reward 601.0, memory_length 2000, epsilon 0.06201051007958039, time 730.0, rides 127\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 3088, reward 696.0, memory_length 2000, epsilon 0.061954700620508764, time 733.0, rides 131\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3089, reward 982.0, memory_length 2000, epsilon 0.06189894138995031, time 727.0, rides 129\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 3090, reward 1026.0, memory_length 2000, epsilon 0.06184323234269935, time 726.0, rides 150\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 3091, reward 565.0, memory_length 2000, epsilon 0.061787573433590925, time 725.0, rides 126\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 3092, reward 577.0, memory_length 2000, epsilon 0.06173196461750069, time 728.0, rides 121\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 3093, reward 708.0, memory_length 2000, epsilon 0.06167640584934494, time 723.0, rides 125\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 3094, reward 638.0, memory_length 2000, epsilon 0.06162089708408053, time 724.0, rides 141\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3095, reward 1044.0, memory_length 2000, epsilon 0.061565438276704854, time 738.0, rides 145\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 3096, reward 635.0, memory_length 2000, epsilon 0.06151002938225582, time 732.0, rides 132\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 3097, reward 792.0, memory_length 2000, epsilon 0.061454670355811786, time 730.0, rides 125\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 3098, reward 740.0, memory_length 2000, epsilon 0.061399361152491554, time 725.0, rides 135\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 3099, reward 907.0, memory_length 2000, epsilon 0.06134410172745431, time 724.0, rides 123\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 3100, reward 1016.0, memory_length 2000, epsilon 0.0612888920358996, time 732.0, rides 131\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 3101, reward 1011.0, memory_length 2000, epsilon 0.06123373203306729, time 727.0, rides 124\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 3102, reward 1018.0, memory_length 2000, epsilon 0.06117862167423753, time 734.0, rides 122\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 3103, reward 677.0, memory_length 2000, epsilon 0.061123560914730715, time 739.0, rides 119\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 3104, reward 796.0, memory_length 2000, epsilon 0.06106854970990746, time 730.0, rides 127\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 3105, reward 1073.0, memory_length 2000, epsilon 0.06101358801516854, time 729.0, rides 129\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 3106, reward 1163.0, memory_length 2000, epsilon 0.06095867578595489, time 729.0, rides 123\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3107, reward 856.0, memory_length 2000, epsilon 0.06090381297774753, time 728.0, rides 127\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 3108, reward 865.0, memory_length 2000, epsilon 0.06084899954606756, time 724.0, rides 131\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 3109, reward 1054.0, memory_length 2000, epsilon 0.0607942354464761, time 729.0, rides 125\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 3110, reward 828.0, memory_length 2000, epsilon 0.06073952063457427, time 724.0, rides 130\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 3111, reward 958.0, memory_length 2000, epsilon 0.06068485506600316, time 728.0, rides 145\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 3112, reward 699.0, memory_length 2000, epsilon 0.06063023869644375, time 731.0, rides 142\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 3113, reward 772.0, memory_length 2000, epsilon 0.06057567148161695, time 727.0, rides 119\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 3114, reward 866.0, memory_length 2000, epsilon 0.0605211533772835, time 738.0, rides 128\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 3115, reward 1118.0, memory_length 2000, epsilon 0.06046668433924394, time 729.0, rides 133\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 3116, reward 955.0, memory_length 2000, epsilon 0.06041226432333862, time 724.0, rides 125\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 3117, reward 781.0, memory_length 2000, epsilon 0.06035789328544761, time 736.0, rides 121\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 3118, reward 981.0, memory_length 2000, epsilon 0.06030357118149071, time 730.0, rides 116\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 3119, reward 933.0, memory_length 2000, epsilon 0.06024929796742737, time 732.0, rides 133\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 3120, reward 845.0, memory_length 2000, epsilon 0.06019507359925668, time 722.0, rides 125\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3121, reward 773.0, memory_length 2000, epsilon 0.06014089803301735, time 727.0, rides 129\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 3122, reward 833.0, memory_length 2000, epsilon 0.06008677122478764, time 740.0, rides 132\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3123, reward 743.0, memory_length 2000, epsilon 0.06003269313068533, time 732.0, rides 139\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 3124, reward 941.0, memory_length 2000, epsilon 0.05997866370686771, time 728.0, rides 133\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3125, reward 958.0, memory_length 2000, epsilon 0.05992468290953153, time 726.0, rides 120\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 3126, reward 858.0, memory_length 2000, epsilon 0.059870750694912954, time 728.0, rides 132\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 3127, reward 954.0, memory_length 2000, epsilon 0.05981686701928753, time 727.0, rides 129\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3128, reward 638.0, memory_length 2000, epsilon 0.05976303183897017, time 730.0, rides 151\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 3129, reward 889.0, memory_length 2000, epsilon 0.0597092451103151, time 727.0, rides 139\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 3130, reward 945.0, memory_length 2000, epsilon 0.05965550678971582, time 722.0, rides 125\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 3131, reward 1120.0, memory_length 2000, epsilon 0.059601816833605076, time 728.0, rides 131\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 3132, reward 832.0, memory_length 2000, epsilon 0.05954817519845483, time 732.0, rides 130\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 3133, reward 702.0, memory_length 2000, epsilon 0.05949458184077622, time 729.0, rides 117\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 3134, reward 940.0, memory_length 2000, epsilon 0.05944103671711952, time 729.0, rides 145\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3135, reward 926.0, memory_length 2000, epsilon 0.059387539784074114, time 730.0, rides 124\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3136, reward 912.0, memory_length 2000, epsilon 0.059334090998268446, time 721.0, rides 138\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 3137, reward 851.0, memory_length 2000, epsilon 0.059280690316370004, time 729.0, rides 144\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 3138, reward 738.0, memory_length 2000, epsilon 0.05922733769508527, time 725.0, rides 135\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 3139, reward 906.0, memory_length 2000, epsilon 0.05917403309115969, time 725.0, rides 120\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 3140, reward 908.0, memory_length 2000, epsilon 0.059120776461377644, time 731.0, rides 119\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 3141, reward 763.0, memory_length 2000, epsilon 0.059067567762562403, time 720.0, rides 128\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 3142, reward 673.0, memory_length 2000, epsilon 0.059014406951576094, time 731.0, rides 129\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 3143, reward 849.0, memory_length 2000, epsilon 0.05896129398531968, time 729.0, rides 135\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 3144, reward 832.0, memory_length 2000, epsilon 0.05890822882073289, time 729.0, rides 121\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 3145, reward 667.0, memory_length 2000, epsilon 0.05885521141479423, time 725.0, rides 135\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 3146, reward 842.0, memory_length 2000, epsilon 0.058802241724520914, time 726.0, rides 127\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 3147, reward 1133.0, memory_length 2000, epsilon 0.058749319706968846, time 729.0, rides 130\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 3148, reward 550.0, memory_length 2000, epsilon 0.05869644531923257, time 727.0, rides 135\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 3149, reward 753.0, memory_length 2000, epsilon 0.05864361851844526, time 727.0, rides 136\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 3150, reward 750.0, memory_length 2000, epsilon 0.05859083926177866, time 731.0, rides 122\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 3151, reward 548.0, memory_length 2000, epsilon 0.05853810750644306, time 731.0, rides 139\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 3152, reward 737.0, memory_length 2000, epsilon 0.05848542320968726, time 730.0, rides 128\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 3153, reward 818.0, memory_length 2000, epsilon 0.058432786328798544, time 731.0, rides 127\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 3154, reward 702.0, memory_length 2000, epsilon 0.058380196821102626, time 738.0, rides 145\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 3155, reward 782.0, memory_length 2000, epsilon 0.05832765464396363, time 731.0, rides 132\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 3156, reward 1078.0, memory_length 2000, epsilon 0.05827515975478406, time 733.0, rides 129\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3157, reward 724.0, memory_length 2000, epsilon 0.05822271211100476, time 730.0, rides 131\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 3158, reward 723.0, memory_length 2000, epsilon 0.05817031167010485, time 722.0, rides 146\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 3159, reward 774.0, memory_length 2000, epsilon 0.05811795838960175, time 727.0, rides 134\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 3160, reward 985.0, memory_length 2000, epsilon 0.05806565222705111, time 726.0, rides 148\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 3161, reward 929.0, memory_length 2000, epsilon 0.05801339314004676, time 725.0, rides 131\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 3162, reward 845.0, memory_length 2000, epsilon 0.05796118108622072, time 733.0, rides 128\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 3163, reward 648.0, memory_length 2000, epsilon 0.057909016023243116, time 734.0, rides 132\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 3164, reward 540.0, memory_length 2000, epsilon 0.057856897908822195, time 726.0, rides 134\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 3165, reward 834.0, memory_length 2000, epsilon 0.057804826700704255, time 729.0, rides 143\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 3166, reward 936.0, memory_length 2000, epsilon 0.05775280235667362, time 734.0, rides 125\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3167, reward 720.0, memory_length 2000, epsilon 0.05770082483455261, time 723.0, rides 123\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 3168, reward 973.0, memory_length 2000, epsilon 0.057648894092201516, time 730.0, rides 138\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 3169, reward 964.0, memory_length 2000, epsilon 0.05759701008751853, time 734.0, rides 124\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 3170, reward 1241.0, memory_length 2000, epsilon 0.05754517277843976, time 728.0, rides 139\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 3171, reward 949.0, memory_length 2000, epsilon 0.05749338212293917, time 729.0, rides 128\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 3172, reward 924.0, memory_length 2000, epsilon 0.05744163807902852, time 723.0, rides 135\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 3173, reward 737.0, memory_length 2000, epsilon 0.0573899406047574, time 737.0, rides 127\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3174, reward 717.0, memory_length 2000, epsilon 0.05733828965821312, time 726.0, rides 135\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 3175, reward 846.0, memory_length 2000, epsilon 0.057286685197520726, time 735.0, rides 131\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 3176, reward 999.0, memory_length 2000, epsilon 0.057235127180842955, time 734.0, rides 138\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 3177, reward 873.0, memory_length 2000, epsilon 0.05718361556638019, time 729.0, rides 128\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 3178, reward 933.0, memory_length 2000, epsilon 0.05713215031237045, time 725.0, rides 132\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 3179, reward 859.0, memory_length 2000, epsilon 0.057080731377089314, time 731.0, rides 147\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 3180, reward 921.0, memory_length 2000, epsilon 0.05702935871884993, time 731.0, rides 133\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3181, reward 1152.0, memory_length 2000, epsilon 0.05697803229600297, time 727.0, rides 124\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 3182, reward 849.0, memory_length 2000, epsilon 0.056926752066936565, time 725.0, rides 139\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 3183, reward 975.0, memory_length 2000, epsilon 0.05687551799007632, time 729.0, rides 135\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 3184, reward 679.0, memory_length 2000, epsilon 0.05682433002388525, time 730.0, rides 121\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 3185, reward 782.0, memory_length 2000, epsilon 0.05677318812686375, time 722.0, rides 140\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3186, reward 925.0, memory_length 2000, epsilon 0.056722092257549574, time 726.0, rides 130\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3187, reward 955.0, memory_length 2000, epsilon 0.056671042374517776, time 725.0, rides 127\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 3188, reward 687.0, memory_length 2000, epsilon 0.05662003843638071, time 733.0, rides 125\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 3189, reward 708.0, memory_length 2000, epsilon 0.056569080401787965, time 736.0, rides 131\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 3190, reward 817.0, memory_length 2000, epsilon 0.056518168229426353, time 732.0, rides 124\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3191, reward 1025.0, memory_length 2000, epsilon 0.05646730187801987, time 734.0, rides 130\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 3192, reward 604.0, memory_length 2000, epsilon 0.056416481306329654, time 725.0, rides 123\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 3193, reward 1024.0, memory_length 2000, epsilon 0.056365706473153955, time 730.0, rides 132\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 3194, reward 853.0, memory_length 2000, epsilon 0.05631497733732812, time 733.0, rides 120\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3195, reward 795.0, memory_length 2000, epsilon 0.05626429385772452, time 739.0, rides 122\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 3196, reward 806.0, memory_length 2000, epsilon 0.05621365599325257, time 732.0, rides 131\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3197, reward 799.0, memory_length 2000, epsilon 0.056163063702858645, time 727.0, rides 142\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 3198, reward 766.0, memory_length 2000, epsilon 0.056112516945526075, time 722.0, rides 131\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 3199, reward 965.0, memory_length 2000, epsilon 0.0560620156802751, time 731.0, rides 122\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3200, reward 983.0, memory_length 2000, epsilon 0.05601155986616285, time 730.0, rides 117\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 3201, reward 668.0, memory_length 2000, epsilon 0.055961149462283304, time 734.0, rides 115\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 3202, reward 577.0, memory_length 2000, epsilon 0.05591078442776725, time 724.0, rides 135\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3203, reward 691.0, memory_length 2000, epsilon 0.05586046472178226, time 730.0, rides 133\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3204, reward 753.0, memory_length 2000, epsilon 0.05581019030353265, time 732.0, rides 137\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 3205, reward 747.0, memory_length 2000, epsilon 0.05575996113225947, time 732.0, rides 120\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 3206, reward 925.0, memory_length 2000, epsilon 0.05570977716724044, time 730.0, rides 126\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 3207, reward 1048.0, memory_length 2000, epsilon 0.05565963836778992, time 729.0, rides 132\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 3208, reward 620.0, memory_length 2000, epsilon 0.05560954469325891, time 726.0, rides 140\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 3209, reward 810.0, memory_length 2000, epsilon 0.055559496103034976, time 728.0, rides 121\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 3210, reward 700.0, memory_length 2000, epsilon 0.05550949255654224, time 727.0, rides 125\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 3211, reward 780.0, memory_length 2000, epsilon 0.05545953401324136, time 725.0, rides 130\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 3212, reward 912.0, memory_length 2000, epsilon 0.05540962043262944, time 727.0, rides 139\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 3213, reward 736.0, memory_length 2000, epsilon 0.055359751774240074, time 731.0, rides 135\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 3214, reward 828.0, memory_length 2000, epsilon 0.055309927997643255, time 734.0, rides 143\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 3215, reward 836.0, memory_length 2000, epsilon 0.05526014906244538, time 744.0, rides 137\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 3216, reward 917.0, memory_length 2000, epsilon 0.055210414928289174, time 735.0, rides 139\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 3217, reward 494.0, memory_length 2000, epsilon 0.05516072555485371, time 732.0, rides 133\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3218, reward 817.0, memory_length 2000, epsilon 0.05511108090185434, time 724.0, rides 132\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 3219, reward 669.0, memory_length 2000, epsilon 0.05506148092904267, time 724.0, rides 130\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3220, reward 848.0, memory_length 2000, epsilon 0.05501192559620653, time 727.0, rides 129\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 3221, reward 1181.0, memory_length 2000, epsilon 0.054962414863169946, time 735.0, rides 144\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 3222, reward 695.0, memory_length 2000, epsilon 0.054912948689793094, time 728.0, rides 129\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 3223, reward 1044.0, memory_length 2000, epsilon 0.054863527035972276, time 737.0, rides 124\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 3224, reward 841.0, memory_length 2000, epsilon 0.0548141498616399, time 727.0, rides 141\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 3225, reward 967.0, memory_length 2000, epsilon 0.05476481712676442, time 733.0, rides 128\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 3226, reward 771.0, memory_length 2000, epsilon 0.05471552879135033, time 728.0, rides 144\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 3227, reward 881.0, memory_length 2000, epsilon 0.054666284815438115, time 728.0, rides 150\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 3228, reward 1040.0, memory_length 2000, epsilon 0.05461708515910422, time 729.0, rides 124\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 3229, reward 890.0, memory_length 2000, epsilon 0.05456792978246102, time 722.0, rides 129\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 3230, reward 702.0, memory_length 2000, epsilon 0.0545188186456568, time 721.0, rides 139\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3231, reward 406.0, memory_length 2000, epsilon 0.05446975170887571, time 730.0, rides 126\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3232, reward 749.0, memory_length 2000, epsilon 0.05442072893233772, time 737.0, rides 146\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 3233, reward 696.0, memory_length 2000, epsilon 0.05437175027629862, time 733.0, rides 129\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 3234, reward 823.0, memory_length 2000, epsilon 0.05432281570104995, time 733.0, rides 135\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3235, reward 642.0, memory_length 2000, epsilon 0.05427392516691901, time 724.0, rides 127\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 3236, reward 873.0, memory_length 2000, epsilon 0.05422507863426878, time 729.0, rides 123\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 3237, reward 1031.0, memory_length 2000, epsilon 0.05417627606349794, time 728.0, rides 125\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 3238, reward 712.0, memory_length 2000, epsilon 0.054127517415040786, time 733.0, rides 132\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 3239, reward 958.0, memory_length 2000, epsilon 0.05407880264936725, time 727.0, rides 128\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 3240, reward 929.0, memory_length 2000, epsilon 0.054030131726982816, time 732.0, rides 135\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 3241, reward 907.0, memory_length 2000, epsilon 0.05398150460842853, time 729.0, rides 128\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 3242, reward 817.0, memory_length 2000, epsilon 0.053932921254280945, time 729.0, rides 138\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 3243, reward 1017.0, memory_length 2000, epsilon 0.05388438162515209, time 732.0, rides 130\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 3244, reward 619.0, memory_length 2000, epsilon 0.053835885681689455, time 730.0, rides 129\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3245, reward 704.0, memory_length 2000, epsilon 0.053787433384575936, time 722.0, rides 121\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 3246, reward 909.0, memory_length 2000, epsilon 0.05373902469452982, time 737.0, rides 129\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 3247, reward 702.0, memory_length 2000, epsilon 0.05369065957230474, time 725.0, rides 133\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 3248, reward 913.0, memory_length 2000, epsilon 0.05364233797868966, time 727.0, rides 132\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 3249, reward 872.0, memory_length 2000, epsilon 0.05359405987450884, time 742.0, rides 132\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 3250, reward 1112.0, memory_length 2000, epsilon 0.05354582522062178, time 728.0, rides 134\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 3251, reward 653.0, memory_length 2000, epsilon 0.053497633977923224, time 733.0, rides 122\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 3252, reward 1012.0, memory_length 2000, epsilon 0.05344948610734309, time 732.0, rides 133\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 3253, reward 879.0, memory_length 2000, epsilon 0.05340138156984648, time 728.0, rides 143\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 3254, reward 972.0, memory_length 2000, epsilon 0.05335332032643362, time 731.0, rides 137\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3255, reward 1263.0, memory_length 2000, epsilon 0.05330530233813983, time 725.0, rides 132\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 3256, reward 1123.0, memory_length 2000, epsilon 0.0532573275660355, time 729.0, rides 141\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 3257, reward 940.0, memory_length 2000, epsilon 0.05320939597122607, time 725.0, rides 150\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 3258, reward 1057.0, memory_length 2000, epsilon 0.05316150751485197, time 727.0, rides 129\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3259, reward 807.0, memory_length 2000, epsilon 0.053113662158088604, time 726.0, rides 134\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 3260, reward 1013.0, memory_length 2000, epsilon 0.053065859862146326, time 723.0, rides 133\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 3261, reward 752.0, memory_length 2000, epsilon 0.053018100588270396, time 727.0, rides 128\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 3262, reward 765.0, memory_length 2000, epsilon 0.05297038429774095, time 731.0, rides 131\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 3263, reward 747.0, memory_length 2000, epsilon 0.05292271095187299, time 722.0, rides 133\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3264, reward 1021.0, memory_length 2000, epsilon 0.0528750805120163, time 732.0, rides 116\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 3265, reward 727.0, memory_length 2000, epsilon 0.052827492939555486, time 728.0, rides 121\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 3266, reward 556.0, memory_length 2000, epsilon 0.052779948195909886, time 732.0, rides 131\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 3267, reward 943.0, memory_length 2000, epsilon 0.052732446242533565, time 732.0, rides 140\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 3268, reward 776.0, memory_length 2000, epsilon 0.05268498704091528, time 731.0, rides 135\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 3269, reward 963.0, memory_length 2000, epsilon 0.05263757055257846, time 735.0, rides 143\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3270, reward 584.0, memory_length 2000, epsilon 0.052590196739081135, time 727.0, rides 120\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 3271, reward 677.0, memory_length 2000, epsilon 0.05254286556201596, time 730.0, rides 126\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 3272, reward 986.0, memory_length 2000, epsilon 0.05249557698301015, time 728.0, rides 126\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 3273, reward 966.0, memory_length 2000, epsilon 0.05244833096372544, time 729.0, rides 145\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 3274, reward 866.0, memory_length 2000, epsilon 0.05240112746585809, time 735.0, rides 125\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 3275, reward 1115.0, memory_length 2000, epsilon 0.052353966451138816, time 728.0, rides 140\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3276, reward 1159.0, memory_length 2000, epsilon 0.05230684788133279, time 731.0, rides 139\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 3277, reward 944.0, memory_length 2000, epsilon 0.05225977171823959, time 722.0, rides 133\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 3278, reward 887.0, memory_length 2000, epsilon 0.05221273792369317, time 738.0, rides 133\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 3279, reward 630.0, memory_length 2000, epsilon 0.052165746459561846, time 721.0, rides 131\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 3280, reward 773.0, memory_length 2000, epsilon 0.052118797287748236, time 722.0, rides 132\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 3281, reward 1051.0, memory_length 2000, epsilon 0.052071890370189264, time 727.0, rides 135\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3282, reward 980.0, memory_length 2000, epsilon 0.05202502566885609, time 723.0, rides 137\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 3283, reward 975.0, memory_length 2000, epsilon 0.05197820314575412, time 737.0, rides 133\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 3284, reward 905.0, memory_length 2000, epsilon 0.05193142276292294, time 731.0, rides 136\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 3285, reward 954.0, memory_length 2000, epsilon 0.05188468448243631, time 730.0, rides 129\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 3286, reward 1044.0, memory_length 2000, epsilon 0.05183798826640211, time 728.0, rides 129\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 3287, reward 982.0, memory_length 2000, epsilon 0.05179133407696235, time 729.0, rides 121\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3288, reward 498.0, memory_length 2000, epsilon 0.05174472187629308, time 729.0, rides 120\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3289, reward 934.0, memory_length 2000, epsilon 0.05169815162660442, time 735.0, rides 111\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 3290, reward 1095.0, memory_length 2000, epsilon 0.051651623290140475, time 730.0, rides 136\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 3291, reward 961.0, memory_length 2000, epsilon 0.051605136829179346, time 729.0, rides 145\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 3292, reward 1027.0, memory_length 2000, epsilon 0.05155869220603308, time 729.0, rides 135\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 3293, reward 717.0, memory_length 2000, epsilon 0.05151228938304765, time 721.0, rides 122\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 3294, reward 905.0, memory_length 2000, epsilon 0.05146592832260291, time 737.0, rides 142\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 3295, reward 742.0, memory_length 2000, epsilon 0.05141960898711257, time 726.0, rides 133\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 3296, reward 728.0, memory_length 2000, epsilon 0.05137333133902417, time 727.0, rides 127\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 3297, reward 875.0, memory_length 2000, epsilon 0.05132709534081905, time 729.0, rides 120\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 3298, reward 828.0, memory_length 2000, epsilon 0.05128090095501231, time 729.0, rides 125\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3299, reward 646.0, memory_length 2000, epsilon 0.0512347481441528, time 728.0, rides 130\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 3300, reward 985.0, memory_length 2000, epsilon 0.05118863687082306, time 733.0, rides 135\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 3301, reward 1074.0, memory_length 2000, epsilon 0.05114256709763932, time 730.0, rides 127\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 3302, reward 1193.0, memory_length 2000, epsilon 0.05109653878725144, time 728.0, rides 133\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3303, reward 712.0, memory_length 2000, epsilon 0.051050551902342915, time 732.0, rides 125\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3304, reward 944.0, memory_length 2000, epsilon 0.05100460640563081, time 730.0, rides 138\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 3305, reward 636.0, memory_length 2000, epsilon 0.05095870225986574, time 722.0, rides 127\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 3306, reward 966.0, memory_length 2000, epsilon 0.05091283942783186, time 730.0, rides 138\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 3307, reward 830.0, memory_length 2000, epsilon 0.05086701787234681, time 725.0, rides 127\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 3308, reward 1117.0, memory_length 2000, epsilon 0.0508212375562617, time 729.0, rides 138\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 3309, reward 912.0, memory_length 2000, epsilon 0.05077549844246106, time 729.0, rides 126\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 3310, reward 430.0, memory_length 2000, epsilon 0.050729800493862845, time 738.0, rides 120\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 3311, reward 797.0, memory_length 2000, epsilon 0.05068414367341837, time 729.0, rides 129\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 3312, reward 921.0, memory_length 2000, epsilon 0.05063852794411229, time 727.0, rides 136\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3313, reward 1109.0, memory_length 2000, epsilon 0.05059295326896259, time 725.0, rides 136\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 3314, reward 1045.0, memory_length 2000, epsilon 0.05054741961102052, time 739.0, rides 129\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 3315, reward 611.0, memory_length 2000, epsilon 0.050501926933370606, time 723.0, rides 132\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3316, reward 803.0, memory_length 2000, epsilon 0.050456475199130574, time 734.0, rides 121\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 3317, reward 798.0, memory_length 2000, epsilon 0.050411064371451354, time 732.0, rides 138\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 3318, reward 1043.0, memory_length 2000, epsilon 0.05036569441351705, time 731.0, rides 131\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 3319, reward 827.0, memory_length 2000, epsilon 0.05032036528854488, time 731.0, rides 126\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3320, reward 727.0, memory_length 2000, epsilon 0.05027507695978519, time 728.0, rides 119\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 3321, reward 989.0, memory_length 2000, epsilon 0.05022982939052138, time 731.0, rides 148\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3322, reward 859.0, memory_length 2000, epsilon 0.05018462254406991, time 730.0, rides 134\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3323, reward 1043.0, memory_length 2000, epsilon 0.05013945638378025, time 732.0, rides 137\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 3324, reward 931.0, memory_length 2000, epsilon 0.050094330873034845, time 729.0, rides 128\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 3325, reward 561.0, memory_length 2000, epsilon 0.05004924597524912, time 729.0, rides 135\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 3326, reward 650.0, memory_length 2000, epsilon 0.05000420165387139, time 726.0, rides 132\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 3327, reward 1205.0, memory_length 2000, epsilon 0.049959197872382906, time 725.0, rides 129\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 3328, reward 910.0, memory_length 2000, epsilon 0.04991423459429776, time 731.0, rides 132\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3329, reward 995.0, memory_length 2000, epsilon 0.04986931178316289, time 729.0, rides 134\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3330, reward 831.0, memory_length 2000, epsilon 0.04982442940255804, time 731.0, rides 124\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 3331, reward 550.0, memory_length 2000, epsilon 0.049779587416095734, time 723.0, rides 135\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 3332, reward 909.0, memory_length 2000, epsilon 0.04973478578742125, time 729.0, rides 144\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 3333, reward 904.0, memory_length 2000, epsilon 0.04969002448021257, time 731.0, rides 125\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 3334, reward 707.0, memory_length 2000, epsilon 0.04964530345818038, time 725.0, rides 136\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 3335, reward 973.0, memory_length 2000, epsilon 0.04960062268506801, time 728.0, rides 125\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 3336, reward 1030.0, memory_length 2000, epsilon 0.049555982124651454, time 732.0, rides 131\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 3337, reward 763.0, memory_length 2000, epsilon 0.04951138174073927, time 724.0, rides 140\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 3338, reward 953.0, memory_length 2000, epsilon 0.0494668214971726, time 729.0, rides 142\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3339, reward 652.0, memory_length 2000, epsilon 0.049422301357825146, time 729.0, rides 129\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 3340, reward 959.0, memory_length 2000, epsilon 0.049377821286603105, time 733.0, rides 137\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 3341, reward 1121.0, memory_length 2000, epsilon 0.049333381247445164, time 732.0, rides 134\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 3342, reward 1046.0, memory_length 2000, epsilon 0.049288981204322464, time 729.0, rides 127\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 3343, reward 794.0, memory_length 2000, epsilon 0.04924462112123857, time 721.0, rides 135\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 3344, reward 960.0, memory_length 2000, epsilon 0.04920030096222946, time 728.0, rides 135\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3345, reward 863.0, memory_length 2000, epsilon 0.049156020691363454, time 724.0, rides 123\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 3346, reward 570.0, memory_length 2000, epsilon 0.049111780272741226, time 730.0, rides 124\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 3347, reward 967.0, memory_length 2000, epsilon 0.049067579670495756, time 731.0, rides 127\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 3348, reward 953.0, memory_length 2000, epsilon 0.049023418848792306, time 724.0, rides 122\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 3349, reward 700.0, memory_length 2000, epsilon 0.04897929777182839, time 723.0, rides 134\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 3350, reward 603.0, memory_length 2000, epsilon 0.04893521640383375, time 723.0, rides 129\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 3351, reward 810.0, memory_length 2000, epsilon 0.0488911747090703, time 730.0, rides 138\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3352, reward 740.0, memory_length 2000, epsilon 0.04884717265183213, time 724.0, rides 137\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 3353, reward 1185.0, memory_length 2000, epsilon 0.048803210196445485, time 727.0, rides 148\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 3354, reward 802.0, memory_length 2000, epsilon 0.04875928730726868, time 730.0, rides 144\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 3355, reward 841.0, memory_length 2000, epsilon 0.048715403948692136, time 732.0, rides 131\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 3356, reward 822.0, memory_length 2000, epsilon 0.048671560085138316, time 726.0, rides 151\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 3357, reward 878.0, memory_length 2000, epsilon 0.04862775568106169, time 726.0, rides 141\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 3358, reward 584.0, memory_length 2000, epsilon 0.04858399070094873, time 734.0, rides 126\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3359, reward 936.0, memory_length 2000, epsilon 0.04854026510931787, time 730.0, rides 131\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 3360, reward 711.0, memory_length 2000, epsilon 0.04849657887071949, time 733.0, rides 140\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 3361, reward 519.0, memory_length 2000, epsilon 0.04845293194973584, time 730.0, rides 126\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 3362, reward 934.0, memory_length 2000, epsilon 0.04840932431098108, time 736.0, rides 160\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 3363, reward 660.0, memory_length 2000, epsilon 0.048365755919101194, time 727.0, rides 123\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3364, reward 656.0, memory_length 2000, epsilon 0.048322226738774, time 729.0, rides 132\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 3365, reward 657.0, memory_length 2000, epsilon 0.04827873673470911, time 726.0, rides 131\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 3366, reward 337.0, memory_length 2000, epsilon 0.04823528587164787, time 732.0, rides 120\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 3367, reward 866.0, memory_length 2000, epsilon 0.04819187411436338, time 728.0, rides 130\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3368, reward 621.0, memory_length 2000, epsilon 0.04814850142766045, time 725.0, rides 121\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 3369, reward 886.0, memory_length 2000, epsilon 0.04810516777637556, time 734.0, rides 142\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 3370, reward 744.0, memory_length 2000, epsilon 0.04806187312537682, time 729.0, rides 131\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 3371, reward 724.0, memory_length 2000, epsilon 0.048018617439563975, time 731.0, rides 137\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 3372, reward 1171.0, memory_length 2000, epsilon 0.047975400683868366, time 723.0, rides 129\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 3373, reward 760.0, memory_length 2000, epsilon 0.047932222823252886, time 724.0, rides 131\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 3374, reward 720.0, memory_length 2000, epsilon 0.04788908382271196, time 728.0, rides 138\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 3375, reward 978.0, memory_length 2000, epsilon 0.047845983647271516, time 730.0, rides 129\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 3376, reward 934.0, memory_length 2000, epsilon 0.04780292226198897, time 726.0, rides 135\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3377, reward 1007.0, memory_length 2000, epsilon 0.04775989963195318, time 727.0, rides 128\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 3378, reward 697.0, memory_length 2000, epsilon 0.04771691572228442, time 733.0, rides 125\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 3379, reward 1027.0, memory_length 2000, epsilon 0.04767397049813436, time 725.0, rides 137\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 3380, reward 1102.0, memory_length 2000, epsilon 0.047631063924686044, time 722.0, rides 134\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3381, reward 1234.0, memory_length 2000, epsilon 0.04758819596715383, time 727.0, rides 135\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 3382, reward 885.0, memory_length 2000, epsilon 0.04754536659078339, time 725.0, rides 131\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 3383, reward 814.0, memory_length 2000, epsilon 0.047502575760851685, time 723.0, rides 134\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3384, reward 521.0, memory_length 2000, epsilon 0.047459823442666915, time 726.0, rides 143\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 3385, reward 582.0, memory_length 2000, epsilon 0.047417109601568516, time 727.0, rides 114\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 3386, reward 1074.0, memory_length 2000, epsilon 0.047374434202927106, time 731.0, rides 130\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 3387, reward 837.0, memory_length 2000, epsilon 0.04733179721214447, time 734.0, rides 124\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 3388, reward 683.0, memory_length 2000, epsilon 0.04728919859465354, time 728.0, rides 125\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 3389, reward 654.0, memory_length 2000, epsilon 0.04724663831591835, time 729.0, rides 120\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 3390, reward 699.0, memory_length 2000, epsilon 0.04720411634143402, time 730.0, rides 128\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 3391, reward 818.0, memory_length 2000, epsilon 0.04716163263672673, time 726.0, rides 131\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 3392, reward 983.0, memory_length 2000, epsilon 0.04711918716735367, time 730.0, rides 119\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 3393, reward 1087.0, memory_length 2000, epsilon 0.047076779898903055, time 727.0, rides 135\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3394, reward 963.0, memory_length 2000, epsilon 0.04703441079699404, time 731.0, rides 132\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 3395, reward 676.0, memory_length 2000, epsilon 0.046992079827276746, time 736.0, rides 121\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 3396, reward 781.0, memory_length 2000, epsilon 0.0469497869554322, time 720.0, rides 130\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 3397, reward 1044.0, memory_length 2000, epsilon 0.04690753214717231, time 737.0, rides 133\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 3398, reward 682.0, memory_length 2000, epsilon 0.04686531536823985, time 727.0, rides 127\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 3399, reward 1018.0, memory_length 2000, epsilon 0.04682313658440844, time 731.0, rides 130\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 3400, reward 941.0, memory_length 2000, epsilon 0.04678099576148247, time 732.0, rides 126\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 3401, reward 829.0, memory_length 2000, epsilon 0.04673889286529714, time 725.0, rides 145\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 3402, reward 811.0, memory_length 2000, epsilon 0.04669682786171837, time 728.0, rides 138\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3403, reward 930.0, memory_length 2000, epsilon 0.04665480071664282, time 731.0, rides 139\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 3404, reward 633.0, memory_length 2000, epsilon 0.046612811395997836, time 724.0, rides 134\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 3405, reward 732.0, memory_length 2000, epsilon 0.046570859865741436, time 723.0, rides 132\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 3406, reward 822.0, memory_length 2000, epsilon 0.04652894609186227, time 721.0, rides 135\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 3407, reward 759.0, memory_length 2000, epsilon 0.046487070040379594, time 733.0, rides 143\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3408, reward 1176.0, memory_length 2000, epsilon 0.046445231677343254, time 729.0, rides 140\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 3409, reward 729.0, memory_length 2000, epsilon 0.04640343096883365, time 729.0, rides 137\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 3410, reward 925.0, memory_length 2000, epsilon 0.046361667880961695, time 731.0, rides 142\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 3411, reward 760.0, memory_length 2000, epsilon 0.04631994237986883, time 738.0, rides 137\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3412, reward 936.0, memory_length 2000, epsilon 0.046278254431726944, time 728.0, rides 143\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3413, reward 1062.0, memory_length 2000, epsilon 0.046236604002738386, time 725.0, rides 135\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 3414, reward 763.0, memory_length 2000, epsilon 0.04619499105913592, time 728.0, rides 124\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 3415, reward 855.0, memory_length 2000, epsilon 0.0461534155671827, time 725.0, rides 133\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 3416, reward 874.0, memory_length 2000, epsilon 0.046111877493172235, time 733.0, rides 132\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3417, reward 670.0, memory_length 2000, epsilon 0.04607037680342838, time 727.0, rides 133\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 3418, reward 729.0, memory_length 2000, epsilon 0.04602891346430529, time 725.0, rides 152\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 3419, reward 958.0, memory_length 2000, epsilon 0.04598748744218742, time 729.0, rides 141\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 3420, reward 989.0, memory_length 2000, epsilon 0.04594609870348945, time 730.0, rides 132\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 3421, reward 937.0, memory_length 2000, epsilon 0.04590474721465631, time 730.0, rides 126\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 3422, reward 709.0, memory_length 2000, epsilon 0.04586343294216312, time 729.0, rides 121\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 3423, reward 1113.0, memory_length 2000, epsilon 0.04582215585251517, time 728.0, rides 142\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 3424, reward 909.0, memory_length 2000, epsilon 0.04578091591224791, time 725.0, rides 141\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 3425, reward 643.0, memory_length 2000, epsilon 0.04573971308792688, time 735.0, rides 129\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 3426, reward 587.0, memory_length 2000, epsilon 0.04569854734614775, time 736.0, rides 131\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 3427, reward 765.0, memory_length 2000, epsilon 0.045657418653536216, time 740.0, rides 139\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 3428, reward 652.0, memory_length 2000, epsilon 0.045616326976748035, time 728.0, rides 151\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3429, reward 787.0, memory_length 2000, epsilon 0.045575272282468965, time 721.0, rides 140\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 3430, reward 944.0, memory_length 2000, epsilon 0.04553425453741474, time 728.0, rides 129\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 3431, reward 1003.0, memory_length 2000, epsilon 0.04549327370833107, time 732.0, rides 131\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 3432, reward 685.0, memory_length 2000, epsilon 0.04545232976199357, time 731.0, rides 133\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 3433, reward 794.0, memory_length 2000, epsilon 0.04541142266520778, time 727.0, rides 130\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 3434, reward 845.0, memory_length 2000, epsilon 0.04537055238480909, time 729.0, rides 129\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3435, reward 797.0, memory_length 2000, epsilon 0.04532971888766276, time 727.0, rides 135\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 3436, reward 621.0, memory_length 2000, epsilon 0.045288922140663865, time 722.0, rides 127\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 3437, reward 834.0, memory_length 2000, epsilon 0.04524816211073727, time 728.0, rides 133\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 3438, reward 932.0, memory_length 2000, epsilon 0.045207438764837606, time 734.0, rides 139\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 3439, reward 1120.0, memory_length 2000, epsilon 0.04516675206994925, time 730.0, rides 130\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 3440, reward 1000.0, memory_length 2000, epsilon 0.045126101993086296, time 726.0, rides 141\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 3441, reward 861.0, memory_length 2000, epsilon 0.045085488501292514, time 725.0, rides 127\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 3442, reward 1243.0, memory_length 2000, epsilon 0.04504491156164135, time 728.0, rides 139\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3443, reward 1202.0, memory_length 2000, epsilon 0.04500437114123587, time 726.0, rides 142\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 3444, reward 980.0, memory_length 2000, epsilon 0.04496386720720876, time 727.0, rides 136\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 3445, reward 1168.0, memory_length 2000, epsilon 0.044923399726722275, time 726.0, rides 143\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 3446, reward 987.0, memory_length 2000, epsilon 0.044882968666968226, time 725.0, rides 132\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 3447, reward 825.0, memory_length 2000, epsilon 0.04484257399516795, time 733.0, rides 130\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3448, reward 879.0, memory_length 2000, epsilon 0.0448022156785723, time 724.0, rides 138\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 3449, reward 894.0, memory_length 2000, epsilon 0.04476189368446159, time 722.0, rides 135\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 3450, reward 643.0, memory_length 2000, epsilon 0.04472160798014557, time 723.0, rides 134\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 3451, reward 630.0, memory_length 2000, epsilon 0.04468135853296344, time 728.0, rides 124\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 3452, reward 1120.0, memory_length 2000, epsilon 0.04464114531028377, time 727.0, rides 134\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 3453, reward 803.0, memory_length 2000, epsilon 0.044600968279504515, time 743.0, rides 138\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 3454, reward 809.0, memory_length 2000, epsilon 0.04456082740805296, time 729.0, rides 135\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 3455, reward 875.0, memory_length 2000, epsilon 0.044520722663385706, time 731.0, rides 137\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3456, reward 798.0, memory_length 2000, epsilon 0.04448065401298866, time 730.0, rides 124\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3457, reward 818.0, memory_length 2000, epsilon 0.04444062142437697, time 731.0, rides 135\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 3458, reward 609.0, memory_length 2000, epsilon 0.04440062486509503, time 735.0, rides 141\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 3459, reward 894.0, memory_length 2000, epsilon 0.04436066430271644, time 734.0, rides 123\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3460, reward 1017.0, memory_length 2000, epsilon 0.044320739704844, time 723.0, rides 135\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 3461, reward 1024.0, memory_length 2000, epsilon 0.04428085103910964, time 723.0, rides 147\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 3462, reward 787.0, memory_length 2000, epsilon 0.044240998273174445, time 728.0, rides 133\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 3463, reward 926.0, memory_length 2000, epsilon 0.04420118137472859, time 731.0, rides 134\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3464, reward 913.0, memory_length 2000, epsilon 0.04416140031149133, time 731.0, rides 122\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 3465, reward 767.0, memory_length 2000, epsilon 0.04412165505121099, time 730.0, rides 130\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 3466, reward 1075.0, memory_length 2000, epsilon 0.0440819455616649, time 724.0, rides 121\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 3467, reward 1107.0, memory_length 2000, epsilon 0.0440422718106594, time 732.0, rides 124\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 3468, reward 841.0, memory_length 2000, epsilon 0.04400263376602981, time 734.0, rides 134\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3469, reward 1185.0, memory_length 2000, epsilon 0.04396303139564038, time 730.0, rides 137\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 3470, reward 1020.0, memory_length 2000, epsilon 0.0439234646673843, time 722.0, rides 136\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 3471, reward 1148.0, memory_length 2000, epsilon 0.04388393354918366, time 729.0, rides 140\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 3472, reward 907.0, memory_length 2000, epsilon 0.04384443800898939, time 724.0, rides 137\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 3473, reward 810.0, memory_length 2000, epsilon 0.0438049780147813, time 730.0, rides 141\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3474, reward 942.0, memory_length 2000, epsilon 0.043765553534568, time 732.0, rides 136\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 3475, reward 1289.0, memory_length 2000, epsilon 0.04372616453638689, time 733.0, rides 133\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 3476, reward 928.0, memory_length 2000, epsilon 0.04368681098830414, time 723.0, rides 126\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 3477, reward 1172.0, memory_length 2000, epsilon 0.04364749285841466, time 724.0, rides 138\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 3478, reward 828.0, memory_length 2000, epsilon 0.04360821011484209, time 735.0, rides 124\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3479, reward 997.0, memory_length 2000, epsilon 0.04356896272573873, time 723.0, rides 130\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 3480, reward 1060.0, memory_length 2000, epsilon 0.04352975065928556, time 728.0, rides 133\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 3481, reward 1066.0, memory_length 2000, epsilon 0.04349057388369221, time 730.0, rides 129\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 3482, reward 749.0, memory_length 2000, epsilon 0.04345143236719688, time 725.0, rides 128\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 3483, reward 744.0, memory_length 2000, epsilon 0.0434123260780664, time 732.0, rides 125\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 3484, reward 932.0, memory_length 2000, epsilon 0.04337325498459614, time 739.0, rides 123\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3485, reward 825.0, memory_length 2000, epsilon 0.04333421905511001, time 732.0, rides 137\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 3486, reward 1144.0, memory_length 2000, epsilon 0.043295218257960406, time 734.0, rides 134\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3487, reward 734.0, memory_length 2000, epsilon 0.04325625256152824, time 727.0, rides 132\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 3488, reward 1055.0, memory_length 2000, epsilon 0.04321732193422287, time 726.0, rides 135\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 3489, reward 920.0, memory_length 2000, epsilon 0.04317842634448207, time 722.0, rides 132\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 3490, reward 1166.0, memory_length 2000, epsilon 0.04313956576077203, time 735.0, rides 140\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 3491, reward 1157.0, memory_length 2000, epsilon 0.04310074015158734, time 735.0, rides 120\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 3492, reward 716.0, memory_length 2000, epsilon 0.04306194948545091, time 729.0, rides 127\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 3493, reward 958.0, memory_length 2000, epsilon 0.043023193730914004, time 739.0, rides 130\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 3494, reward 615.0, memory_length 2000, epsilon 0.04298447285655618, time 733.0, rides 143\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 3495, reward 782.0, memory_length 2000, epsilon 0.04294578683098528, time 732.0, rides 132\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3496, reward 853.0, memory_length 2000, epsilon 0.04290713562283739, time 724.0, rides 125\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3497, reward 743.0, memory_length 2000, epsilon 0.04286851920077684, time 733.0, rides 136\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 3498, reward 1045.0, memory_length 2000, epsilon 0.04282993753349614, time 733.0, rides 136\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 3499, reward 753.0, memory_length 2000, epsilon 0.042791390589716, time 728.0, rides 118\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3500, reward 692.0, memory_length 2000, epsilon 0.04275287833818525, time 735.0, rides 136\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3501, reward 1043.0, memory_length 2000, epsilon 0.04271440074768088, time 730.0, rides 126\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3502, reward 615.0, memory_length 2000, epsilon 0.042675957787007966, time 728.0, rides 147\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 3503, reward 1044.0, memory_length 2000, epsilon 0.04263754942499966, time 738.0, rides 134\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 3504, reward 975.0, memory_length 2000, epsilon 0.042599175630517155, time 730.0, rides 131\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 3505, reward 912.0, memory_length 2000, epsilon 0.04256083637244969, time 727.0, rides 129\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 3506, reward 941.0, memory_length 2000, epsilon 0.04252253161971448, time 720.0, rides 136\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 3507, reward 1255.0, memory_length 2000, epsilon 0.04248426134125674, time 729.0, rides 131\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3508, reward 780.0, memory_length 2000, epsilon 0.04244602550604961, time 734.0, rides 129\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 3509, reward 967.0, memory_length 2000, epsilon 0.04240782408309417, time 728.0, rides 135\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 3510, reward 927.0, memory_length 2000, epsilon 0.04236965704141938, time 729.0, rides 130\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 3511, reward 976.0, memory_length 2000, epsilon 0.042331524350082105, time 726.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 3512, reward 997.0, memory_length 2000, epsilon 0.04229342597816703, time 733.0, rides 138\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3513, reward 923.0, memory_length 2000, epsilon 0.04225536189478668, time 730.0, rides 139\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 3514, reward 951.0, memory_length 2000, epsilon 0.04221733206908137, time 731.0, rides 126\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 3515, reward 792.0, memory_length 2000, epsilon 0.042179336470219195, time 729.0, rides 132\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 3516, reward 631.0, memory_length 2000, epsilon 0.042141375067396, time 725.0, rides 129\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 3517, reward 870.0, memory_length 2000, epsilon 0.04210344782983534, time 726.0, rides 132\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3518, reward 1010.0, memory_length 2000, epsilon 0.04206555472678849, time 728.0, rides 122\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 3519, reward 932.0, memory_length 2000, epsilon 0.04202769572753438, time 726.0, rides 132\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 3520, reward 858.0, memory_length 2000, epsilon 0.04198987080137959, time 734.0, rides 133\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 3521, reward 951.0, memory_length 2000, epsilon 0.04195207991765835, time 725.0, rides 127\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 3522, reward 912.0, memory_length 2000, epsilon 0.041914323045732456, time 729.0, rides 138\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 3523, reward 935.0, memory_length 2000, epsilon 0.0418766001549913, time 730.0, rides 141\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3524, reward 915.0, memory_length 2000, epsilon 0.0418389112148518, time 725.0, rides 121\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 3525, reward 828.0, memory_length 2000, epsilon 0.041801256194758434, time 724.0, rides 118\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 3526, reward 820.0, memory_length 2000, epsilon 0.04176363506418315, time 729.0, rides 128\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 3527, reward 868.0, memory_length 2000, epsilon 0.041726047792625384, time 727.0, rides 128\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 3528, reward 658.0, memory_length 2000, epsilon 0.04168849434961202, time 727.0, rides 126\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 3529, reward 994.0, memory_length 2000, epsilon 0.04165097470469737, time 722.0, rides 129\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 3530, reward 794.0, memory_length 2000, epsilon 0.041613488827463144, time 729.0, rides 136\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3531, reward 1245.0, memory_length 2000, epsilon 0.04157603668751843, time 731.0, rides 140\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 3532, reward 674.0, memory_length 2000, epsilon 0.041538618254499664, time 727.0, rides 131\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 3533, reward 950.0, memory_length 2000, epsilon 0.04150123349807061, time 734.0, rides 120\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 3534, reward 917.0, memory_length 2000, epsilon 0.04146388238792235, time 731.0, rides 131\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3535, reward 809.0, memory_length 2000, epsilon 0.041426564893773214, time 730.0, rides 143\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 3536, reward 946.0, memory_length 2000, epsilon 0.041389280985368815, time 731.0, rides 127\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 3537, reward 1087.0, memory_length 2000, epsilon 0.04135203063248198, time 732.0, rides 125\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3538, reward 879.0, memory_length 2000, epsilon 0.041314813804912746, time 731.0, rides 130\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3539, reward 1018.0, memory_length 2000, epsilon 0.04127763047248832, time 729.0, rides 132\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 3540, reward 1038.0, memory_length 2000, epsilon 0.04124048060506308, time 729.0, rides 125\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 3541, reward 956.0, memory_length 2000, epsilon 0.04120336417251852, time 729.0, rides 124\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 3542, reward 1015.0, memory_length 2000, epsilon 0.04116628114476325, time 728.0, rides 134\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 3543, reward 766.0, memory_length 2000, epsilon 0.04112923149173296, time 735.0, rides 120\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 3544, reward 986.0, memory_length 2000, epsilon 0.0410922151833904, time 724.0, rides 127\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 3545, reward 873.0, memory_length 2000, epsilon 0.04105523218972535, time 723.0, rides 145\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 3546, reward 608.0, memory_length 2000, epsilon 0.0410182824807546, time 734.0, rides 129\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 3547, reward 1093.0, memory_length 2000, epsilon 0.04098136602652192, time 723.0, rides 137\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 3548, reward 969.0, memory_length 2000, epsilon 0.04094448279709805, time 733.0, rides 130\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 3549, reward 842.0, memory_length 2000, epsilon 0.040907632762580665, time 734.0, rides 123\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 3550, reward 968.0, memory_length 2000, epsilon 0.04087081589309434, time 726.0, rides 132\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 3551, reward 740.0, memory_length 2000, epsilon 0.040834032158790556, time 723.0, rides 138\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 3552, reward 865.0, memory_length 2000, epsilon 0.04079728152984764, time 722.0, rides 130\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 3553, reward 1127.0, memory_length 2000, epsilon 0.04076056397647078, time 730.0, rides 130\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 3554, reward 711.0, memory_length 2000, epsilon 0.04072387946889196, time 725.0, rides 136\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 3555, reward 972.0, memory_length 2000, epsilon 0.040687227977369955, time 731.0, rides 123\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 3556, reward 873.0, memory_length 2000, epsilon 0.04065060947219032, time 723.0, rides 139\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3557, reward 718.0, memory_length 2000, epsilon 0.040614023923665345, time 726.0, rides 136\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 3558, reward 870.0, memory_length 2000, epsilon 0.040577471302134044, time 725.0, rides 126\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 3559, reward 1006.0, memory_length 2000, epsilon 0.04054095157796212, time 728.0, rides 134\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 3560, reward 991.0, memory_length 2000, epsilon 0.040504464721541955, time 727.0, rides 127\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 3561, reward 432.0, memory_length 2000, epsilon 0.04046801070329257, time 730.0, rides 118\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 3562, reward 967.0, memory_length 2000, epsilon 0.0404315894936596, time 727.0, rides 131\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3563, reward 816.0, memory_length 2000, epsilon 0.04039520106311531, time 724.0, rides 127\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3564, reward 910.0, memory_length 2000, epsilon 0.040358845382158504, time 727.0, rides 136\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 3565, reward 719.0, memory_length 2000, epsilon 0.04032252242131456, time 728.0, rides 138\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 3566, reward 727.0, memory_length 2000, epsilon 0.04028623215113537, time 722.0, rides 156\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3567, reward 823.0, memory_length 2000, epsilon 0.04024997454219935, time 725.0, rides 130\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 3568, reward 974.0, memory_length 2000, epsilon 0.04021374956511137, time 731.0, rides 134\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 3569, reward 754.0, memory_length 2000, epsilon 0.04017755719050277, time 735.0, rides 138\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3570, reward 723.0, memory_length 2000, epsilon 0.040141397389031316, time 731.0, rides 130\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3571, reward 746.0, memory_length 2000, epsilon 0.04010527013138119, time 728.0, rides 135\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3572, reward 1225.0, memory_length 2000, epsilon 0.04006917538826295, time 729.0, rides 140\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 3573, reward 647.0, memory_length 2000, epsilon 0.04003311313041351, time 730.0, rides 132\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 3574, reward 1011.0, memory_length 2000, epsilon 0.03999708332859614, time 730.0, rides 128\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 3575, reward 591.0, memory_length 2000, epsilon 0.0399610859536004, time 727.0, rides 113\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 3576, reward 1199.0, memory_length 2000, epsilon 0.03992512097624216, time 725.0, rides 134\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 3577, reward 619.0, memory_length 2000, epsilon 0.03988918836736354, time 722.0, rides 143\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 3578, reward 958.0, memory_length 2000, epsilon 0.039853288097832916, time 725.0, rides 134\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 3579, reward 863.0, memory_length 2000, epsilon 0.03981742013854487, time 726.0, rides 139\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 3580, reward 837.0, memory_length 2000, epsilon 0.039781584460420176, time 745.0, rides 128\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 3581, reward 903.0, memory_length 2000, epsilon 0.0397457810344058, time 731.0, rides 128\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 3582, reward 1404.0, memory_length 2000, epsilon 0.03971000983147483, time 723.0, rides 137\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 3583, reward 709.0, memory_length 2000, epsilon 0.039674270822626506, time 730.0, rides 147\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 3584, reward 1076.0, memory_length 2000, epsilon 0.03963856397888614, time 732.0, rides 135\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 3585, reward 1323.0, memory_length 2000, epsilon 0.03960288927130514, time 722.0, rides 137\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 3586, reward 1011.0, memory_length 2000, epsilon 0.03956724667096097, time 721.0, rides 136\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 3587, reward 806.0, memory_length 2000, epsilon 0.039531636148957106, time 731.0, rides 124\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 3588, reward 1125.0, memory_length 2000, epsilon 0.039496057676423044, time 722.0, rides 138\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 3589, reward 891.0, memory_length 2000, epsilon 0.039460511224514265, time 730.0, rides 132\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 3590, reward 844.0, memory_length 2000, epsilon 0.039424996764412204, time 727.0, rides 119\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 3591, reward 643.0, memory_length 2000, epsilon 0.03938951426732423, time 730.0, rides 119\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 3592, reward 1091.0, memory_length 2000, epsilon 0.03935406370448364, time 730.0, rides 130\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 3593, reward 675.0, memory_length 2000, epsilon 0.0393186450471496, time 730.0, rides 135\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 3594, reward 306.0, memory_length 2000, epsilon 0.03928325826660717, time 730.0, rides 116\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 3595, reward 1091.0, memory_length 2000, epsilon 0.03924790333416722, time 734.0, rides 128\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 3596, reward 972.0, memory_length 2000, epsilon 0.03921258022116647, time 730.0, rides 140\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3597, reward 1040.0, memory_length 2000, epsilon 0.03917728889896742, time 732.0, rides 141\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 3598, reward 731.0, memory_length 2000, epsilon 0.03914202933895835, time 729.0, rides 132\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 3599, reward 498.0, memory_length 2000, epsilon 0.03910680151255329, time 727.0, rides 136\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 3600, reward 982.0, memory_length 2000, epsilon 0.03907160539119199, time 723.0, rides 138\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 3601, reward 554.0, memory_length 2000, epsilon 0.039036440946339915, time 732.0, rides 127\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 3602, reward 975.0, memory_length 2000, epsilon 0.039001308149488205, time 725.0, rides 138\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 3603, reward 997.0, memory_length 2000, epsilon 0.038966206972153666, time 729.0, rides 128\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 3604, reward 966.0, memory_length 2000, epsilon 0.03893113738587873, time 732.0, rides 140\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 3605, reward 1047.0, memory_length 2000, epsilon 0.038896099362231436, time 728.0, rides 128\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 3606, reward 886.0, memory_length 2000, epsilon 0.038861092872805425, time 726.0, rides 144\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 3607, reward 1056.0, memory_length 2000, epsilon 0.0388261178892199, time 731.0, rides 134\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 3608, reward 629.0, memory_length 2000, epsilon 0.0387911743831196, time 730.0, rides 141\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3609, reward 859.0, memory_length 2000, epsilon 0.038756262326174795, time 730.0, rides 121\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 3610, reward 924.0, memory_length 2000, epsilon 0.038721381690081234, time 725.0, rides 134\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 3611, reward 999.0, memory_length 2000, epsilon 0.03868653244656016, time 729.0, rides 134\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 3612, reward 1016.0, memory_length 2000, epsilon 0.038651714567358254, time 733.0, rides 140\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 3613, reward 726.0, memory_length 2000, epsilon 0.03861692802424763, time 725.0, rides 140\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 3614, reward 933.0, memory_length 2000, epsilon 0.03858217278902581, time 730.0, rides 133\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 3615, reward 602.0, memory_length 2000, epsilon 0.038547448833515685, time 726.0, rides 131\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 3616, reward 919.0, memory_length 2000, epsilon 0.03851275612956552, time 723.0, rides 129\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 3617, reward 592.0, memory_length 2000, epsilon 0.03847809464904891, time 734.0, rides 129\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 3618, reward 656.0, memory_length 2000, epsilon 0.03844346436386476, time 722.0, rides 137\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 3619, reward 969.0, memory_length 2000, epsilon 0.038408865245937285, time 727.0, rides 134\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3620, reward 753.0, memory_length 2000, epsilon 0.03837429726721594, time 730.0, rides 123\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3621, reward 894.0, memory_length 2000, epsilon 0.038339760399675446, time 727.0, rides 127\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 3622, reward 944.0, memory_length 2000, epsilon 0.03830525461531574, time 735.0, rides 147\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 3623, reward 815.0, memory_length 2000, epsilon 0.038270779886161954, time 729.0, rides 118\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 3624, reward 1380.0, memory_length 2000, epsilon 0.038236336184264405, time 731.0, rides 136\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 3625, reward 613.0, memory_length 2000, epsilon 0.03820192348169857, time 724.0, rides 131\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 3626, reward 916.0, memory_length 2000, epsilon 0.03816754175056504, time 725.0, rides 137\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 3627, reward 504.0, memory_length 2000, epsilon 0.03813319096298953, time 734.0, rides 133\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 3628, reward 896.0, memory_length 2000, epsilon 0.038098871091122845, time 732.0, rides 136\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 3629, reward 716.0, memory_length 2000, epsilon 0.03806458210714083, time 724.0, rides 141\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 3630, reward 1135.0, memory_length 2000, epsilon 0.0380303239832444, time 722.0, rides 135\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 3631, reward 799.0, memory_length 2000, epsilon 0.03799609669165948, time 726.0, rides 128\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 3632, reward 1002.0, memory_length 2000, epsilon 0.03796190020463699, time 737.0, rides 136\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 3633, reward 1244.0, memory_length 2000, epsilon 0.03792773449445282, time 730.0, rides 140\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 3634, reward 627.0, memory_length 2000, epsilon 0.03789359953340781, time 730.0, rides 148\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 3635, reward 902.0, memory_length 2000, epsilon 0.03785949529382775, time 727.0, rides 157\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 3636, reward 717.0, memory_length 2000, epsilon 0.037825421748063304, time 733.0, rides 127\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3637, reward 949.0, memory_length 2000, epsilon 0.037791378868490044, time 735.0, rides 142\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 3638, reward 900.0, memory_length 2000, epsilon 0.0377573666275084, time 726.0, rides 130\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 3639, reward 826.0, memory_length 2000, epsilon 0.037723384997543644, time 722.0, rides 135\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 3640, reward 716.0, memory_length 2000, epsilon 0.037689433951045855, time 729.0, rides 134\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 3641, reward 1105.0, memory_length 2000, epsilon 0.03765551346048991, time 731.0, rides 132\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 3642, reward 721.0, memory_length 2000, epsilon 0.03762162349837547, time 725.0, rides 130\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 3643, reward 960.0, memory_length 2000, epsilon 0.03758776403722693, time 736.0, rides 131\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 3644, reward 1227.0, memory_length 2000, epsilon 0.03755393504959343, time 727.0, rides 142\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 3645, reward 1003.0, memory_length 2000, epsilon 0.03752013650804879, time 732.0, rides 138\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 3646, reward 774.0, memory_length 2000, epsilon 0.03748636838519155, time 737.0, rides 137\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 3647, reward 741.0, memory_length 2000, epsilon 0.03745263065364488, time 736.0, rides 138\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 3648, reward 866.0, memory_length 2000, epsilon 0.0374189232860566, time 727.0, rides 127\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 3649, reward 868.0, memory_length 2000, epsilon 0.03738524625509915, time 727.0, rides 133\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 3650, reward 754.0, memory_length 2000, epsilon 0.03735159953346956, time 733.0, rides 129\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 3651, reward 636.0, memory_length 2000, epsilon 0.03731798309388944, time 728.0, rides 143\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 3652, reward 714.0, memory_length 2000, epsilon 0.037284396909104935, time 723.0, rides 126\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 3653, reward 768.0, memory_length 2000, epsilon 0.037250840951886736, time 724.0, rides 122\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 3654, reward 792.0, memory_length 2000, epsilon 0.037217315195030035, time 725.0, rides 122\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 3655, reward 953.0, memory_length 2000, epsilon 0.03718381961135451, time 731.0, rides 139\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 3656, reward 800.0, memory_length 2000, epsilon 0.03715035417370429, time 728.0, rides 133\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 3657, reward 749.0, memory_length 2000, epsilon 0.03711691885494796, time 722.0, rides 155\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 3658, reward 1184.0, memory_length 2000, epsilon 0.03708351362797851, time 731.0, rides 149\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 3659, reward 767.0, memory_length 2000, epsilon 0.037050138465713325, time 734.0, rides 127\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 3660, reward 1024.0, memory_length 2000, epsilon 0.03701679334109418, time 727.0, rides 132\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 3661, reward 354.0, memory_length 2000, epsilon 0.036983478227087196, time 721.0, rides 121\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 3662, reward 811.0, memory_length 2000, epsilon 0.03695019309668282, time 725.0, rides 134\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 3663, reward 915.0, memory_length 2000, epsilon 0.036916937922895805, time 724.0, rides 119\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 3664, reward 944.0, memory_length 2000, epsilon 0.036883712678765196, time 729.0, rides 137\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3665, reward 748.0, memory_length 2000, epsilon 0.036850517337354304, time 723.0, rides 128\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 3666, reward 1056.0, memory_length 2000, epsilon 0.036817351871750684, time 734.0, rides 138\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3667, reward 690.0, memory_length 2000, epsilon 0.03678421625506611, time 729.0, rides 131\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 3668, reward 735.0, memory_length 2000, epsilon 0.03675111046043655, time 731.0, rides 141\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 3669, reward 829.0, memory_length 2000, epsilon 0.036718034461022155, time 735.0, rides 135\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 3670, reward 709.0, memory_length 2000, epsilon 0.03668498823000724, time 730.0, rides 142\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 3671, reward 861.0, memory_length 2000, epsilon 0.03665197174060023, time 726.0, rides 143\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 3672, reward 985.0, memory_length 2000, epsilon 0.03661898496603369, time 731.0, rides 134\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 3673, reward 915.0, memory_length 2000, epsilon 0.03658602787956426, time 721.0, rides 130\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 3674, reward 707.0, memory_length 2000, epsilon 0.03655310045447265, time 733.0, rides 124\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 3675, reward 762.0, memory_length 2000, epsilon 0.036520202664063625, time 730.0, rides 136\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 3676, reward 830.0, memory_length 2000, epsilon 0.03648733448166597, time 727.0, rides 128\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 3677, reward 226.0, memory_length 2000, epsilon 0.036454495880632466, time 735.0, rides 125\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 3678, reward 613.0, memory_length 2000, epsilon 0.0364216868343399, time 730.0, rides 141\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 3679, reward 1012.0, memory_length 2000, epsilon 0.03638890731618899, time 733.0, rides 144\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 3680, reward 986.0, memory_length 2000, epsilon 0.03635615729960442, time 727.0, rides 130\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 3681, reward 1009.0, memory_length 2000, epsilon 0.036323436758034774, time 723.0, rides 127\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 3682, reward 830.0, memory_length 2000, epsilon 0.036290745664952544, time 725.0, rides 135\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 3683, reward 1185.0, memory_length 2000, epsilon 0.036258083993854086, time 722.0, rides 138\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 3684, reward 847.0, memory_length 2000, epsilon 0.03622545171825962, time 722.0, rides 125\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 3685, reward 824.0, memory_length 2000, epsilon 0.03619284881171318, time 723.0, rides 126\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 3686, reward 971.0, memory_length 2000, epsilon 0.03616027524778264, time 730.0, rides 136\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 3687, reward 809.0, memory_length 2000, epsilon 0.036127731000059636, time 728.0, rides 140\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 3688, reward 905.0, memory_length 2000, epsilon 0.03609521604215958, time 723.0, rides 136\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 3689, reward 816.0, memory_length 2000, epsilon 0.03606273034772164, time 739.0, rides 140\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 3690, reward 756.0, memory_length 2000, epsilon 0.036030273890408686, time 729.0, rides 136\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 3691, reward 714.0, memory_length 2000, epsilon 0.035997846643907316, time 735.0, rides 131\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 3692, reward 726.0, memory_length 2000, epsilon 0.0359654485819278, time 737.0, rides 134\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3693, reward 661.0, memory_length 2000, epsilon 0.03593307967820407, time 728.0, rides 131\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 3694, reward 1169.0, memory_length 2000, epsilon 0.03590073990649369, time 731.0, rides 130\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 3695, reward 1027.0, memory_length 2000, epsilon 0.03586842924057784, time 727.0, rides 138\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 3696, reward 611.0, memory_length 2000, epsilon 0.035836147654261324, time 734.0, rides 136\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 3697, reward 925.0, memory_length 2000, epsilon 0.03580389512137249, time 727.0, rides 133\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 3698, reward 881.0, memory_length 2000, epsilon 0.03577167161576326, time 723.0, rides 133\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 3699, reward 653.0, memory_length 2000, epsilon 0.03573947711130907, time 724.0, rides 127\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 3700, reward 1171.0, memory_length 2000, epsilon 0.035707311581908895, time 731.0, rides 144\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 3701, reward 933.0, memory_length 2000, epsilon 0.035675175001485177, time 729.0, rides 127\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 3702, reward 884.0, memory_length 2000, epsilon 0.03564306734398384, time 730.0, rides 135\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 3703, reward 1094.0, memory_length 2000, epsilon 0.035610988583374255, time 736.0, rides 130\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3704, reward 958.0, memory_length 2000, epsilon 0.03557893869364922, time 728.0, rides 135\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 3705, reward 904.0, memory_length 2000, epsilon 0.035546917648824936, time 737.0, rides 127\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 3706, reward 855.0, memory_length 2000, epsilon 0.03551492542294099, time 727.0, rides 139\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 3707, reward 912.0, memory_length 2000, epsilon 0.03548296199006035, time 731.0, rides 138\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 3708, reward 723.0, memory_length 2000, epsilon 0.035451027324269295, time 729.0, rides 138\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 3709, reward 1037.0, memory_length 2000, epsilon 0.035419121399677456, time 730.0, rides 136\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 3710, reward 935.0, memory_length 2000, epsilon 0.03538724419041774, time 725.0, rides 142\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 3711, reward 1012.0, memory_length 2000, epsilon 0.03535539567064636, time 728.0, rides 142\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 3712, reward 1029.0, memory_length 2000, epsilon 0.03532357581454278, time 727.0, rides 150\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 3713, reward 1033.0, memory_length 2000, epsilon 0.035291784596309696, time 727.0, rides 153\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 3714, reward 1009.0, memory_length 2000, epsilon 0.035260021990173016, time 727.0, rides 127\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 3715, reward 1056.0, memory_length 2000, epsilon 0.03522828797038186, time 730.0, rides 146\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 3716, reward 568.0, memory_length 2000, epsilon 0.03519658251120852, time 734.0, rides 142\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 3717, reward 1005.0, memory_length 2000, epsilon 0.03516490558694843, time 729.0, rides 124\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 3718, reward 936.0, memory_length 2000, epsilon 0.035133257171920174, time 725.0, rides 138\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3719, reward 539.0, memory_length 2000, epsilon 0.035101637240465444, time 727.0, rides 131\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 3720, reward 996.0, memory_length 2000, epsilon 0.035070045766949026, time 723.0, rides 137\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 3721, reward 1217.0, memory_length 2000, epsilon 0.03503848272575877, time 724.0, rides 130\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 3722, reward 878.0, memory_length 2000, epsilon 0.035006948091305584, time 729.0, rides 131\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 3723, reward 911.0, memory_length 2000, epsilon 0.03497544183802341, time 726.0, rides 138\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 3724, reward 1016.0, memory_length 2000, epsilon 0.03494396394036919, time 723.0, rides 120\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 3725, reward 803.0, memory_length 2000, epsilon 0.034912514372822855, time 733.0, rides 127\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3726, reward 976.0, memory_length 2000, epsilon 0.034881093109887316, time 728.0, rides 133\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 3727, reward 923.0, memory_length 2000, epsilon 0.034849700126088415, time 725.0, rides 134\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 3728, reward 867.0, memory_length 2000, epsilon 0.03481833539597493, time 725.0, rides 133\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 3729, reward 832.0, memory_length 2000, epsilon 0.034786998894118557, time 729.0, rides 147\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 3730, reward 968.0, memory_length 2000, epsilon 0.03475569059511385, time 723.0, rides 130\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 3731, reward 1145.0, memory_length 2000, epsilon 0.03472441047357825, time 732.0, rides 125\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 3732, reward 830.0, memory_length 2000, epsilon 0.03469315850415203, time 730.0, rides 130\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 3733, reward 724.0, memory_length 2000, epsilon 0.03466193466149829, time 726.0, rides 150\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 3734, reward 970.0, memory_length 2000, epsilon 0.034630738920302946, time 726.0, rides 140\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 3735, reward 941.0, memory_length 2000, epsilon 0.03459957125527467, time 724.0, rides 145\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 3736, reward 920.0, memory_length 2000, epsilon 0.034568431641144926, time 730.0, rides 131\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 3737, reward 973.0, memory_length 2000, epsilon 0.034537320052667894, time 732.0, rides 137\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 3738, reward 1104.0, memory_length 2000, epsilon 0.03450623646462049, time 725.0, rides 128\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 3739, reward 1295.0, memory_length 2000, epsilon 0.03447518085180233, time 728.0, rides 137\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 3740, reward 1064.0, memory_length 2000, epsilon 0.03444415318903571, time 732.0, rides 141\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 3741, reward 1076.0, memory_length 2000, epsilon 0.03441315345116558, time 733.0, rides 132\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3742, reward 891.0, memory_length 2000, epsilon 0.03438218161305953, time 729.0, rides 126\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 3743, reward 718.0, memory_length 2000, epsilon 0.03435123764960778, time 730.0, rides 128\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 3744, reward 712.0, memory_length 2000, epsilon 0.034320321535723126, time 733.0, rides 141\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 3745, reward 1090.0, memory_length 2000, epsilon 0.034289433246340977, time 723.0, rides 129\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 3746, reward 1003.0, memory_length 2000, epsilon 0.03425857275641927, time 722.0, rides 134\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 3747, reward 858.0, memory_length 2000, epsilon 0.03422774004093849, time 723.0, rides 129\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 3748, reward 633.0, memory_length 2000, epsilon 0.034196935074901645, time 724.0, rides 133\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 3749, reward 1063.0, memory_length 2000, epsilon 0.03416615783333423, time 727.0, rides 138\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3750, reward 839.0, memory_length 2000, epsilon 0.03413540829128423, time 721.0, rides 127\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 3751, reward 887.0, memory_length 2000, epsilon 0.03410468642382208, time 735.0, rides 143\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 3752, reward 1001.0, memory_length 2000, epsilon 0.03407399220604063, time 730.0, rides 130\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 3753, reward 754.0, memory_length 2000, epsilon 0.034043325613055196, time 728.0, rides 134\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 3754, reward 752.0, memory_length 2000, epsilon 0.034012686620003445, time 733.0, rides 132\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 3755, reward 971.0, memory_length 2000, epsilon 0.03398207520204544, time 730.0, rides 125\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 3756, reward 951.0, memory_length 2000, epsilon 0.0339514913343636, time 733.0, rides 142\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 3757, reward 873.0, memory_length 2000, epsilon 0.03392093499216267, time 727.0, rides 130\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 3758, reward 715.0, memory_length 2000, epsilon 0.033890406150669725, time 736.0, rides 130\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 3759, reward 885.0, memory_length 2000, epsilon 0.03385990478513412, time 724.0, rides 122\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3760, reward 1101.0, memory_length 2000, epsilon 0.0338294308708275, time 727.0, rides 145\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 3761, reward 946.0, memory_length 2000, epsilon 0.033798984383043754, time 730.0, rides 124\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 3762, reward 1142.0, memory_length 2000, epsilon 0.03376856529709901, time 725.0, rides 142\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 3763, reward 877.0, memory_length 2000, epsilon 0.03373817358833162, time 731.0, rides 138\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 3764, reward 920.0, memory_length 2000, epsilon 0.03370780923210212, time 725.0, rides 133\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 3765, reward 751.0, memory_length 2000, epsilon 0.033677472203793225, time 725.0, rides 117\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3766, reward 581.0, memory_length 2000, epsilon 0.03364716247880981, time 732.0, rides 127\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 3767, reward 1113.0, memory_length 2000, epsilon 0.033616880032578886, time 735.0, rides 146\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 3768, reward 1239.0, memory_length 2000, epsilon 0.03358662484054956, time 730.0, rides 142\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 3769, reward 803.0, memory_length 2000, epsilon 0.03355639687819307, time 730.0, rides 143\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 3770, reward 1028.0, memory_length 2000, epsilon 0.033526196121002695, time 733.0, rides 138\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 3771, reward 1073.0, memory_length 2000, epsilon 0.03349602254449379, time 729.0, rides 147\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 3772, reward 1006.0, memory_length 2000, epsilon 0.03346587612420374, time 722.0, rides 147\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 3773, reward 781.0, memory_length 2000, epsilon 0.03343575683569196, time 736.0, rides 138\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 3774, reward 596.0, memory_length 2000, epsilon 0.033405664654539834, time 726.0, rides 133\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 3775, reward 633.0, memory_length 2000, epsilon 0.03337559955635075, time 732.0, rides 139\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 3776, reward 1115.0, memory_length 2000, epsilon 0.033345561516750034, time 721.0, rides 136\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 3777, reward 483.0, memory_length 2000, epsilon 0.03331555051138496, time 733.0, rides 146\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 3778, reward 985.0, memory_length 2000, epsilon 0.033285566515924715, time 728.0, rides 151\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3779, reward 1040.0, memory_length 2000, epsilon 0.03325560950606038, time 727.0, rides 146\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 3780, reward 1091.0, memory_length 2000, epsilon 0.033225679457504924, time 725.0, rides 122\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 3781, reward 1018.0, memory_length 2000, epsilon 0.03319577634599317, time 728.0, rides 146\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 3782, reward 901.0, memory_length 2000, epsilon 0.033165900147281775, time 731.0, rides 129\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 3783, reward 1138.0, memory_length 2000, epsilon 0.03313605083714922, time 727.0, rides 140\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3784, reward 918.0, memory_length 2000, epsilon 0.033106228391395785, time 731.0, rides 144\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 3785, reward 1183.0, memory_length 2000, epsilon 0.03307643278584353, time 728.0, rides 144\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 3786, reward 607.0, memory_length 2000, epsilon 0.033046663996336274, time 735.0, rides 151\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 3787, reward 776.0, memory_length 2000, epsilon 0.03301692199873957, time 731.0, rides 148\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 3788, reward 799.0, memory_length 2000, epsilon 0.0329872067689407, time 729.0, rides 136\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 3789, reward 877.0, memory_length 2000, epsilon 0.03295751828284865, time 728.0, rides 144\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 3790, reward 902.0, memory_length 2000, epsilon 0.032927856516394086, time 734.0, rides 136\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 3791, reward 738.0, memory_length 2000, epsilon 0.032898221445529334, time 734.0, rides 138\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 3792, reward 1111.0, memory_length 2000, epsilon 0.03286861304622836, time 732.0, rides 126\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 3793, reward 947.0, memory_length 2000, epsilon 0.03283903129448675, time 725.0, rides 152\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 3794, reward 755.0, memory_length 2000, epsilon 0.03280947616632171, time 730.0, rides 149\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 3795, reward 778.0, memory_length 2000, epsilon 0.03277994763777202, time 731.0, rides 135\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 3796, reward 1124.0, memory_length 2000, epsilon 0.03275044568489802, time 727.0, rides 131\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 3797, reward 651.0, memory_length 2000, epsilon 0.03272097028378161, time 734.0, rides 157\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 3798, reward 940.0, memory_length 2000, epsilon 0.032691521410526204, time 728.0, rides 148\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 3799, reward 1031.0, memory_length 2000, epsilon 0.03266209904125673, time 729.0, rides 135\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 3800, reward 932.0, memory_length 2000, epsilon 0.032632703152119594, time 731.0, rides 137\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 3801, reward 791.0, memory_length 2000, epsilon 0.03260333371928269, time 722.0, rides 126\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 3802, reward 840.0, memory_length 2000, epsilon 0.03257399071893533, time 731.0, rides 134\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 3803, reward 588.0, memory_length 2000, epsilon 0.03254467412728829, time 726.0, rides 136\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 3804, reward 930.0, memory_length 2000, epsilon 0.03251538392057373, time 735.0, rides 149\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3805, reward 987.0, memory_length 2000, epsilon 0.03248612007504521, time 734.0, rides 144\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 3806, reward 479.0, memory_length 2000, epsilon 0.03245688256697767, time 737.0, rides 139\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 3807, reward 1388.0, memory_length 2000, epsilon 0.032427671372667395, time 727.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3808, reward 944.0, memory_length 2000, epsilon 0.03239848646843199, time 731.0, rides 131\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 3809, reward 769.0, memory_length 2000, epsilon 0.0323693278306104, time 738.0, rides 132\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 3810, reward 683.0, memory_length 2000, epsilon 0.03234019543556285, time 727.0, rides 142\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3811, reward 1056.0, memory_length 2000, epsilon 0.03231108925967084, time 737.0, rides 130\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3812, reward 1001.0, memory_length 2000, epsilon 0.03228200927933714, time 723.0, rides 126\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 3813, reward 775.0, memory_length 2000, epsilon 0.032252955470985736, time 726.0, rides 129\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 3814, reward 1009.0, memory_length 2000, epsilon 0.03222392781106185, time 728.0, rides 146\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 3815, reward 707.0, memory_length 2000, epsilon 0.03219492627603189, time 727.0, rides 137\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3816, reward 1207.0, memory_length 2000, epsilon 0.03216595084238346, time 731.0, rides 137\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 3817, reward 988.0, memory_length 2000, epsilon 0.032137001486625315, time 727.0, rides 136\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3818, reward 826.0, memory_length 2000, epsilon 0.03210807818528735, time 728.0, rides 143\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 3819, reward 1247.0, memory_length 2000, epsilon 0.032079180914920596, time 723.0, rides 124\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 3820, reward 1223.0, memory_length 2000, epsilon 0.03205030965209717, time 737.0, rides 122\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 3821, reward 815.0, memory_length 2000, epsilon 0.03202146437341028, time 729.0, rides 136\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 3822, reward 870.0, memory_length 2000, epsilon 0.03199264505547421, time 728.0, rides 127\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 3823, reward 890.0, memory_length 2000, epsilon 0.031963851674924285, time 725.0, rides 133\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3824, reward 1036.0, memory_length 2000, epsilon 0.031935084208416856, time 723.0, rides 146\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 3825, reward 827.0, memory_length 2000, epsilon 0.03190634263262928, time 736.0, rides 130\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 3826, reward 1106.0, memory_length 2000, epsilon 0.03187762692425991, time 723.0, rides 139\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 3827, reward 767.0, memory_length 2000, epsilon 0.031848937060028074, time 733.0, rides 122\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3828, reward 1120.0, memory_length 2000, epsilon 0.03182027301667405, time 726.0, rides 134\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3829, reward 1091.0, memory_length 2000, epsilon 0.03179163477095904, time 727.0, rides 151\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 3830, reward 603.0, memory_length 2000, epsilon 0.031763022299665176, time 732.0, rides 148\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 3831, reward 893.0, memory_length 2000, epsilon 0.031734435579595474, time 726.0, rides 131\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 3832, reward 749.0, memory_length 2000, epsilon 0.03170587458757384, time 726.0, rides 140\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 3833, reward 908.0, memory_length 2000, epsilon 0.03167733930044502, time 724.0, rides 118\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 3834, reward 997.0, memory_length 2000, epsilon 0.03164882969507462, time 729.0, rides 139\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 3835, reward 839.0, memory_length 2000, epsilon 0.03162034574834905, time 739.0, rides 133\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3836, reward 682.0, memory_length 2000, epsilon 0.03159188743717554, time 725.0, rides 121\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3837, reward 974.0, memory_length 2000, epsilon 0.03156345473848208, time 724.0, rides 125\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 3838, reward 875.0, memory_length 2000, epsilon 0.031535047629217446, time 727.0, rides 139\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 3839, reward 848.0, memory_length 2000, epsilon 0.03150666608635115, time 729.0, rides 128\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 3840, reward 1046.0, memory_length 2000, epsilon 0.031478310086873434, time 726.0, rides 128\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 3841, reward 944.0, memory_length 2000, epsilon 0.03144997960779525, time 725.0, rides 130\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 3842, reward 930.0, memory_length 2000, epsilon 0.031421674626148234, time 720.0, rides 135\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3843, reward 1176.0, memory_length 2000, epsilon 0.0313933951189847, time 735.0, rides 135\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 3844, reward 917.0, memory_length 2000, epsilon 0.031365141063377615, time 729.0, rides 122\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 3845, reward 1146.0, memory_length 2000, epsilon 0.031336912436420575, time 730.0, rides 138\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 3846, reward 1033.0, memory_length 2000, epsilon 0.0313087092152278, time 742.0, rides 149\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 3847, reward 722.0, memory_length 2000, epsilon 0.031280531376934095, time 729.0, rides 137\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 3848, reward 847.0, memory_length 2000, epsilon 0.03125237889869485, time 727.0, rides 139\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3849, reward 808.0, memory_length 2000, epsilon 0.031224251757686027, time 728.0, rides 138\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 3850, reward 959.0, memory_length 2000, epsilon 0.03119614993110411, time 723.0, rides 145\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 3851, reward 1011.0, memory_length 2000, epsilon 0.031168073396166115, time 727.0, rides 145\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 3852, reward 1027.0, memory_length 2000, epsilon 0.031140022130109565, time 730.0, rides 145\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 3853, reward 970.0, memory_length 2000, epsilon 0.031111996110192466, time 723.0, rides 131\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 3854, reward 1059.0, memory_length 2000, epsilon 0.031083995313693293, time 730.0, rides 133\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 3855, reward 1079.0, memory_length 2000, epsilon 0.031056019717910967, time 734.0, rides 138\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 3856, reward 1067.0, memory_length 2000, epsilon 0.031028069300164846, time 732.0, rides 147\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 3857, reward 767.0, memory_length 2000, epsilon 0.031000144037794698, time 730.0, rides 148\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 3858, reward 815.0, memory_length 2000, epsilon 0.030972243908160682, time 725.0, rides 135\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 3859, reward 1050.0, memory_length 2000, epsilon 0.030944368888643336, time 724.0, rides 144\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 3860, reward 928.0, memory_length 2000, epsilon 0.030916518956643557, time 724.0, rides 138\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 3861, reward 806.0, memory_length 2000, epsilon 0.030888694089582575, time 732.0, rides 126\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3862, reward 712.0, memory_length 2000, epsilon 0.03086089426490195, time 726.0, rides 124\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 3863, reward 840.0, memory_length 2000, epsilon 0.03083311946006354, time 734.0, rides 139\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 3864, reward 1004.0, memory_length 2000, epsilon 0.030805369652549482, time 730.0, rides 143\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 3865, reward 431.0, memory_length 2000, epsilon 0.03077764481986219, time 730.0, rides 145\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 3866, reward 1025.0, memory_length 2000, epsilon 0.03074994493952431, time 729.0, rides 142\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 3867, reward 737.0, memory_length 2000, epsilon 0.03072226998907874, time 726.0, rides 140\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 3868, reward 830.0, memory_length 2000, epsilon 0.030694619946088568, time 736.0, rides 135\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 3869, reward 1153.0, memory_length 2000, epsilon 0.030666994788137086, time 729.0, rides 142\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 3870, reward 1126.0, memory_length 2000, epsilon 0.03063939449282776, time 724.0, rides 135\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3871, reward 916.0, memory_length 2000, epsilon 0.030611819037784215, time 729.0, rides 138\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 3872, reward 857.0, memory_length 2000, epsilon 0.03058426840065021, time 733.0, rides 142\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 3873, reward 956.0, memory_length 2000, epsilon 0.030556742559089623, time 728.0, rides 147\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 3874, reward 727.0, memory_length 2000, epsilon 0.03052924149078644, time 736.0, rides 146\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 3875, reward 734.0, memory_length 2000, epsilon 0.030501765173444734, time 733.0, rides 131\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 3876, reward 892.0, memory_length 2000, epsilon 0.030474313584788634, time 730.0, rides 143\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 3877, reward 1126.0, memory_length 2000, epsilon 0.030446886702562324, time 724.0, rides 133\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 3878, reward 1046.0, memory_length 2000, epsilon 0.03041948450453002, time 728.0, rides 141\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 3879, reward 1023.0, memory_length 2000, epsilon 0.03039210696847594, time 727.0, rides 130\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 3880, reward 688.0, memory_length 2000, epsilon 0.030364754072204313, time 723.0, rides 130\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 3881, reward 902.0, memory_length 2000, epsilon 0.03033742579353933, time 729.0, rides 154\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 3882, reward 955.0, memory_length 2000, epsilon 0.030310122110325143, time 725.0, rides 145\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 3883, reward 864.0, memory_length 2000, epsilon 0.03028284300042585, time 725.0, rides 142\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3884, reward 876.0, memory_length 2000, epsilon 0.03025558844172547, time 728.0, rides 134\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 3885, reward 847.0, memory_length 2000, epsilon 0.030228358412127915, time 727.0, rides 140\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 3886, reward 772.0, memory_length 2000, epsilon 0.030201152889557, time 730.0, rides 127\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 3887, reward 1105.0, memory_length 2000, epsilon 0.0301739718519564, time 729.0, rides 132\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 3888, reward 1178.0, memory_length 2000, epsilon 0.030146815277289636, time 730.0, rides 147\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3889, reward 986.0, memory_length 2000, epsilon 0.030119683143540073, time 729.0, rides 140\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 3890, reward 813.0, memory_length 2000, epsilon 0.030092575428710886, time 722.0, rides 142\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 3891, reward 727.0, memory_length 2000, epsilon 0.030065492110825046, time 736.0, rides 128\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 3892, reward 992.0, memory_length 2000, epsilon 0.030038433167925302, time 725.0, rides 135\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 3893, reward 1096.0, memory_length 2000, epsilon 0.03001139857807417, time 728.0, rides 140\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 3894, reward 733.0, memory_length 2000, epsilon 0.0299843883193539, time 723.0, rides 143\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3895, reward 699.0, memory_length 2000, epsilon 0.029957402369866482, time 734.0, rides 125\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 3896, reward 1046.0, memory_length 2000, epsilon 0.029930440707733603, time 730.0, rides 137\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 3897, reward 760.0, memory_length 2000, epsilon 0.029903503311096643, time 721.0, rides 127\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 3898, reward 928.0, memory_length 2000, epsilon 0.029876590158116657, time 736.0, rides 140\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3899, reward 652.0, memory_length 2000, epsilon 0.029849701226974352, time 728.0, rides 134\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 3900, reward 1179.0, memory_length 2000, epsilon 0.029822836495870076, time 726.0, rides 146\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 3901, reward 941.0, memory_length 2000, epsilon 0.029795995943023793, time 734.0, rides 132\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 3902, reward 886.0, memory_length 2000, epsilon 0.029769179546675073, time 721.0, rides 127\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3903, reward 1028.0, memory_length 2000, epsilon 0.029742387285083063, time 737.0, rides 140\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 3904, reward 1111.0, memory_length 2000, epsilon 0.029715619136526487, time 724.0, rides 131\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 3905, reward 985.0, memory_length 2000, epsilon 0.029688875079303612, time 725.0, rides 142\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 3906, reward 986.0, memory_length 2000, epsilon 0.02966215509173224, time 734.0, rides 134\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 3907, reward 1155.0, memory_length 2000, epsilon 0.02963545915214968, time 721.0, rides 144\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 3908, reward 905.0, memory_length 2000, epsilon 0.029608787238912745, time 725.0, rides 130\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 3909, reward 791.0, memory_length 2000, epsilon 0.029582139330397723, time 726.0, rides 127\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 3910, reward 953.0, memory_length 2000, epsilon 0.029555515405000364, time 725.0, rides 140\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3911, reward 947.0, memory_length 2000, epsilon 0.029528915441135863, time 725.0, rides 131\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 3912, reward 837.0, memory_length 2000, epsilon 0.02950233941723884, time 724.0, rides 124\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3913, reward 951.0, memory_length 2000, epsilon 0.029475787311763323, time 730.0, rides 130\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 3914, reward 816.0, memory_length 2000, epsilon 0.029449259103182735, time 729.0, rides 130\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 3915, reward 782.0, memory_length 2000, epsilon 0.02942275476998987, time 729.0, rides 133\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 3916, reward 843.0, memory_length 2000, epsilon 0.02939627429069688, time 724.0, rides 140\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 3917, reward 826.0, memory_length 2000, epsilon 0.029369817643835252, time 728.0, rides 147\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 3918, reward 1038.0, memory_length 2000, epsilon 0.0293433848079558, time 736.0, rides 136\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3919, reward 1094.0, memory_length 2000, epsilon 0.02931697576162864, time 730.0, rides 135\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 3920, reward 822.0, memory_length 2000, epsilon 0.029290590483443176, time 730.0, rides 134\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 3921, reward 1375.0, memory_length 2000, epsilon 0.029264228952008076, time 735.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3922, reward 1059.0, memory_length 2000, epsilon 0.02923789114595127, time 727.0, rides 125\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3923, reward 1070.0, memory_length 2000, epsilon 0.029211577043919915, time 722.0, rides 132\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 3924, reward 664.0, memory_length 2000, epsilon 0.02918528662458039, time 723.0, rides 134\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 3925, reward 653.0, memory_length 2000, epsilon 0.029159019866618265, time 738.0, rides 131\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 3926, reward 1008.0, memory_length 2000, epsilon 0.029132776748738307, time 724.0, rides 138\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3927, reward 969.0, memory_length 2000, epsilon 0.02910655724966444, time 723.0, rides 117\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 3928, reward 977.0, memory_length 2000, epsilon 0.029080361348139742, time 734.0, rides 143\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 3929, reward 697.0, memory_length 2000, epsilon 0.029054189022926415, time 732.0, rides 146\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 3930, reward 841.0, memory_length 2000, epsilon 0.02902804025280578, time 726.0, rides 138\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 3931, reward 845.0, memory_length 2000, epsilon 0.029001915016578256, time 729.0, rides 133\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3932, reward 752.0, memory_length 2000, epsilon 0.028975813293063334, time 722.0, rides 141\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3933, reward 928.0, memory_length 2000, epsilon 0.028949735061099578, time 725.0, rides 136\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 3934, reward 843.0, memory_length 2000, epsilon 0.028923680299544587, time 725.0, rides 137\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 3935, reward 968.0, memory_length 2000, epsilon 0.028897648987274996, time 721.0, rides 133\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 3936, reward 1058.0, memory_length 2000, epsilon 0.02887164110318645, time 728.0, rides 128\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 3937, reward 1010.0, memory_length 2000, epsilon 0.02884565662619358, time 729.0, rides 132\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 3938, reward 682.0, memory_length 2000, epsilon 0.028819695535230005, time 728.0, rides 127\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 3939, reward 788.0, memory_length 2000, epsilon 0.028793757809248297, time 724.0, rides 145\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 3940, reward 791.0, memory_length 2000, epsilon 0.028767843427219972, time 722.0, rides 135\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 3941, reward 1038.0, memory_length 2000, epsilon 0.028741952368135475, time 730.0, rides 136\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 3942, reward 758.0, memory_length 2000, epsilon 0.028716084611004153, time 727.0, rides 127\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 3943, reward 1125.0, memory_length 2000, epsilon 0.028690240134854248, time 723.0, rides 132\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 3944, reward 955.0, memory_length 2000, epsilon 0.02866441891873288, time 736.0, rides 134\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 3945, reward 997.0, memory_length 2000, epsilon 0.02863862094170602, time 736.0, rides 137\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 3946, reward 1012.0, memory_length 2000, epsilon 0.028612846182858483, time 733.0, rides 142\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3947, reward 953.0, memory_length 2000, epsilon 0.02858709462129391, time 727.0, rides 133\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 3948, reward 890.0, memory_length 2000, epsilon 0.028561366236134745, time 722.0, rides 131\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3949, reward 949.0, memory_length 2000, epsilon 0.028535661006522224, time 737.0, rides 126\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 3950, reward 928.0, memory_length 2000, epsilon 0.028509978911616354, time 728.0, rides 117\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 3951, reward 924.0, memory_length 2000, epsilon 0.0284843199305959, time 730.0, rides 128\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 3952, reward 830.0, memory_length 2000, epsilon 0.028458684042658364, time 733.0, rides 153\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 3953, reward 1086.0, memory_length 2000, epsilon 0.028433071227019973, time 726.0, rides 132\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 3954, reward 933.0, memory_length 2000, epsilon 0.028407481462915656, time 728.0, rides 136\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 3955, reward 977.0, memory_length 2000, epsilon 0.02838191472959903, time 725.0, rides 126\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 3956, reward 880.0, memory_length 2000, epsilon 0.028356371006342394, time 721.0, rides 135\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 3957, reward 909.0, memory_length 2000, epsilon 0.028330850272436685, time 723.0, rides 125\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 3958, reward 1079.0, memory_length 2000, epsilon 0.028305352507191493, time 731.0, rides 137\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 3959, reward 779.0, memory_length 2000, epsilon 0.02827987768993502, time 734.0, rides 130\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 3960, reward 926.0, memory_length 2000, epsilon 0.02825442580001408, time 730.0, rides 139\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3961, reward 824.0, memory_length 2000, epsilon 0.028228996816794066, time 729.0, rides 127\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 3962, reward 700.0, memory_length 2000, epsilon 0.02820359071965895, time 726.0, rides 139\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 3963, reward 1040.0, memory_length 2000, epsilon 0.028178207488011257, time 727.0, rides 135\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 3964, reward 872.0, memory_length 2000, epsilon 0.028152847101272045, time 726.0, rides 141\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 3965, reward 970.0, memory_length 2000, epsilon 0.0281275095388809, time 734.0, rides 146\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 3966, reward 721.0, memory_length 2000, epsilon 0.028102194780295908, time 725.0, rides 117\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 3967, reward 829.0, memory_length 2000, epsilon 0.028076902804993642, time 733.0, rides 129\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 3968, reward 840.0, memory_length 2000, epsilon 0.028051633592469146, time 724.0, rides 130\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 3969, reward 857.0, memory_length 2000, epsilon 0.028026387122235923, time 731.0, rides 134\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 3970, reward 921.0, memory_length 2000, epsilon 0.02800116337382591, time 731.0, rides 134\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3971, reward 875.0, memory_length 2000, epsilon 0.027975962326789467, time 726.0, rides 130\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 3972, reward 796.0, memory_length 2000, epsilon 0.027950783960695356, time 732.0, rides 122\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 3973, reward 871.0, memory_length 2000, epsilon 0.02792562825513073, time 722.0, rides 122\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 3974, reward 1015.0, memory_length 2000, epsilon 0.027900495189701113, time 728.0, rides 128\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 3975, reward 676.0, memory_length 2000, epsilon 0.027875384744030382, time 727.0, rides 139\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 3976, reward 736.0, memory_length 2000, epsilon 0.027850296897760755, time 726.0, rides 139\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3977, reward 944.0, memory_length 2000, epsilon 0.02782523163055277, time 734.0, rides 127\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 3978, reward 821.0, memory_length 2000, epsilon 0.02780018892208527, time 731.0, rides 129\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 3979, reward 986.0, memory_length 2000, epsilon 0.027775168752055393, time 726.0, rides 129\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 3980, reward 932.0, memory_length 2000, epsilon 0.027750171100178543, time 734.0, rides 134\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3981, reward 1090.0, memory_length 2000, epsilon 0.027725195946188382, time 731.0, rides 122\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 3982, reward 932.0, memory_length 2000, epsilon 0.027700243269836812, time 722.0, rides 126\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 3983, reward 1131.0, memory_length 2000, epsilon 0.02767531305089396, time 729.0, rides 131\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3984, reward 860.0, memory_length 2000, epsilon 0.027650405269148155, time 729.0, rides 138\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 3985, reward 871.0, memory_length 2000, epsilon 0.02762551990440592, time 729.0, rides 134\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 3986, reward 929.0, memory_length 2000, epsilon 0.027600656936491955, time 726.0, rides 128\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 3987, reward 970.0, memory_length 2000, epsilon 0.02757581634524911, time 722.0, rides 144\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 3988, reward 913.0, memory_length 2000, epsilon 0.027550998110538384, time 731.0, rides 116\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 3989, reward 1205.0, memory_length 2000, epsilon 0.0275262022122389, time 729.0, rides 135\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 3990, reward 1017.0, memory_length 2000, epsilon 0.027501428630247883, time 728.0, rides 131\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3991, reward 1094.0, memory_length 2000, epsilon 0.02747667734448066, time 728.0, rides 123\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 3992, reward 1149.0, memory_length 2000, epsilon 0.027451948334870628, time 732.0, rides 135\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 3993, reward 802.0, memory_length 2000, epsilon 0.027427241581369242, time 724.0, rides 127\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3994, reward 808.0, memory_length 2000, epsilon 0.02740255706394601, time 725.0, rides 119\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 3995, reward 995.0, memory_length 2000, epsilon 0.027377894762588458, time 730.0, rides 128\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 3996, reward 1050.0, memory_length 2000, epsilon 0.027353254657302126, time 729.0, rides 141\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 3997, reward 1141.0, memory_length 2000, epsilon 0.027328636728110554, time 727.0, rides 136\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 3998, reward 1039.0, memory_length 2000, epsilon 0.027304040955055255, time 737.0, rides 140\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 3999, reward 826.0, memory_length 2000, epsilon 0.027279467318195704, time 730.0, rides 136\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 4000, reward 1000.0, memory_length 2000, epsilon 0.027254915797609327, time 731.0, rides 142\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4001, reward 789.0, memory_length 2000, epsilon 0.02723038637339148, time 731.0, rides 148\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4002, reward 932.0, memory_length 2000, epsilon 0.027205879025655428, time 733.0, rides 132\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 4003, reward 980.0, memory_length 2000, epsilon 0.02718139373453234, time 721.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4004, reward 782.0, memory_length 2000, epsilon 0.02715693048017126, time 735.0, rides 144\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4005, reward 1074.0, memory_length 2000, epsilon 0.027132489242739106, time 724.0, rides 142\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 4006, reward 1037.0, memory_length 2000, epsilon 0.02710807000242064, time 728.0, rides 127\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4007, reward 1013.0, memory_length 2000, epsilon 0.027083672739418464, time 730.0, rides 130\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 4008, reward 812.0, memory_length 2000, epsilon 0.027059297433952988, time 725.0, rides 135\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 4009, reward 874.0, memory_length 2000, epsilon 0.02703494406626243, time 727.0, rides 130\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 4010, reward 994.0, memory_length 2000, epsilon 0.027010612616602796, time 735.0, rides 127\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 4011, reward 866.0, memory_length 2000, epsilon 0.026986303065247852, time 731.0, rides 133\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 4012, reward 422.0, memory_length 2000, epsilon 0.026962015392489127, time 722.0, rides 124\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 4013, reward 1001.0, memory_length 2000, epsilon 0.026937749578635886, time 732.0, rides 133\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4014, reward 1045.0, memory_length 2000, epsilon 0.026913505604015113, time 732.0, rides 140\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 4015, reward 786.0, memory_length 2000, epsilon 0.0268892834489715, time 732.0, rides 123\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 4016, reward 831.0, memory_length 2000, epsilon 0.026865083093867426, time 733.0, rides 138\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 4017, reward 665.0, memory_length 2000, epsilon 0.026840904519082946, time 735.0, rides 130\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 4018, reward 869.0, memory_length 2000, epsilon 0.02681674770501577, time 724.0, rides 127\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 4019, reward 986.0, memory_length 2000, epsilon 0.026792612632081256, time 726.0, rides 132\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4020, reward 825.0, memory_length 2000, epsilon 0.02676849928071238, time 735.0, rides 129\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 4021, reward 851.0, memory_length 2000, epsilon 0.02674440763135974, time 728.0, rides 133\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 4022, reward 918.0, memory_length 2000, epsilon 0.026720337664491518, time 725.0, rides 131\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 4023, reward 831.0, memory_length 2000, epsilon 0.026696289360593473, time 724.0, rides 130\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 4024, reward 941.0, memory_length 2000, epsilon 0.02667226270016894, time 729.0, rides 136\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 4025, reward 1092.0, memory_length 2000, epsilon 0.026648257663738788, time 733.0, rides 126\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 4026, reward 906.0, memory_length 2000, epsilon 0.02662427423184142, time 731.0, rides 133\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4027, reward 579.0, memory_length 2000, epsilon 0.026600312385032764, time 726.0, rides 121\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 4028, reward 912.0, memory_length 2000, epsilon 0.026576372103886234, time 724.0, rides 134\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 4029, reward 697.0, memory_length 2000, epsilon 0.026552453368992736, time 724.0, rides 123\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 4030, reward 935.0, memory_length 2000, epsilon 0.026528556160960642, time 734.0, rides 139\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 4031, reward 1071.0, memory_length 2000, epsilon 0.026504680460415778, time 728.0, rides 140\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 4032, reward 845.0, memory_length 2000, epsilon 0.026480826248001403, time 732.0, rides 136\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4033, reward 876.0, memory_length 2000, epsilon 0.0264569935043782, time 727.0, rides 141\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 4034, reward 783.0, memory_length 2000, epsilon 0.02643318221022426, time 739.0, rides 124\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 4035, reward 898.0, memory_length 2000, epsilon 0.02640939234623506, time 726.0, rides 135\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 4036, reward 899.0, memory_length 2000, epsilon 0.026385623893123447, time 724.0, rides 122\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 4037, reward 774.0, memory_length 2000, epsilon 0.026361876831619637, time 729.0, rides 116\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 4038, reward 1137.0, memory_length 2000, epsilon 0.026338151142471178, time 723.0, rides 148\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 4039, reward 978.0, memory_length 2000, epsilon 0.026314446806442952, time 733.0, rides 126\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 4040, reward 716.0, memory_length 2000, epsilon 0.026290763804317153, time 724.0, rides 136\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 4041, reward 947.0, memory_length 2000, epsilon 0.026267102116893266, time 732.0, rides 136\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 4042, reward 1060.0, memory_length 2000, epsilon 0.026243461724988062, time 727.0, rides 133\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4043, reward 669.0, memory_length 2000, epsilon 0.02621984260943557, time 733.0, rides 141\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 4044, reward 907.0, memory_length 2000, epsilon 0.02619624475108708, time 724.0, rides 129\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 4045, reward 859.0, memory_length 2000, epsilon 0.0261726681308111, time 729.0, rides 132\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4046, reward 1096.0, memory_length 2000, epsilon 0.02614911272949337, time 729.0, rides 130\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 4047, reward 976.0, memory_length 2000, epsilon 0.026125578528036826, time 724.0, rides 139\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4048, reward 841.0, memory_length 2000, epsilon 0.02610206550736159, time 730.0, rides 120\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 4049, reward 1084.0, memory_length 2000, epsilon 0.026078573648404966, time 723.0, rides 139\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 4050, reward 1010.0, memory_length 2000, epsilon 0.0260551029321214, time 726.0, rides 132\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 4051, reward 865.0, memory_length 2000, epsilon 0.026031653339482493, time 732.0, rides 130\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 4052, reward 895.0, memory_length 2000, epsilon 0.02600822485147696, time 726.0, rides 133\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 4053, reward 860.0, memory_length 2000, epsilon 0.025984817449110627, time 735.0, rides 134\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 4054, reward 964.0, memory_length 2000, epsilon 0.025961431113406427, time 730.0, rides 139\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 4055, reward 780.0, memory_length 2000, epsilon 0.02593806582540436, time 728.0, rides 137\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 4056, reward 704.0, memory_length 2000, epsilon 0.025914721566161494, time 725.0, rides 136\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 4057, reward 704.0, memory_length 2000, epsilon 0.025891398316751947, time 726.0, rides 140\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 4058, reward 885.0, memory_length 2000, epsilon 0.02586809605826687, time 729.0, rides 133\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4059, reward 634.0, memory_length 2000, epsilon 0.02584481477181443, time 732.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 4060, reward 1308.0, memory_length 2000, epsilon 0.025821554438519797, time 728.0, rides 152\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4061, reward 1132.0, memory_length 2000, epsilon 0.02579831503952513, time 727.0, rides 131\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 4062, reward 809.0, memory_length 2000, epsilon 0.025775096555989554, time 734.0, rides 120\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4063, reward 1014.0, memory_length 2000, epsilon 0.025751898969089162, time 726.0, rides 134\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 4064, reward 873.0, memory_length 2000, epsilon 0.025728722260016983, time 727.0, rides 145\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 4065, reward 1038.0, memory_length 2000, epsilon 0.025705566409982967, time 731.0, rides 123\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 4066, reward 799.0, memory_length 2000, epsilon 0.025682431400213982, time 724.0, rides 130\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 4067, reward 752.0, memory_length 2000, epsilon 0.02565931721195379, time 729.0, rides 115\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 4068, reward 924.0, memory_length 2000, epsilon 0.02563622382646303, time 726.0, rides 135\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4069, reward 817.0, memory_length 2000, epsilon 0.025613151225019212, time 738.0, rides 132\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 4070, reward 752.0, memory_length 2000, epsilon 0.025590099388916696, time 731.0, rides 128\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 4071, reward 1103.0, memory_length 2000, epsilon 0.02556706829946667, time 733.0, rides 140\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4072, reward 806.0, memory_length 2000, epsilon 0.025544057937997147, time 727.0, rides 127\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 4073, reward 1013.0, memory_length 2000, epsilon 0.02552106828585295, time 728.0, rides 140\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 4074, reward 872.0, memory_length 2000, epsilon 0.02549809932439568, time 728.0, rides 130\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 4075, reward 654.0, memory_length 2000, epsilon 0.025475151035003724, time 727.0, rides 126\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 4076, reward 858.0, memory_length 2000, epsilon 0.02545222339907222, time 722.0, rides 139\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 4077, reward 868.0, memory_length 2000, epsilon 0.025429316398013053, time 727.0, rides 125\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 4078, reward 761.0, memory_length 2000, epsilon 0.025406430013254842, time 724.0, rides 137\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 4079, reward 635.0, memory_length 2000, epsilon 0.025383564226242914, time 724.0, rides 138\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 4080, reward 855.0, memory_length 2000, epsilon 0.025360719018439296, time 723.0, rides 143\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 4081, reward 435.0, memory_length 2000, epsilon 0.0253378943713227, time 723.0, rides 126\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 4082, reward 701.0, memory_length 2000, epsilon 0.02531509026638851, time 735.0, rides 144\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 4083, reward 804.0, memory_length 2000, epsilon 0.02529230668514876, time 730.0, rides 133\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 4084, reward 608.0, memory_length 2000, epsilon 0.02526954360913213, time 733.0, rides 120\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4085, reward 958.0, memory_length 2000, epsilon 0.02524680101988391, time 725.0, rides 139\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 4086, reward 1190.0, memory_length 2000, epsilon 0.025224078898966013, time 734.0, rides 129\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 4087, reward 822.0, memory_length 2000, epsilon 0.025201377227956942, time 725.0, rides 125\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 4088, reward 1062.0, memory_length 2000, epsilon 0.02517869598845178, time 729.0, rides 139\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 4089, reward 963.0, memory_length 2000, epsilon 0.025156035162062173, time 728.0, rides 124\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 4090, reward 809.0, memory_length 2000, epsilon 0.025133394730416318, time 734.0, rides 131\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 4091, reward 784.0, memory_length 2000, epsilon 0.02511077467515894, time 724.0, rides 123\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 4092, reward 1013.0, memory_length 2000, epsilon 0.025088174977951298, time 740.0, rides 133\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 4093, reward 739.0, memory_length 2000, epsilon 0.025065595620471143, time 725.0, rides 132\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 4094, reward 686.0, memory_length 2000, epsilon 0.025043036584412717, time 734.0, rides 134\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 4095, reward 772.0, memory_length 2000, epsilon 0.025020497851486745, time 737.0, rides 122\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 4096, reward 814.0, memory_length 2000, epsilon 0.024997979403420408, time 727.0, rides 134\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 4097, reward 948.0, memory_length 2000, epsilon 0.02497548122195733, time 730.0, rides 132\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 4098, reward 903.0, memory_length 2000, epsilon 0.024953003288857568, time 729.0, rides 132\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 4099, reward 928.0, memory_length 2000, epsilon 0.024930545585897596, time 724.0, rides 127\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 4100, reward 1062.0, memory_length 2000, epsilon 0.024908108094870287, time 726.0, rides 137\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4101, reward 817.0, memory_length 2000, epsilon 0.024885690797584903, time 725.0, rides 131\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 4102, reward 866.0, memory_length 2000, epsilon 0.024863293675867076, time 728.0, rides 134\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 4103, reward 588.0, memory_length 2000, epsilon 0.024840916711558796, time 730.0, rides 137\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 4104, reward 973.0, memory_length 2000, epsilon 0.024818559886518394, time 736.0, rides 131\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 4105, reward 909.0, memory_length 2000, epsilon 0.024796223182620526, time 723.0, rides 135\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 4106, reward 846.0, memory_length 2000, epsilon 0.024773906581756166, time 734.0, rides 133\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 4107, reward 918.0, memory_length 2000, epsilon 0.024751610065832586, time 734.0, rides 127\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4108, reward 782.0, memory_length 2000, epsilon 0.024729333616773336, time 731.0, rides 121\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4109, reward 1044.0, memory_length 2000, epsilon 0.024707077216518242, time 730.0, rides 132\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 4110, reward 974.0, memory_length 2000, epsilon 0.024684840847023375, time 725.0, rides 128\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4111, reward 929.0, memory_length 2000, epsilon 0.02466262449026105, time 730.0, rides 120\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 4112, reward 575.0, memory_length 2000, epsilon 0.024640428128219816, time 736.0, rides 133\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 4113, reward 879.0, memory_length 2000, epsilon 0.02461825174290442, time 730.0, rides 127\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4114, reward 1166.0, memory_length 2000, epsilon 0.024596095316335807, time 730.0, rides 130\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 4115, reward 610.0, memory_length 2000, epsilon 0.024573958830551103, time 723.0, rides 140\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 4116, reward 801.0, memory_length 2000, epsilon 0.024551842267603607, time 728.0, rides 122\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4117, reward 730.0, memory_length 2000, epsilon 0.024529745609562763, time 735.0, rides 127\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 4118, reward 714.0, memory_length 2000, epsilon 0.024507668838514157, time 735.0, rides 134\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 4119, reward 973.0, memory_length 2000, epsilon 0.024485611936559494, time 728.0, rides 133\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 4120, reward 920.0, memory_length 2000, epsilon 0.02446357488581659, time 725.0, rides 132\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 4121, reward 859.0, memory_length 2000, epsilon 0.024441557668419354, time 729.0, rides 122\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 4122, reward 991.0, memory_length 2000, epsilon 0.024419560266517776, time 729.0, rides 140\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 4123, reward 615.0, memory_length 2000, epsilon 0.02439758266227791, time 731.0, rides 129\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 4124, reward 612.0, memory_length 2000, epsilon 0.02437562483788186, time 727.0, rides 146\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 4125, reward 1076.0, memory_length 2000, epsilon 0.024353686775527766, time 738.0, rides 123\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4126, reward 1258.0, memory_length 2000, epsilon 0.024331768457429792, time 727.0, rides 136\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 4127, reward 1123.0, memory_length 2000, epsilon 0.024309869865818106, time 733.0, rides 133\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 4128, reward 1168.0, memory_length 2000, epsilon 0.024287990982938868, time 727.0, rides 135\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 4129, reward 781.0, memory_length 2000, epsilon 0.024266131791054222, time 732.0, rides 135\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 4130, reward 1093.0, memory_length 2000, epsilon 0.024244292272442274, time 731.0, rides 141\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4131, reward 1002.0, memory_length 2000, epsilon 0.024222472409397077, time 740.0, rides 143\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 4132, reward 1041.0, memory_length 2000, epsilon 0.024200672184228618, time 724.0, rides 125\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 4133, reward 897.0, memory_length 2000, epsilon 0.024178891579262812, time 727.0, rides 129\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4134, reward 882.0, memory_length 2000, epsilon 0.024157130576841476, time 730.0, rides 144\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 4135, reward 1065.0, memory_length 2000, epsilon 0.02413538915932232, time 728.0, rides 129\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 4136, reward 888.0, memory_length 2000, epsilon 0.024113667309078927, time 733.0, rides 122\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 4137, reward 1087.0, memory_length 2000, epsilon 0.024091965008500756, time 724.0, rides 130\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 4138, reward 808.0, memory_length 2000, epsilon 0.024070282239993104, time 728.0, rides 133\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4139, reward 884.0, memory_length 2000, epsilon 0.02404861898597711, time 728.0, rides 143\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 4140, reward 942.0, memory_length 2000, epsilon 0.02402697522888973, time 724.0, rides 135\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 4141, reward 719.0, memory_length 2000, epsilon 0.024005350951183727, time 725.0, rides 126\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 4142, reward 1200.0, memory_length 2000, epsilon 0.023983746135327663, time 733.0, rides 125\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4143, reward 1064.0, memory_length 2000, epsilon 0.02396216076380587, time 733.0, rides 135\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 4144, reward 1059.0, memory_length 2000, epsilon 0.023940594819118442, time 723.0, rides 128\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 4145, reward 701.0, memory_length 2000, epsilon 0.023919048283781236, time 721.0, rides 132\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 4146, reward 901.0, memory_length 2000, epsilon 0.023897521140325832, time 724.0, rides 133\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 4147, reward 1381.0, memory_length 2000, epsilon 0.023876013371299538, time 729.0, rides 139\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 4148, reward 1108.0, memory_length 2000, epsilon 0.023854524959265367, time 732.0, rides 115\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 4149, reward 1201.0, memory_length 2000, epsilon 0.023833055886802026, time 724.0, rides 141\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 4150, reward 923.0, memory_length 2000, epsilon 0.023811606136503904, time 722.0, rides 143\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 4151, reward 947.0, memory_length 2000, epsilon 0.02379017569098105, time 729.0, rides 135\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 4152, reward 919.0, memory_length 2000, epsilon 0.023768764532859168, time 731.0, rides 126\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4153, reward 1121.0, memory_length 2000, epsilon 0.023747372644779594, time 730.0, rides 131\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4154, reward 769.0, memory_length 2000, epsilon 0.02372600000939929, time 737.0, rides 127\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 4155, reward 960.0, memory_length 2000, epsilon 0.023704646609390832, time 732.0, rides 142\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 4156, reward 956.0, memory_length 2000, epsilon 0.02368331242744238, time 728.0, rides 124\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 4157, reward 1027.0, memory_length 2000, epsilon 0.023661997446257684, time 729.0, rides 127\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 4158, reward 811.0, memory_length 2000, epsilon 0.023640701648556053, time 728.0, rides 138\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 4159, reward 1021.0, memory_length 2000, epsilon 0.023619425017072353, time 733.0, rides 127\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 4160, reward 1228.0, memory_length 2000, epsilon 0.02359816753455699, time 729.0, rides 134\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 4161, reward 1074.0, memory_length 2000, epsilon 0.023576929183775887, time 730.0, rides 134\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 4162, reward 906.0, memory_length 2000, epsilon 0.023555709947510488, time 727.0, rides 127\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4163, reward 1067.0, memory_length 2000, epsilon 0.02353450980855773, time 734.0, rides 144\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4164, reward 790.0, memory_length 2000, epsilon 0.023513328749730028, time 730.0, rides 130\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 4165, reward 816.0, memory_length 2000, epsilon 0.02349216675385527, time 726.0, rides 125\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 4166, reward 882.0, memory_length 2000, epsilon 0.023471023803776803, time 727.0, rides 136\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 4167, reward 926.0, memory_length 2000, epsilon 0.023449899882353402, time 724.0, rides 138\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 4168, reward 940.0, memory_length 2000, epsilon 0.023428794972459283, time 735.0, rides 138\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 4169, reward 971.0, memory_length 2000, epsilon 0.02340770905698407, time 725.0, rides 145\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 4170, reward 889.0, memory_length 2000, epsilon 0.023386642118832783, time 725.0, rides 150\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 4171, reward 1157.0, memory_length 2000, epsilon 0.023365594140925833, time 728.0, rides 135\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 4172, reward 917.0, memory_length 2000, epsilon 0.023344565106199, time 730.0, rides 138\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 4173, reward 958.0, memory_length 2000, epsilon 0.02332355499760342, time 730.0, rides 121\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 4174, reward 515.0, memory_length 2000, epsilon 0.023302563798105577, time 734.0, rides 122\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4175, reward 1116.0, memory_length 2000, epsilon 0.02328159149068728, time 734.0, rides 144\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 4176, reward 955.0, memory_length 2000, epsilon 0.023260638058345662, time 730.0, rides 130\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 4177, reward 872.0, memory_length 2000, epsilon 0.02323970348409315, time 721.0, rides 138\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 4178, reward 815.0, memory_length 2000, epsilon 0.023218787750957467, time 726.0, rides 130\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 4179, reward 877.0, memory_length 2000, epsilon 0.023197890841981605, time 723.0, rides 131\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 4180, reward 528.0, memory_length 2000, epsilon 0.02317701274022382, time 731.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4181, reward 1081.0, memory_length 2000, epsilon 0.02315615342875762, time 721.0, rides 142\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 4182, reward 823.0, memory_length 2000, epsilon 0.023135312890671736, time 723.0, rides 120\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 4183, reward 919.0, memory_length 2000, epsilon 0.023114491109070132, time 727.0, rides 145\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 4184, reward 857.0, memory_length 2000, epsilon 0.02309368806707197, time 722.0, rides 136\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 4185, reward 915.0, memory_length 2000, epsilon 0.023072903747811607, time 728.0, rides 134\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4186, reward 878.0, memory_length 2000, epsilon 0.023052138134438575, time 731.0, rides 134\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 4187, reward 1163.0, memory_length 2000, epsilon 0.02303139121011758, time 724.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 4188, reward 680.0, memory_length 2000, epsilon 0.023010662958028474, time 726.0, rides 129\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 4189, reward 996.0, memory_length 2000, epsilon 0.022989953361366246, time 733.0, rides 126\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 4190, reward 1365.0, memory_length 2000, epsilon 0.022969262403341018, time 731.0, rides 136\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 4191, reward 1062.0, memory_length 2000, epsilon 0.02294859006717801, time 725.0, rides 130\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 4192, reward 940.0, memory_length 2000, epsilon 0.02292793633611755, time 730.0, rides 145\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 4193, reward 984.0, memory_length 2000, epsilon 0.022907301193415042, time 727.0, rides 126\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 4194, reward 695.0, memory_length 2000, epsilon 0.022886684622340968, time 723.0, rides 137\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4195, reward 1154.0, memory_length 2000, epsilon 0.02286608660618086, time 729.0, rides 112\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 4196, reward 683.0, memory_length 2000, epsilon 0.0228455071282353, time 730.0, rides 139\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 4197, reward 975.0, memory_length 2000, epsilon 0.022824946171819887, time 724.0, rides 129\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 4198, reward 908.0, memory_length 2000, epsilon 0.022804403720265248, time 725.0, rides 122\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 4199, reward 875.0, memory_length 2000, epsilon 0.022783879756917008, time 726.0, rides 135\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 4200, reward 910.0, memory_length 2000, epsilon 0.022763374265135784, time 736.0, rides 135\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 4201, reward 1064.0, memory_length 2000, epsilon 0.022742887228297162, time 726.0, rides 132\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 4202, reward 999.0, memory_length 2000, epsilon 0.022722418629791696, time 727.0, rides 132\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4203, reward 1154.0, memory_length 2000, epsilon 0.022701968453024884, time 731.0, rides 122\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 4204, reward 760.0, memory_length 2000, epsilon 0.02268153668141716, time 730.0, rides 129\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 4205, reward 884.0, memory_length 2000, epsilon 0.022661123298403887, time 724.0, rides 137\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 4206, reward 966.0, memory_length 2000, epsilon 0.022640728287435324, time 726.0, rides 136\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 4207, reward 852.0, memory_length 2000, epsilon 0.02262035163197663, time 727.0, rides 128\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4208, reward 946.0, memory_length 2000, epsilon 0.02259999331550785, time 735.0, rides 137\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4209, reward 905.0, memory_length 2000, epsilon 0.022579653321523892, time 725.0, rides 128\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 4210, reward 877.0, memory_length 2000, epsilon 0.022559331633534522, time 724.0, rides 125\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 4211, reward 789.0, memory_length 2000, epsilon 0.022539028235064342, time 726.0, rides 123\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 4212, reward 982.0, memory_length 2000, epsilon 0.022518743109652784, time 734.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 4213, reward 1016.0, memory_length 2000, epsilon 0.022498476240854097, time 725.0, rides 125\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 4214, reward 749.0, memory_length 2000, epsilon 0.022478227612237327, time 731.0, rides 130\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 4215, reward 726.0, memory_length 2000, epsilon 0.022457997207386313, time 728.0, rides 115\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 4216, reward 779.0, memory_length 2000, epsilon 0.022437785009899666, time 730.0, rides 120\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 4217, reward 1091.0, memory_length 2000, epsilon 0.022417591003390757, time 730.0, rides 132\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 4218, reward 800.0, memory_length 2000, epsilon 0.022397415171487706, time 724.0, rides 121\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 4219, reward 933.0, memory_length 2000, epsilon 0.022377257497833366, time 729.0, rides 136\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 4220, reward 1093.0, memory_length 2000, epsilon 0.022357117966085315, time 721.0, rides 138\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 4221, reward 832.0, memory_length 2000, epsilon 0.022336996559915837, time 723.0, rides 122\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 4222, reward 1203.0, memory_length 2000, epsilon 0.02231689326301191, time 724.0, rides 131\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 4223, reward 773.0, memory_length 2000, epsilon 0.0222968080590752, time 730.0, rides 122\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 4224, reward 804.0, memory_length 2000, epsilon 0.022276740931822032, time 727.0, rides 121\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 4225, reward 785.0, memory_length 2000, epsilon 0.022256691864983393, time 728.0, rides 125\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 4226, reward 1131.0, memory_length 2000, epsilon 0.022236660842304908, time 730.0, rides 123\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 4227, reward 1044.0, memory_length 2000, epsilon 0.022216647847546834, time 736.0, rides 128\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4228, reward 856.0, memory_length 2000, epsilon 0.02219665286448404, time 729.0, rides 137\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 4229, reward 937.0, memory_length 2000, epsilon 0.022176675876906006, time 723.0, rides 130\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 4230, reward 848.0, memory_length 2000, epsilon 0.02215671686861679, time 734.0, rides 124\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 4231, reward 1155.0, memory_length 2000, epsilon 0.022136775823435033, time 731.0, rides 124\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 4232, reward 813.0, memory_length 2000, epsilon 0.022116852725193942, time 729.0, rides 125\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 4233, reward 967.0, memory_length 2000, epsilon 0.02209694755774127, time 729.0, rides 126\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 4234, reward 981.0, memory_length 2000, epsilon 0.022077060304939302, time 731.0, rides 134\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 4235, reward 881.0, memory_length 2000, epsilon 0.022057190950664857, time 730.0, rides 147\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 4236, reward 608.0, memory_length 2000, epsilon 0.02203733947880926, time 724.0, rides 118\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 4237, reward 1114.0, memory_length 2000, epsilon 0.02201750587327833, time 735.0, rides 137\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 4238, reward 1117.0, memory_length 2000, epsilon 0.02199769011799238, time 735.0, rides 141\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 4239, reward 822.0, memory_length 2000, epsilon 0.021977892196886187, time 731.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 4240, reward 931.0, memory_length 2000, epsilon 0.02195811209390899, time 729.0, rides 125\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 4241, reward 905.0, memory_length 2000, epsilon 0.021938349793024472, time 737.0, rides 137\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 4242, reward 904.0, memory_length 2000, epsilon 0.02191860527821075, time 729.0, rides 142\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 4243, reward 744.0, memory_length 2000, epsilon 0.02189887853346036, time 727.0, rides 135\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 4244, reward 647.0, memory_length 2000, epsilon 0.021879169542780245, time 722.0, rides 136\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 4245, reward 1026.0, memory_length 2000, epsilon 0.021859478290191744, time 725.0, rides 127\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 4246, reward 1167.0, memory_length 2000, epsilon 0.02183980475973057, time 733.0, rides 149\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 4247, reward 1014.0, memory_length 2000, epsilon 0.021820148935446815, time 731.0, rides 142\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4248, reward 1028.0, memory_length 2000, epsilon 0.021800510801404913, time 727.0, rides 121\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 4249, reward 680.0, memory_length 2000, epsilon 0.021780890341683647, time 729.0, rides 116\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4250, reward 756.0, memory_length 2000, epsilon 0.021761287540376133, time 724.0, rides 121\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 4251, reward 797.0, memory_length 2000, epsilon 0.021741702381589796, time 722.0, rides 137\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 4252, reward 764.0, memory_length 2000, epsilon 0.021722134849446365, time 724.0, rides 141\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 4253, reward 1029.0, memory_length 2000, epsilon 0.021702584928081862, time 727.0, rides 129\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4254, reward 799.0, memory_length 2000, epsilon 0.021683052601646588, time 725.0, rides 121\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4255, reward 623.0, memory_length 2000, epsilon 0.021663537854305106, time 727.0, rides 125\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 4256, reward 988.0, memory_length 2000, epsilon 0.02164404067023623, time 722.0, rides 136\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4257, reward 757.0, memory_length 2000, epsilon 0.021624561033633017, time 729.0, rides 128\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 4258, reward 759.0, memory_length 2000, epsilon 0.021605098928702746, time 734.0, rides 124\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 4259, reward 1101.0, memory_length 2000, epsilon 0.021585654339666912, time 739.0, rides 138\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 4260, reward 999.0, memory_length 2000, epsilon 0.02156622725076121, time 731.0, rides 124\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 4261, reward 788.0, memory_length 2000, epsilon 0.021546817646235526, time 725.0, rides 127\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 4262, reward 1008.0, memory_length 2000, epsilon 0.021527425510353915, time 736.0, rides 136\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4263, reward 927.0, memory_length 2000, epsilon 0.021508050827394595, time 724.0, rides 126\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4264, reward 1208.0, memory_length 2000, epsilon 0.02148869358164994, time 731.0, rides 137\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 4265, reward 775.0, memory_length 2000, epsilon 0.021469353757426455, time 733.0, rides 137\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 4266, reward 809.0, memory_length 2000, epsilon 0.02145003133904477, time 730.0, rides 128\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 4267, reward 1071.0, memory_length 2000, epsilon 0.02143072631083963, time 725.0, rides 142\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 4268, reward 783.0, memory_length 2000, epsilon 0.021411438657159873, time 732.0, rides 136\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4269, reward 1197.0, memory_length 2000, epsilon 0.02139216836236843, time 731.0, rides 145\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 4270, reward 919.0, memory_length 2000, epsilon 0.021372915410842297, time 730.0, rides 144\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4271, reward 872.0, memory_length 2000, epsilon 0.02135367978697254, time 728.0, rides 141\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 4272, reward 920.0, memory_length 2000, epsilon 0.021334461475164265, time 723.0, rides 128\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 4273, reward 957.0, memory_length 2000, epsilon 0.021315260459836616, time 725.0, rides 143\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 4274, reward 816.0, memory_length 2000, epsilon 0.021296076725422764, time 732.0, rides 144\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 4275, reward 708.0, memory_length 2000, epsilon 0.021276910256369883, time 731.0, rides 140\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 4276, reward 1079.0, memory_length 2000, epsilon 0.02125776103713915, time 731.0, rides 133\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 4277, reward 1032.0, memory_length 2000, epsilon 0.021238629052205724, time 725.0, rides 136\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 4278, reward 1108.0, memory_length 2000, epsilon 0.021219514286058738, time 728.0, rides 140\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4279, reward 1102.0, memory_length 2000, epsilon 0.021200416723201283, time 729.0, rides 125\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 4280, reward 773.0, memory_length 2000, epsilon 0.021181336348150403, time 728.0, rides 133\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 4281, reward 852.0, memory_length 2000, epsilon 0.021162273145437067, time 732.0, rides 130\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 4282, reward 1062.0, memory_length 2000, epsilon 0.021143227099606175, time 727.0, rides 149\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 4283, reward 996.0, memory_length 2000, epsilon 0.021124198195216527, time 729.0, rides 131\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4284, reward 951.0, memory_length 2000, epsilon 0.02110518641684083, time 731.0, rides 131\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 4285, reward 792.0, memory_length 2000, epsilon 0.021086191749065675, time 726.0, rides 128\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 4286, reward 967.0, memory_length 2000, epsilon 0.021067214176491517, time 725.0, rides 136\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 4287, reward 744.0, memory_length 2000, epsilon 0.021048253683732674, time 723.0, rides 125\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4288, reward 985.0, memory_length 2000, epsilon 0.021029310255417315, time 723.0, rides 127\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 4289, reward 1043.0, memory_length 2000, epsilon 0.02101038387618744, time 727.0, rides 136\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 4290, reward 910.0, memory_length 2000, epsilon 0.02099147453069887, time 725.0, rides 131\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 4291, reward 715.0, memory_length 2000, epsilon 0.02097258220362124, time 733.0, rides 127\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 4292, reward 1064.0, memory_length 2000, epsilon 0.020953706879637983, time 728.0, rides 121\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4293, reward 1203.0, memory_length 2000, epsilon 0.020934848543446308, time 722.0, rides 136\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4294, reward 1007.0, memory_length 2000, epsilon 0.020916007179757206, time 728.0, rides 128\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 4295, reward 1129.0, memory_length 2000, epsilon 0.020897182773295424, time 725.0, rides 146\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 4296, reward 868.0, memory_length 2000, epsilon 0.02087837530879946, time 723.0, rides 123\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 4297, reward 896.0, memory_length 2000, epsilon 0.02085958477102154, time 725.0, rides 130\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 4298, reward 1036.0, memory_length 2000, epsilon 0.02084081114472762, time 724.0, rides 124\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 4299, reward 913.0, memory_length 2000, epsilon 0.020822054414697363, time 730.0, rides 144\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4300, reward 1000.0, memory_length 2000, epsilon 0.020803314565724134, time 728.0, rides 134\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 4301, reward 960.0, memory_length 2000, epsilon 0.020784591582614982, time 725.0, rides 132\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 4302, reward 613.0, memory_length 2000, epsilon 0.02076588545019063, time 736.0, rides 133\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 4303, reward 857.0, memory_length 2000, epsilon 0.020747196153285456, time 735.0, rides 140\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 4304, reward 1316.0, memory_length 2000, epsilon 0.0207285236767475, time 728.0, rides 140\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 4305, reward 787.0, memory_length 2000, epsilon 0.020709868005438427, time 723.0, rides 144\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4306, reward 958.0, memory_length 2000, epsilon 0.02069122912423353, time 734.0, rides 131\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 4307, reward 764.0, memory_length 2000, epsilon 0.020672607018021722, time 730.0, rides 135\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 4308, reward 922.0, memory_length 2000, epsilon 0.020654001671705502, time 726.0, rides 137\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4309, reward 818.0, memory_length 2000, epsilon 0.02063541307020097, time 728.0, rides 132\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 4310, reward 865.0, memory_length 2000, epsilon 0.020616841198437787, time 727.0, rides 123\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 4311, reward 905.0, memory_length 2000, epsilon 0.020598286041359194, time 725.0, rides 138\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 4312, reward 904.0, memory_length 2000, epsilon 0.020579747583921972, time 725.0, rides 138\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 4313, reward 1073.0, memory_length 2000, epsilon 0.020561225811096442, time 734.0, rides 132\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 4314, reward 835.0, memory_length 2000, epsilon 0.020542720707866457, time 729.0, rides 128\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 4315, reward 950.0, memory_length 2000, epsilon 0.020524232259229377, time 725.0, rides 131\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4316, reward 945.0, memory_length 2000, epsilon 0.02050576045019607, time 725.0, rides 132\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 4317, reward 944.0, memory_length 2000, epsilon 0.020487305265790894, time 726.0, rides 132\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 4318, reward 920.0, memory_length 2000, epsilon 0.02046886669105168, time 723.0, rides 130\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 4319, reward 731.0, memory_length 2000, epsilon 0.020450444711029733, time 735.0, rides 133\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 4320, reward 720.0, memory_length 2000, epsilon 0.020432039310789806, time 730.0, rides 128\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 4321, reward 941.0, memory_length 2000, epsilon 0.020413650475410095, time 731.0, rides 142\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 4322, reward 1020.0, memory_length 2000, epsilon 0.020395278189982227, time 726.0, rides 135\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 4323, reward 781.0, memory_length 2000, epsilon 0.020376922439611242, time 729.0, rides 133\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4324, reward 1050.0, memory_length 2000, epsilon 0.020358583209415592, time 740.0, rides 135\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 4325, reward 737.0, memory_length 2000, epsilon 0.02034026048452712, time 726.0, rides 125\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 4326, reward 683.0, memory_length 2000, epsilon 0.020321954250091045, time 725.0, rides 137\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 4327, reward 1011.0, memory_length 2000, epsilon 0.02030366449126596, time 727.0, rides 147\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 4328, reward 872.0, memory_length 2000, epsilon 0.020285391193223822, time 730.0, rides 141\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 4329, reward 1111.0, memory_length 2000, epsilon 0.02026713434114992, time 724.0, rides 141\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 4330, reward 941.0, memory_length 2000, epsilon 0.020248893920242886, time 726.0, rides 118\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 4331, reward 667.0, memory_length 2000, epsilon 0.020230669915714667, time 732.0, rides 129\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 4332, reward 994.0, memory_length 2000, epsilon 0.020212462312790523, time 726.0, rides 135\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 4333, reward 941.0, memory_length 2000, epsilon 0.020194271096709012, time 726.0, rides 129\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 4334, reward 807.0, memory_length 2000, epsilon 0.020176096252721973, time 730.0, rides 133\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 4335, reward 725.0, memory_length 2000, epsilon 0.020157937766094522, time 727.0, rides 130\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4336, reward 1065.0, memory_length 2000, epsilon 0.020139795622105036, time 730.0, rides 123\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 4337, reward 859.0, memory_length 2000, epsilon 0.020121669806045142, time 737.0, rides 138\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4338, reward 659.0, memory_length 2000, epsilon 0.020103560303219702, time 729.0, rides 142\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 4339, reward 636.0, memory_length 2000, epsilon 0.020085467098946805, time 730.0, rides 123\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 4340, reward 824.0, memory_length 2000, epsilon 0.020067390178557753, time 733.0, rides 135\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 4341, reward 908.0, memory_length 2000, epsilon 0.02004932952739705, time 726.0, rides 130\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4342, reward 1114.0, memory_length 2000, epsilon 0.020031285130822394, time 731.0, rides 120\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 4343, reward 881.0, memory_length 2000, epsilon 0.020013256974204655, time 730.0, rides 131\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 4344, reward 739.0, memory_length 2000, epsilon 0.01999524504292787, time 730.0, rides 119\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 4345, reward 1011.0, memory_length 2000, epsilon 0.019977249322389236, time 731.0, rides 128\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 4346, reward 977.0, memory_length 2000, epsilon 0.019959269797999085, time 729.0, rides 129\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 4347, reward 809.0, memory_length 2000, epsilon 0.019941306455180885, time 731.0, rides 139\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 4348, reward 614.0, memory_length 2000, epsilon 0.019923359279371222, time 732.0, rides 135\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 4349, reward 707.0, memory_length 2000, epsilon 0.019905428256019788, time 731.0, rides 122\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 4350, reward 932.0, memory_length 2000, epsilon 0.01988751337058937, time 734.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 4351, reward 923.0, memory_length 2000, epsilon 0.01986961460855584, time 734.0, rides 117\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 4352, reward 924.0, memory_length 2000, epsilon 0.01985173195540814, time 733.0, rides 133\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 4353, reward 1090.0, memory_length 2000, epsilon 0.019833865396648272, time 725.0, rides 136\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 4354, reward 857.0, memory_length 2000, epsilon 0.019816014917791287, time 726.0, rides 143\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 4355, reward 853.0, memory_length 2000, epsilon 0.019798180504365274, time 726.0, rides 126\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 4356, reward 733.0, memory_length 2000, epsilon 0.019780362141911347, time 730.0, rides 129\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4357, reward 768.0, memory_length 2000, epsilon 0.019762559815983627, time 728.0, rides 131\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 4358, reward 885.0, memory_length 2000, epsilon 0.01974477351214924, time 728.0, rides 129\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4359, reward 960.0, memory_length 2000, epsilon 0.019727003215988307, time 726.0, rides 126\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 4360, reward 870.0, memory_length 2000, epsilon 0.01970924891309392, time 722.0, rides 128\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 4361, reward 1207.0, memory_length 2000, epsilon 0.019691510589072134, time 731.0, rides 124\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 4362, reward 856.0, memory_length 2000, epsilon 0.01967378822954197, time 732.0, rides 128\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 4363, reward 823.0, memory_length 2000, epsilon 0.019656081820135382, time 730.0, rides 128\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 4364, reward 613.0, memory_length 2000, epsilon 0.01963839134649726, time 726.0, rides 130\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4365, reward 1062.0, memory_length 2000, epsilon 0.01962071679428541, time 736.0, rides 130\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4366, reward 1051.0, memory_length 2000, epsilon 0.019603058149170554, time 728.0, rides 143\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 4367, reward 948.0, memory_length 2000, epsilon 0.019585415396836302, time 726.0, rides 143\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 4368, reward 705.0, memory_length 2000, epsilon 0.01956778852297915, time 726.0, rides 121\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 4369, reward 840.0, memory_length 2000, epsilon 0.019550177513308467, time 723.0, rides 126\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 4370, reward 483.0, memory_length 2000, epsilon 0.01953258235354649, time 723.0, rides 133\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 4371, reward 763.0, memory_length 2000, epsilon 0.0195150030294283, time 728.0, rides 129\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 4372, reward 876.0, memory_length 2000, epsilon 0.019497439526701812, time 722.0, rides 126\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4373, reward 1119.0, memory_length 2000, epsilon 0.01947989183112778, time 729.0, rides 128\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 4374, reward 1050.0, memory_length 2000, epsilon 0.019462359928479764, time 733.0, rides 136\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 4375, reward 804.0, memory_length 2000, epsilon 0.019444843804544133, time 725.0, rides 133\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 4376, reward 955.0, memory_length 2000, epsilon 0.01942734344512004, time 727.0, rides 125\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4377, reward 564.0, memory_length 2000, epsilon 0.019409858836019433, time 727.0, rides 135\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 4378, reward 967.0, memory_length 2000, epsilon 0.019392389963067014, time 729.0, rides 131\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 4379, reward 1225.0, memory_length 2000, epsilon 0.019374936812100254, time 723.0, rides 132\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 4380, reward 856.0, memory_length 2000, epsilon 0.019357499368969362, time 734.0, rides 123\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 4381, reward 1088.0, memory_length 2000, epsilon 0.01934007761953729, time 731.0, rides 126\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 4382, reward 1090.0, memory_length 2000, epsilon 0.019322671549679708, time 721.0, rides 123\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 4383, reward 1017.0, memory_length 2000, epsilon 0.019305281145284996, time 733.0, rides 128\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 4384, reward 1020.0, memory_length 2000, epsilon 0.01928790639225424, time 734.0, rides 124\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 4385, reward 877.0, memory_length 2000, epsilon 0.01927054727650121, time 734.0, rides 136\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 4386, reward 843.0, memory_length 2000, epsilon 0.019253203783952358, time 731.0, rides 140\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 4387, reward 812.0, memory_length 2000, epsilon 0.0192358759005468, time 727.0, rides 116\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 4388, reward 552.0, memory_length 2000, epsilon 0.019218563612236308, time 723.0, rides 123\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 4389, reward 945.0, memory_length 2000, epsilon 0.019201266904985297, time 730.0, rides 134\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 4390, reward 850.0, memory_length 2000, epsilon 0.01918398576477081, time 723.0, rides 127\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 4391, reward 829.0, memory_length 2000, epsilon 0.019166720177582516, time 733.0, rides 144\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 4392, reward 1123.0, memory_length 2000, epsilon 0.019149470129422693, time 721.0, rides 127\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4393, reward 619.0, memory_length 2000, epsilon 0.01913223560630621, time 726.0, rides 132\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 4394, reward 882.0, memory_length 2000, epsilon 0.019115016594260535, time 728.0, rides 130\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 4395, reward 815.0, memory_length 2000, epsilon 0.0190978130793257, time 734.0, rides 132\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4396, reward 918.0, memory_length 2000, epsilon 0.019080625047554308, time 729.0, rides 132\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 4397, reward 745.0, memory_length 2000, epsilon 0.019063452485011508, time 736.0, rides 130\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 4398, reward 904.0, memory_length 2000, epsilon 0.019046295377774997, time 725.0, rides 124\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 4399, reward 699.0, memory_length 2000, epsilon 0.019029153711935, time 732.0, rides 131\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 4400, reward 683.0, memory_length 2000, epsilon 0.01901202747359426, time 722.0, rides 133\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 4401, reward 812.0, memory_length 2000, epsilon 0.018994916648868022, time 733.0, rides 129\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 4402, reward 964.0, memory_length 2000, epsilon 0.018977821223884042, time 729.0, rides 119\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 4403, reward 757.0, memory_length 2000, epsilon 0.018960741184782547, time 727.0, rides 130\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 4404, reward 887.0, memory_length 2000, epsilon 0.01894367651771624, time 723.0, rides 130\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 4405, reward 718.0, memory_length 2000, epsilon 0.018926627208850296, time 735.0, rides 125\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 4406, reward 895.0, memory_length 2000, epsilon 0.01890959324436233, time 730.0, rides 135\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 4407, reward 984.0, memory_length 2000, epsilon 0.018892574610442404, time 731.0, rides 141\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4408, reward 912.0, memory_length 2000, epsilon 0.018875571293293005, time 725.0, rides 119\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 4409, reward 1058.0, memory_length 2000, epsilon 0.01885858327912904, time 729.0, rides 134\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4410, reward 977.0, memory_length 2000, epsilon 0.018841610554177823, time 725.0, rides 130\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 4411, reward 1030.0, memory_length 2000, epsilon 0.018824653104679064, time 730.0, rides 118\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4412, reward 846.0, memory_length 2000, epsilon 0.018807710916884855, time 730.0, rides 137\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 4413, reward 1031.0, memory_length 2000, epsilon 0.018790783977059657, time 729.0, rides 136\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 4414, reward 1211.0, memory_length 2000, epsilon 0.018773872271480304, time 734.0, rides 146\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 4415, reward 817.0, memory_length 2000, epsilon 0.01875697578643597, time 724.0, rides 140\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 4416, reward 828.0, memory_length 2000, epsilon 0.018740094508228177, time 729.0, rides 124\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 4417, reward 985.0, memory_length 2000, epsilon 0.01872322842317077, time 736.0, rides 124\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 4418, reward 1136.0, memory_length 2000, epsilon 0.018706377517589915, time 729.0, rides 136\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4419, reward 828.0, memory_length 2000, epsilon 0.018689541777824083, time 731.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 4420, reward 973.0, memory_length 2000, epsilon 0.01867272119022404, time 723.0, rides 146\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 4421, reward 822.0, memory_length 2000, epsilon 0.01865591574115284, time 726.0, rides 122\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 4422, reward 1039.0, memory_length 2000, epsilon 0.018639125416985803, time 732.0, rides 131\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 4423, reward 837.0, memory_length 2000, epsilon 0.018622350204110516, time 735.0, rides 140\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 4424, reward 896.0, memory_length 2000, epsilon 0.018605590088926816, time 729.0, rides 129\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 4425, reward 980.0, memory_length 2000, epsilon 0.018588845057846783, time 727.0, rides 129\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 4426, reward 934.0, memory_length 2000, epsilon 0.01857211509729472, time 722.0, rides 148\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 4427, reward 933.0, memory_length 2000, epsilon 0.018555400193707154, time 724.0, rides 132\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 4428, reward 765.0, memory_length 2000, epsilon 0.018538700333532818, time 727.0, rides 135\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 4429, reward 1081.0, memory_length 2000, epsilon 0.01852201550323264, time 733.0, rides 136\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 4430, reward 892.0, memory_length 2000, epsilon 0.01850534568927973, time 728.0, rides 130\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 4431, reward 722.0, memory_length 2000, epsilon 0.018488690878159377, time 733.0, rides 126\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 4432, reward 686.0, memory_length 2000, epsilon 0.018472051056369034, time 725.0, rides 134\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 4433, reward 1079.0, memory_length 2000, epsilon 0.0184554262104183, time 738.0, rides 127\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 4434, reward 1014.0, memory_length 2000, epsilon 0.018438816326828925, time 730.0, rides 139\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 4435, reward 778.0, memory_length 2000, epsilon 0.01842222139213478, time 726.0, rides 125\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 4436, reward 986.0, memory_length 2000, epsilon 0.018405641392881856, time 733.0, rides 122\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 4437, reward 1148.0, memory_length 2000, epsilon 0.01838907631562826, time 732.0, rides 152\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 4438, reward 897.0, memory_length 2000, epsilon 0.018372526146944193, time 727.0, rides 145\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4439, reward 787.0, memory_length 2000, epsilon 0.018355990873411943, time 727.0, rides 140\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 4440, reward 951.0, memory_length 2000, epsilon 0.01833947048162587, time 725.0, rides 124\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4441, reward 940.0, memory_length 2000, epsilon 0.018322964958192408, time 731.0, rides 138\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 4442, reward 997.0, memory_length 2000, epsilon 0.018306474289730035, time 738.0, rides 129\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 4443, reward 659.0, memory_length 2000, epsilon 0.018289998462869276, time 725.0, rides 132\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 4444, reward 1105.0, memory_length 2000, epsilon 0.018273537464252695, time 731.0, rides 143\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 4445, reward 1191.0, memory_length 2000, epsilon 0.018257091280534866, time 734.0, rides 126\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 4446, reward 741.0, memory_length 2000, epsilon 0.018240659898382385, time 724.0, rides 139\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4447, reward 794.0, memory_length 2000, epsilon 0.01822424330447384, time 722.0, rides 141\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 4448, reward 987.0, memory_length 2000, epsilon 0.018207841485499813, time 730.0, rides 135\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 4449, reward 934.0, memory_length 2000, epsilon 0.018191454428162862, time 727.0, rides 138\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 4450, reward 1105.0, memory_length 2000, epsilon 0.018175082119177514, time 725.0, rides 141\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 4451, reward 995.0, memory_length 2000, epsilon 0.018158724545270254, time 724.0, rides 124\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 4452, reward 1018.0, memory_length 2000, epsilon 0.01814238169317951, time 734.0, rides 142\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 4453, reward 1085.0, memory_length 2000, epsilon 0.018126053549655647, time 725.0, rides 131\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 4454, reward 877.0, memory_length 2000, epsilon 0.018109740101460957, time 722.0, rides 129\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 4455, reward 867.0, memory_length 2000, epsilon 0.01809344133536964, time 727.0, rides 135\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 4456, reward 758.0, memory_length 2000, epsilon 0.01807715723816781, time 727.0, rides 141\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 4457, reward 792.0, memory_length 2000, epsilon 0.018060887796653456, time 729.0, rides 132\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 4458, reward 800.0, memory_length 2000, epsilon 0.018044632997636468, time 730.0, rides 128\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 4459, reward 1156.0, memory_length 2000, epsilon 0.018028392827938593, time 722.0, rides 123\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 4460, reward 1033.0, memory_length 2000, epsilon 0.018012167274393448, time 729.0, rides 130\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4461, reward 731.0, memory_length 2000, epsilon 0.017995956323846495, time 728.0, rides 142\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 4462, reward 1052.0, memory_length 2000, epsilon 0.017979759963155033, time 728.0, rides 131\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 4463, reward 1250.0, memory_length 2000, epsilon 0.017963578179188193, time 727.0, rides 149\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 4464, reward 1263.0, memory_length 2000, epsilon 0.017947410958826925, time 729.0, rides 137\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 4465, reward 705.0, memory_length 2000, epsilon 0.01793125828896398, time 729.0, rides 136\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 4466, reward 927.0, memory_length 2000, epsilon 0.017915120156503914, time 724.0, rides 131\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 4467, reward 924.0, memory_length 2000, epsilon 0.01789899654836306, time 737.0, rides 130\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 4468, reward 910.0, memory_length 2000, epsilon 0.017882887451469532, time 743.0, rides 143\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 4469, reward 905.0, memory_length 2000, epsilon 0.01786679285276321, time 729.0, rides 136\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 4470, reward 932.0, memory_length 2000, epsilon 0.017850712739195723, time 728.0, rides 147\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4471, reward 803.0, memory_length 2000, epsilon 0.017834647097730447, time 736.0, rides 127\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 4472, reward 951.0, memory_length 2000, epsilon 0.01781859591534249, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 4473, reward 706.0, memory_length 2000, epsilon 0.01780255917901868, time 725.0, rides 127\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 4474, reward 923.0, memory_length 2000, epsilon 0.017786536875757562, time 733.0, rides 134\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 4475, reward 519.0, memory_length 2000, epsilon 0.01777052899256938, time 723.0, rides 121\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 4476, reward 979.0, memory_length 2000, epsilon 0.01775453551647607, time 724.0, rides 126\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 4477, reward 877.0, memory_length 2000, epsilon 0.01773855643451124, time 736.0, rides 131\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 4478, reward 972.0, memory_length 2000, epsilon 0.017722591733720178, time 731.0, rides 135\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 4479, reward 1109.0, memory_length 2000, epsilon 0.01770664140115983, time 724.0, rides 123\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 4480, reward 811.0, memory_length 2000, epsilon 0.017690705423898785, time 728.0, rides 131\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 4481, reward 799.0, memory_length 2000, epsilon 0.017674783789017275, time 725.0, rides 129\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 4482, reward 589.0, memory_length 2000, epsilon 0.017658876483607158, time 733.0, rides 134\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 4483, reward 1128.0, memory_length 2000, epsilon 0.017642983494771912, time 730.0, rides 130\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 4484, reward 1028.0, memory_length 2000, epsilon 0.017627104809626617, time 723.0, rides 135\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 4485, reward 758.0, memory_length 2000, epsilon 0.017611240415297953, time 733.0, rides 135\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 4486, reward 840.0, memory_length 2000, epsilon 0.017595390298924183, time 733.0, rides 145\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 4487, reward 728.0, memory_length 2000, epsilon 0.01757955444765515, time 729.0, rides 123\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 4488, reward 817.0, memory_length 2000, epsilon 0.01756373284865226, time 732.0, rides 132\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 4489, reward 986.0, memory_length 2000, epsilon 0.017547925489088474, time 731.0, rides 136\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 4490, reward 863.0, memory_length 2000, epsilon 0.017532132356148294, time 731.0, rides 134\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 4491, reward 1038.0, memory_length 2000, epsilon 0.01751635343702776, time 728.0, rides 134\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 4492, reward 869.0, memory_length 2000, epsilon 0.017500588718934434, time 725.0, rides 130\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 4493, reward 935.0, memory_length 2000, epsilon 0.017484838189087394, time 724.0, rides 123\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 4494, reward 775.0, memory_length 2000, epsilon 0.017469101834717216, time 720.0, rides 136\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 4495, reward 882.0, memory_length 2000, epsilon 0.01745337964306597, time 729.0, rides 130\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 4496, reward 872.0, memory_length 2000, epsilon 0.01743767160138721, time 733.0, rides 142\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 4497, reward 945.0, memory_length 2000, epsilon 0.01742197769694596, time 725.0, rides 135\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 4498, reward 798.0, memory_length 2000, epsilon 0.01740629791701871, time 724.0, rides 120\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 4499, reward 754.0, memory_length 2000, epsilon 0.01739063224889339, time 723.0, rides 129\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 4500, reward 1129.0, memory_length 2000, epsilon 0.017374980679869388, time 734.0, rides 139\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4501, reward 1049.0, memory_length 2000, epsilon 0.017359343197257505, time 732.0, rides 130\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 4502, reward 1032.0, memory_length 2000, epsilon 0.017343719788379973, time 723.0, rides 162\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 4503, reward 755.0, memory_length 2000, epsilon 0.01732811044057043, time 730.0, rides 129\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4504, reward 688.0, memory_length 2000, epsilon 0.017312515141173917, time 726.0, rides 139\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 4505, reward 941.0, memory_length 2000, epsilon 0.01729693387754686, time 726.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4506, reward 1100.0, memory_length 2000, epsilon 0.017281366637057066, time 736.0, rides 146\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 4507, reward 784.0, memory_length 2000, epsilon 0.017265813407083715, time 730.0, rides 127\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 4508, reward 584.0, memory_length 2000, epsilon 0.01725027417501734, time 725.0, rides 125\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 4509, reward 837.0, memory_length 2000, epsilon 0.017234748928259824, time 722.0, rides 132\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 4510, reward 772.0, memory_length 2000, epsilon 0.017219237654224392, time 725.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 4511, reward 1093.0, memory_length 2000, epsilon 0.017203740340335588, time 721.0, rides 134\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4512, reward 893.0, memory_length 2000, epsilon 0.017188256974029287, time 735.0, rides 123\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 4513, reward 962.0, memory_length 2000, epsilon 0.01717278754275266, time 728.0, rides 132\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4514, reward 628.0, memory_length 2000, epsilon 0.017157332033964183, time 723.0, rides 133\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4515, reward 1080.0, memory_length 2000, epsilon 0.017141890435133617, time 732.0, rides 145\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 4516, reward 795.0, memory_length 2000, epsilon 0.017126462733741996, time 730.0, rides 131\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 4517, reward 1043.0, memory_length 2000, epsilon 0.01711104891728163, time 737.0, rides 136\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 4518, reward 840.0, memory_length 2000, epsilon 0.017095648973256074, time 726.0, rides 136\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 4519, reward 934.0, memory_length 2000, epsilon 0.017080262889180145, time 729.0, rides 140\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 4520, reward 773.0, memory_length 2000, epsilon 0.01706489065257988, time 728.0, rides 127\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 4521, reward 797.0, memory_length 2000, epsilon 0.01704953225099256, time 734.0, rides 136\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 4522, reward 849.0, memory_length 2000, epsilon 0.017034187671966666, time 726.0, rides 144\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 4523, reward 908.0, memory_length 2000, epsilon 0.017018856903061895, time 734.0, rides 146\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 4524, reward 1125.0, memory_length 2000, epsilon 0.017003539931849138, time 728.0, rides 131\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 4525, reward 848.0, memory_length 2000, epsilon 0.016988236745910473, time 730.0, rides 146\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 4526, reward 807.0, memory_length 2000, epsilon 0.016972947332839154, time 726.0, rides 115\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 4527, reward 1202.0, memory_length 2000, epsilon 0.016957671680239598, time 730.0, rides 144\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 4528, reward 965.0, memory_length 2000, epsilon 0.016942409775727384, time 731.0, rides 146\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 4529, reward 997.0, memory_length 2000, epsilon 0.01692716160692923, time 724.0, rides 138\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 4530, reward 1004.0, memory_length 2000, epsilon 0.016911927161482994, time 729.0, rides 136\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 4531, reward 869.0, memory_length 2000, epsilon 0.01689670642703766, time 727.0, rides 128\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 4532, reward 1131.0, memory_length 2000, epsilon 0.016881499391253326, time 731.0, rides 126\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 4533, reward 1048.0, memory_length 2000, epsilon 0.0168663060418012, time 730.0, rides 127\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 4534, reward 680.0, memory_length 2000, epsilon 0.01685112636636358, time 722.0, rides 130\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4535, reward 867.0, memory_length 2000, epsilon 0.016835960352633853, time 726.0, rides 125\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 4536, reward 1191.0, memory_length 2000, epsilon 0.01682080798831648, time 734.0, rides 131\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 4537, reward 684.0, memory_length 2000, epsilon 0.016805669261126997, time 724.0, rides 122\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 4538, reward 1008.0, memory_length 2000, epsilon 0.016790544158791984, time 727.0, rides 132\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4539, reward 991.0, memory_length 2000, epsilon 0.01677543266904907, time 727.0, rides 133\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4540, reward 960.0, memory_length 2000, epsilon 0.016760334779646925, time 730.0, rides 144\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 4541, reward 816.0, memory_length 2000, epsilon 0.01674525047834524, time 730.0, rides 131\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 4542, reward 751.0, memory_length 2000, epsilon 0.016730179752914732, time 726.0, rides 125\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 4543, reward 1035.0, memory_length 2000, epsilon 0.016715122591137107, time 724.0, rides 138\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4544, reward 1087.0, memory_length 2000, epsilon 0.016700078980805083, time 731.0, rides 125\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 4545, reward 1256.0, memory_length 2000, epsilon 0.016685048909722357, time 730.0, rides 134\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 4546, reward 516.0, memory_length 2000, epsilon 0.016670032365703608, time 734.0, rides 136\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 4547, reward 1113.0, memory_length 2000, epsilon 0.016655029336574475, time 724.0, rides 130\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 4548, reward 904.0, memory_length 2000, epsilon 0.016640039810171557, time 725.0, rides 141\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 4549, reward 926.0, memory_length 2000, epsilon 0.0166250637743424, time 724.0, rides 131\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 4550, reward 815.0, memory_length 2000, epsilon 0.016610101216945495, time 728.0, rides 130\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4551, reward 940.0, memory_length 2000, epsilon 0.016595152125850245, time 727.0, rides 140\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4552, reward 1032.0, memory_length 2000, epsilon 0.01658021648893698, time 726.0, rides 139\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 4553, reward 927.0, memory_length 2000, epsilon 0.016565294294096936, time 724.0, rides 138\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 4554, reward 949.0, memory_length 2000, epsilon 0.01655038552923225, time 730.0, rides 130\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 4555, reward 1022.0, memory_length 2000, epsilon 0.01653549018225594, time 732.0, rides 134\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 4556, reward 826.0, memory_length 2000, epsilon 0.01652060824109191, time 732.0, rides 132\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4557, reward 1078.0, memory_length 2000, epsilon 0.016505739693674925, time 727.0, rides 127\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 4558, reward 878.0, memory_length 2000, epsilon 0.016490884527950618, time 730.0, rides 130\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4559, reward 763.0, memory_length 2000, epsilon 0.016476042731875463, time 734.0, rides 140\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 4560, reward 1197.0, memory_length 2000, epsilon 0.016461214293416775, time 731.0, rides 134\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 4561, reward 816.0, memory_length 2000, epsilon 0.0164463992005527, time 730.0, rides 127\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 4562, reward 997.0, memory_length 2000, epsilon 0.016431597441272202, time 731.0, rides 140\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 4563, reward 839.0, memory_length 2000, epsilon 0.016416809003575058, time 728.0, rides 135\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 4564, reward 922.0, memory_length 2000, epsilon 0.01640203387547184, time 731.0, rides 131\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 4565, reward 1115.0, memory_length 2000, epsilon 0.016387272044983917, time 731.0, rides 143\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 4566, reward 1251.0, memory_length 2000, epsilon 0.01637252350014343, time 728.0, rides 132\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 4567, reward 868.0, memory_length 2000, epsilon 0.0163577882289933, time 726.0, rides 119\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 4568, reward 591.0, memory_length 2000, epsilon 0.016343066219587206, time 723.0, rides 134\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 4569, reward 1035.0, memory_length 2000, epsilon 0.016328357459989576, time 735.0, rides 147\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 4570, reward 1101.0, memory_length 2000, epsilon 0.016313661938275586, time 732.0, rides 133\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 4571, reward 1007.0, memory_length 2000, epsilon 0.016298979642531138, time 730.0, rides 133\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 4572, reward 989.0, memory_length 2000, epsilon 0.01628431056085286, time 724.0, rides 130\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4573, reward 917.0, memory_length 2000, epsilon 0.016269654681348094, time 727.0, rides 122\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 4574, reward 870.0, memory_length 2000, epsilon 0.01625501199213488, time 731.0, rides 138\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 4575, reward 999.0, memory_length 2000, epsilon 0.01624038248134196, time 726.0, rides 139\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 4576, reward 818.0, memory_length 2000, epsilon 0.016225766137108754, time 728.0, rides 130\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 4577, reward 1046.0, memory_length 2000, epsilon 0.016211162947585355, time 729.0, rides 130\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 4578, reward 1037.0, memory_length 2000, epsilon 0.01619657290093253, time 732.0, rides 136\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 4579, reward 1108.0, memory_length 2000, epsilon 0.01618199598532169, time 727.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 4580, reward 889.0, memory_length 2000, epsilon 0.0161674321889349, time 723.0, rides 142\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 4581, reward 859.0, memory_length 2000, epsilon 0.01615288149996486, time 731.0, rides 137\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 4582, reward 934.0, memory_length 2000, epsilon 0.01613834390661489, time 727.0, rides 138\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 4583, reward 1009.0, memory_length 2000, epsilon 0.016123819397098938, time 728.0, rides 130\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 4584, reward 1049.0, memory_length 2000, epsilon 0.01610930795964155, time 734.0, rides 119\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 4585, reward 898.0, memory_length 2000, epsilon 0.016094809582477873, time 729.0, rides 136\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 4586, reward 728.0, memory_length 2000, epsilon 0.016080324253853643, time 728.0, rides 134\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 4587, reward 834.0, memory_length 2000, epsilon 0.016065851962025174, time 735.0, rides 125\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 4588, reward 1141.0, memory_length 2000, epsilon 0.01605139269525935, time 723.0, rides 140\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 4589, reward 778.0, memory_length 2000, epsilon 0.016036946441833618, time 727.0, rides 160\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 4590, reward 1231.0, memory_length 2000, epsilon 0.016022513190035968, time 731.0, rides 138\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4591, reward 839.0, memory_length 2000, epsilon 0.016008092928164935, time 731.0, rides 138\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 4592, reward 1206.0, memory_length 2000, epsilon 0.015993685644529586, time 731.0, rides 145\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 4593, reward 652.0, memory_length 2000, epsilon 0.015979291327449508, time 728.0, rides 122\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 4594, reward 1012.0, memory_length 2000, epsilon 0.015964909965254803, time 721.0, rides 140\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 4595, reward 811.0, memory_length 2000, epsilon 0.015950541546286074, time 733.0, rides 136\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 4596, reward 1247.0, memory_length 2000, epsilon 0.015936186058894415, time 732.0, rides 147\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 4597, reward 905.0, memory_length 2000, epsilon 0.01592184349144141, time 729.0, rides 148\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 4598, reward 1020.0, memory_length 2000, epsilon 0.015907513832299113, time 734.0, rides 130\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 4599, reward 1070.0, memory_length 2000, epsilon 0.015893197069850044, time 735.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 4600, reward 1055.0, memory_length 2000, epsilon 0.015878893192487177, time 726.0, rides 128\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 4601, reward 1256.0, memory_length 2000, epsilon 0.01586460218861394, time 727.0, rides 125\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 4602, reward 961.0, memory_length 2000, epsilon 0.015850324046644187, time 725.0, rides 152\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 4603, reward 1218.0, memory_length 2000, epsilon 0.015836058755002207, time 724.0, rides 139\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 4604, reward 999.0, memory_length 2000, epsilon 0.015821806302122706, time 730.0, rides 123\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 4605, reward 741.0, memory_length 2000, epsilon 0.015807566676450797, time 731.0, rides 128\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4606, reward 644.0, memory_length 2000, epsilon 0.01579333986644199, time 735.0, rides 137\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 4607, reward 592.0, memory_length 2000, epsilon 0.015779125860562192, time 732.0, rides 144\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 4608, reward 881.0, memory_length 2000, epsilon 0.015764924647287685, time 730.0, rides 126\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 4609, reward 697.0, memory_length 2000, epsilon 0.015750736215105126, time 728.0, rides 143\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 4610, reward 860.0, memory_length 2000, epsilon 0.01573656055251153, time 722.0, rides 139\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 4611, reward 1031.0, memory_length 2000, epsilon 0.01572239764801427, time 726.0, rides 128\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 4612, reward 714.0, memory_length 2000, epsilon 0.015708247490131055, time 731.0, rides 134\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 4613, reward 899.0, memory_length 2000, epsilon 0.015694110067389938, time 723.0, rides 134\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 4614, reward 1220.0, memory_length 2000, epsilon 0.015679985368329288, time 725.0, rides 138\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 4615, reward 890.0, memory_length 2000, epsilon 0.015665873381497792, time 727.0, rides 133\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 4616, reward 874.0, memory_length 2000, epsilon 0.015651774095454443, time 735.0, rides 136\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 4617, reward 754.0, memory_length 2000, epsilon 0.015637687498768534, time 731.0, rides 142\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 4618, reward 807.0, memory_length 2000, epsilon 0.015623613580019643, time 724.0, rides 133\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 4619, reward 1023.0, memory_length 2000, epsilon 0.015609552327797625, time 727.0, rides 123\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4620, reward 963.0, memory_length 2000, epsilon 0.015595503730702606, time 727.0, rides 132\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 4621, reward 926.0, memory_length 2000, epsilon 0.015581467777344973, time 728.0, rides 120\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 4622, reward 1011.0, memory_length 2000, epsilon 0.015567444456345362, time 729.0, rides 138\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 4623, reward 968.0, memory_length 2000, epsilon 0.015553433756334651, time 734.0, rides 128\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 4624, reward 806.0, memory_length 2000, epsilon 0.01553943566595395, time 732.0, rides 122\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 4625, reward 1001.0, memory_length 2000, epsilon 0.015525450173854592, time 730.0, rides 134\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 4626, reward 804.0, memory_length 2000, epsilon 0.015511477268698122, time 725.0, rides 135\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 4627, reward 988.0, memory_length 2000, epsilon 0.015497516939156294, time 722.0, rides 131\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4628, reward 1061.0, memory_length 2000, epsilon 0.015483569173911053, time 725.0, rides 128\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 4629, reward 849.0, memory_length 2000, epsilon 0.015469633961654534, time 730.0, rides 134\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 4630, reward 1039.0, memory_length 2000, epsilon 0.015455711291089044, time 730.0, rides 135\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4631, reward 882.0, memory_length 2000, epsilon 0.015441801150927064, time 734.0, rides 141\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 4632, reward 871.0, memory_length 2000, epsilon 0.01542790352989123, time 720.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 4633, reward 751.0, memory_length 2000, epsilon 0.015414018416714328, time 731.0, rides 132\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 4634, reward 699.0, memory_length 2000, epsilon 0.015400145800139285, time 727.0, rides 137\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4635, reward 766.0, memory_length 2000, epsilon 0.01538628566891916, time 736.0, rides 139\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 4636, reward 823.0, memory_length 2000, epsilon 0.015372438011817131, time 735.0, rides 131\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 4637, reward 857.0, memory_length 2000, epsilon 0.015358602817606495, time 730.0, rides 150\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 4638, reward 837.0, memory_length 2000, epsilon 0.01534478007507065, time 724.0, rides 130\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 4639, reward 1088.0, memory_length 2000, epsilon 0.015330969773003087, time 720.0, rides 131\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 4640, reward 930.0, memory_length 2000, epsilon 0.015317171900207384, time 733.0, rides 137\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 4641, reward 1297.0, memory_length 2000, epsilon 0.015303386445497197, time 726.0, rides 132\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4642, reward 821.0, memory_length 2000, epsilon 0.01528961339769625, time 723.0, rides 137\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 4643, reward 965.0, memory_length 2000, epsilon 0.015275852745638323, time 731.0, rides 125\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 4644, reward 968.0, memory_length 2000, epsilon 0.01526210447816725, time 732.0, rides 144\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 4645, reward 1226.0, memory_length 2000, epsilon 0.015248368584136899, time 724.0, rides 140\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4646, reward 931.0, memory_length 2000, epsilon 0.015234645052411176, time 726.0, rides 133\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 4647, reward 801.0, memory_length 2000, epsilon 0.015220933871864005, time 735.0, rides 135\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 4648, reward 1128.0, memory_length 2000, epsilon 0.015207235031379327, time 726.0, rides 141\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 4649, reward 920.0, memory_length 2000, epsilon 0.015193548519851085, time 727.0, rides 138\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 4650, reward 1038.0, memory_length 2000, epsilon 0.015179874326183219, time 729.0, rides 145\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 4651, reward 883.0, memory_length 2000, epsilon 0.015166212439289653, time 733.0, rides 130\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 4652, reward 666.0, memory_length 2000, epsilon 0.015152562848094292, time 727.0, rides 133\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 4653, reward 831.0, memory_length 2000, epsilon 0.015138925541531007, time 733.0, rides 151\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 4654, reward 930.0, memory_length 2000, epsilon 0.015125300508543629, time 731.0, rides 147\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 4655, reward 901.0, memory_length 2000, epsilon 0.01511168773808594, time 724.0, rides 137\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 4656, reward 1133.0, memory_length 2000, epsilon 0.015098087219121663, time 728.0, rides 139\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4657, reward 997.0, memory_length 2000, epsilon 0.015084498940624453, time 729.0, rides 125\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 4658, reward 1119.0, memory_length 2000, epsilon 0.015070922891577892, time 724.0, rides 132\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 4659, reward 854.0, memory_length 2000, epsilon 0.015057359060975472, time 727.0, rides 146\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 4660, reward 676.0, memory_length 2000, epsilon 0.015043807437820593, time 730.0, rides 136\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 4661, reward 749.0, memory_length 2000, epsilon 0.015030268011126554, time 727.0, rides 148\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4662, reward 749.0, memory_length 2000, epsilon 0.01501674076991654, time 741.0, rides 140\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 4663, reward 785.0, memory_length 2000, epsilon 0.015003225703223613, time 723.0, rides 138\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 4664, reward 1181.0, memory_length 2000, epsilon 0.014989722800090711, time 725.0, rides 146\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 4665, reward 1049.0, memory_length 2000, epsilon 0.01497623204957063, time 728.0, rides 126\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4666, reward 793.0, memory_length 2000, epsilon 0.014962753440726015, time 731.0, rides 144\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 4667, reward 851.0, memory_length 2000, epsilon 0.01494928696262936, time 727.0, rides 138\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 4668, reward 1124.0, memory_length 2000, epsilon 0.014935832604362995, time 721.0, rides 123\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 4669, reward 1100.0, memory_length 2000, epsilon 0.014922390355019069, time 728.0, rides 133\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 4670, reward 975.0, memory_length 2000, epsilon 0.014908960203699551, time 734.0, rides 129\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 4671, reward 1136.0, memory_length 2000, epsilon 0.014895542139516221, time 726.0, rides 133\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 4672, reward 1097.0, memory_length 2000, epsilon 0.014882136151590656, time 726.0, rides 133\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 4673, reward 814.0, memory_length 2000, epsilon 0.014868742229054224, time 729.0, rides 145\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 4674, reward 954.0, memory_length 2000, epsilon 0.014855360361048075, time 720.0, rides 131\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 4675, reward 682.0, memory_length 2000, epsilon 0.01484199053672313, time 726.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 4676, reward 668.0, memory_length 2000, epsilon 0.01482863274524008, time 728.0, rides 128\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 4677, reward 939.0, memory_length 2000, epsilon 0.014815286975769363, time 728.0, rides 138\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 4678, reward 734.0, memory_length 2000, epsilon 0.01480195321749117, time 727.0, rides 150\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 4679, reward 1040.0, memory_length 2000, epsilon 0.014788631459595428, time 729.0, rides 141\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 4680, reward 1029.0, memory_length 2000, epsilon 0.014775321691281791, time 726.0, rides 142\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 4681, reward 771.0, memory_length 2000, epsilon 0.014762023901759638, time 727.0, rides 134\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 4682, reward 666.0, memory_length 2000, epsilon 0.014748738080248054, time 730.0, rides 131\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4683, reward 817.0, memory_length 2000, epsilon 0.014735464215975831, time 726.0, rides 126\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 4684, reward 821.0, memory_length 2000, epsilon 0.014722202298181452, time 722.0, rides 140\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 4685, reward 911.0, memory_length 2000, epsilon 0.014708952316113088, time 733.0, rides 142\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 4686, reward 691.0, memory_length 2000, epsilon 0.014695714259028585, time 735.0, rides 116\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 4687, reward 796.0, memory_length 2000, epsilon 0.01468248811619546, time 733.0, rides 140\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 4688, reward 857.0, memory_length 2000, epsilon 0.014669273876890885, time 727.0, rides 128\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 4689, reward 777.0, memory_length 2000, epsilon 0.014656071530401682, time 728.0, rides 125\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 4690, reward 1108.0, memory_length 2000, epsilon 0.014642881066024321, time 732.0, rides 149\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 4691, reward 663.0, memory_length 2000, epsilon 0.0146297024730649, time 724.0, rides 154\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 4692, reward 813.0, memory_length 2000, epsilon 0.01461653574083914, time 724.0, rides 133\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 4693, reward 968.0, memory_length 2000, epsilon 0.014603380858672384, time 729.0, rides 125\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 4694, reward 1265.0, memory_length 2000, epsilon 0.01459023781589958, time 728.0, rides 126\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 4695, reward 696.0, memory_length 2000, epsilon 0.01457710660186527, time 729.0, rides 139\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 4696, reward 882.0, memory_length 2000, epsilon 0.014563987205923591, time 737.0, rides 134\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4697, reward 644.0, memory_length 2000, epsilon 0.01455087961743826, time 727.0, rides 129\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 4698, reward 1110.0, memory_length 2000, epsilon 0.014537783825782564, time 734.0, rides 129\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 4699, reward 1001.0, memory_length 2000, epsilon 0.01452469982033936, time 723.0, rides 139\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 4700, reward 882.0, memory_length 2000, epsilon 0.014511627590501053, time 729.0, rides 129\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 4701, reward 645.0, memory_length 2000, epsilon 0.014498567125669602, time 727.0, rides 124\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 4702, reward 1009.0, memory_length 2000, epsilon 0.014485518415256499, time 725.0, rides 139\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 4703, reward 900.0, memory_length 2000, epsilon 0.014472481448682767, time 731.0, rides 126\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 4704, reward 415.0, memory_length 2000, epsilon 0.014459456215378952, time 735.0, rides 133\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 4705, reward 1033.0, memory_length 2000, epsilon 0.01444644270478511, time 728.0, rides 130\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 4706, reward 880.0, memory_length 2000, epsilon 0.014433440906350804, time 724.0, rides 138\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 4707, reward 724.0, memory_length 2000, epsilon 0.014420450809535088, time 729.0, rides 144\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 4708, reward 909.0, memory_length 2000, epsilon 0.014407472403806507, time 730.0, rides 131\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 4709, reward 797.0, memory_length 2000, epsilon 0.014394505678643081, time 736.0, rides 125\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 4710, reward 877.0, memory_length 2000, epsilon 0.014381550623532302, time 736.0, rides 123\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 4711, reward 1038.0, memory_length 2000, epsilon 0.014368607227971123, time 733.0, rides 134\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 4712, reward 809.0, memory_length 2000, epsilon 0.014355675481465949, time 730.0, rides 123\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 4713, reward 874.0, memory_length 2000, epsilon 0.014342755373532629, time 727.0, rides 130\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 4714, reward 819.0, memory_length 2000, epsilon 0.014329846893696449, time 732.0, rides 131\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 4715, reward 882.0, memory_length 2000, epsilon 0.014316950031492122, time 729.0, rides 136\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 4716, reward 1028.0, memory_length 2000, epsilon 0.014304064776463779, time 727.0, rides 127\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 4717, reward 884.0, memory_length 2000, epsilon 0.01429119111816496, time 736.0, rides 129\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 4718, reward 1007.0, memory_length 2000, epsilon 0.014278329046158611, time 727.0, rides 135\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 4719, reward 927.0, memory_length 2000, epsilon 0.014265478550017068, time 732.0, rides 121\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 4720, reward 862.0, memory_length 2000, epsilon 0.014252639619322053, time 731.0, rides 138\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 4721, reward 870.0, memory_length 2000, epsilon 0.014239812243664662, time 721.0, rides 142\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 4722, reward 764.0, memory_length 2000, epsilon 0.014226996412645364, time 729.0, rides 124\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 4723, reward 431.0, memory_length 2000, epsilon 0.014214192115873983, time 728.0, rides 128\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 4724, reward 635.0, memory_length 2000, epsilon 0.014201399342969696, time 733.0, rides 134\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 4725, reward 736.0, memory_length 2000, epsilon 0.014188618083561023, time 735.0, rides 118\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 4726, reward 908.0, memory_length 2000, epsilon 0.014175848327285818, time 725.0, rides 118\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 4727, reward 659.0, memory_length 2000, epsilon 0.01416309006379126, time 728.0, rides 131\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 4728, reward 1210.0, memory_length 2000, epsilon 0.014150343282733848, time 729.0, rides 144\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 4729, reward 779.0, memory_length 2000, epsilon 0.014137607973779387, time 730.0, rides 126\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4730, reward 1053.0, memory_length 2000, epsilon 0.014124884126602986, time 730.0, rides 138\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4731, reward 996.0, memory_length 2000, epsilon 0.014112171730889043, time 730.0, rides 132\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 4732, reward 819.0, memory_length 2000, epsilon 0.014099470776331243, time 734.0, rides 131\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 4733, reward 1095.0, memory_length 2000, epsilon 0.014086781252632545, time 727.0, rides 124\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4734, reward 993.0, memory_length 2000, epsilon 0.014074103149505175, time 729.0, rides 133\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 4735, reward 858.0, memory_length 2000, epsilon 0.01406143645667062, time 730.0, rides 133\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 4736, reward 1195.0, memory_length 2000, epsilon 0.014048781163859617, time 731.0, rides 129\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 4737, reward 408.0, memory_length 2000, epsilon 0.014036137260812143, time 733.0, rides 130\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 4738, reward 783.0, memory_length 2000, epsilon 0.014023504737277412, time 730.0, rides 129\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 4739, reward 909.0, memory_length 2000, epsilon 0.014010883583013861, time 724.0, rides 137\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4740, reward 582.0, memory_length 2000, epsilon 0.013998273787789148, time 727.0, rides 130\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 4741, reward 978.0, memory_length 2000, epsilon 0.013985675341380139, time 733.0, rides 146\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 4742, reward 1054.0, memory_length 2000, epsilon 0.013973088233572897, time 727.0, rides 134\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 4743, reward 774.0, memory_length 2000, epsilon 0.013960512454162681, time 731.0, rides 131\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 4744, reward 881.0, memory_length 2000, epsilon 0.013947947992953935, time 728.0, rides 138\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 4745, reward 1099.0, memory_length 2000, epsilon 0.013935394839760275, time 724.0, rides 133\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 4746, reward 1272.0, memory_length 2000, epsilon 0.013922852984404491, time 729.0, rides 128\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4747, reward 946.0, memory_length 2000, epsilon 0.013910322416718527, time 728.0, rides 140\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 4748, reward 1152.0, memory_length 2000, epsilon 0.01389780312654348, time 728.0, rides 134\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 4749, reward 1406.0, memory_length 2000, epsilon 0.013885295103729592, time 737.0, rides 125\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 4750, reward 802.0, memory_length 2000, epsilon 0.013872798338136235, time 736.0, rides 129\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 4751, reward 1094.0, memory_length 2000, epsilon 0.013860312819631912, time 727.0, rides 135\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 4752, reward 923.0, memory_length 2000, epsilon 0.013847838538094244, time 734.0, rides 144\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 4753, reward 1044.0, memory_length 2000, epsilon 0.013835375483409958, time 730.0, rides 134\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 4754, reward 802.0, memory_length 2000, epsilon 0.01382292364547489, time 727.0, rides 141\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 4755, reward 1086.0, memory_length 2000, epsilon 0.013810483014193962, time 733.0, rides 140\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 4756, reward 1016.0, memory_length 2000, epsilon 0.013798053579481188, time 731.0, rides 146\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4757, reward 796.0, memory_length 2000, epsilon 0.013785635331259654, time 727.0, rides 128\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 4758, reward 1060.0, memory_length 2000, epsilon 0.01377322825946152, time 726.0, rides 123\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 4759, reward 825.0, memory_length 2000, epsilon 0.013760832354028005, time 726.0, rides 130\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 4760, reward 1028.0, memory_length 2000, epsilon 0.01374844760490938, time 730.0, rides 131\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 4761, reward 853.0, memory_length 2000, epsilon 0.013736074002064962, time 730.0, rides 140\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 4762, reward 1062.0, memory_length 2000, epsilon 0.013723711535463104, time 732.0, rides 144\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 4763, reward 953.0, memory_length 2000, epsilon 0.013711360195081186, time 729.0, rides 121\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 4764, reward 668.0, memory_length 2000, epsilon 0.013699019970905613, time 729.0, rides 123\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4765, reward 1037.0, memory_length 2000, epsilon 0.013686690852931798, time 726.0, rides 136\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 4766, reward 951.0, memory_length 2000, epsilon 0.013674372831164159, time 728.0, rides 131\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 4767, reward 996.0, memory_length 2000, epsilon 0.013662065895616112, time 729.0, rides 137\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 4768, reward 860.0, memory_length 2000, epsilon 0.013649770036310058, time 730.0, rides 147\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 4769, reward 854.0, memory_length 2000, epsilon 0.013637485243277379, time 728.0, rides 140\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 4770, reward 1029.0, memory_length 2000, epsilon 0.013625211506558429, time 725.0, rides 147\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 4771, reward 669.0, memory_length 2000, epsilon 0.013612948816202525, time 726.0, rides 124\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 4772, reward 316.0, memory_length 2000, epsilon 0.013600697162267942, time 726.0, rides 128\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 4773, reward 627.0, memory_length 2000, epsilon 0.0135884565348219, time 730.0, rides 140\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 4774, reward 787.0, memory_length 2000, epsilon 0.013576226923940561, time 733.0, rides 137\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4775, reward 1095.0, memory_length 2000, epsilon 0.013564008319709015, time 723.0, rides 146\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 4776, reward 1049.0, memory_length 2000, epsilon 0.013551800712221276, time 724.0, rides 136\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 4777, reward 1035.0, memory_length 2000, epsilon 0.013539604091580277, time 725.0, rides 146\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 4778, reward 1015.0, memory_length 2000, epsilon 0.013527418447897854, time 733.0, rides 138\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 4779, reward 1124.0, memory_length 2000, epsilon 0.013515243771294745, time 736.0, rides 130\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 4780, reward 792.0, memory_length 2000, epsilon 0.01350308005190058, time 733.0, rides 129\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 4781, reward 757.0, memory_length 2000, epsilon 0.013490927279853869, time 734.0, rides 136\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 4782, reward 734.0, memory_length 2000, epsilon 0.013478785445302, time 723.0, rides 135\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 4783, reward 1023.0, memory_length 2000, epsilon 0.013466654538401228, time 731.0, rides 135\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 4784, reward 962.0, memory_length 2000, epsilon 0.013454534549316667, time 731.0, rides 122\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 4785, reward 558.0, memory_length 2000, epsilon 0.013442425468222283, time 724.0, rides 126\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 4786, reward 814.0, memory_length 2000, epsilon 0.013430327285300882, time 725.0, rides 136\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 4787, reward 860.0, memory_length 2000, epsilon 0.013418239990744112, time 731.0, rides 132\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 4788, reward 902.0, memory_length 2000, epsilon 0.013406163574752442, time 730.0, rides 124\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 4789, reward 946.0, memory_length 2000, epsilon 0.013394098027535165, time 731.0, rides 125\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 4790, reward 870.0, memory_length 2000, epsilon 0.013382043339310383, time 729.0, rides 125\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 4791, reward 1115.0, memory_length 2000, epsilon 0.013369999500305004, time 723.0, rides 147\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 4792, reward 816.0, memory_length 2000, epsilon 0.01335796650075473, time 728.0, rides 129\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 4793, reward 918.0, memory_length 2000, epsilon 0.013345944330904051, time 726.0, rides 138\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 4794, reward 771.0, memory_length 2000, epsilon 0.013333932981006238, time 731.0, rides 129\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 4795, reward 845.0, memory_length 2000, epsilon 0.013321932441323332, time 729.0, rides 129\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 4796, reward 682.0, memory_length 2000, epsilon 0.01330994270212614, time 737.0, rides 137\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 4797, reward 1118.0, memory_length 2000, epsilon 0.013297963753694226, time 735.0, rides 134\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 4798, reward 1286.0, memory_length 2000, epsilon 0.013285995586315902, time 733.0, rides 141\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 4799, reward 829.0, memory_length 2000, epsilon 0.013274038190288218, time 723.0, rides 130\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 4800, reward 1120.0, memory_length 2000, epsilon 0.013262091555916958, time 727.0, rides 118\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 4801, reward 1067.0, memory_length 2000, epsilon 0.013250155673516633, time 740.0, rides 138\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 4802, reward 807.0, memory_length 2000, epsilon 0.013238230533410467, time 728.0, rides 132\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4803, reward 753.0, memory_length 2000, epsilon 0.013226316125930398, time 729.0, rides 142\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 4804, reward 936.0, memory_length 2000, epsilon 0.013214412441417061, time 726.0, rides 134\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 4805, reward 1026.0, memory_length 2000, epsilon 0.013202519470219786, time 731.0, rides 119\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 4806, reward 892.0, memory_length 2000, epsilon 0.013190637202696589, time 725.0, rides 127\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4807, reward 1139.0, memory_length 2000, epsilon 0.013178765629214162, time 734.0, rides 140\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 4808, reward 1040.0, memory_length 2000, epsilon 0.013166904740147868, time 728.0, rides 147\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 4809, reward 1275.0, memory_length 2000, epsilon 0.013155054525881735, time 731.0, rides 143\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 4810, reward 985.0, memory_length 2000, epsilon 0.013143214976808442, time 732.0, rides 133\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4811, reward 1098.0, memory_length 2000, epsilon 0.013131386083329314, time 731.0, rides 154\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 4812, reward 891.0, memory_length 2000, epsilon 0.013119567835854317, time 729.0, rides 139\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 4813, reward 841.0, memory_length 2000, epsilon 0.013107760224802048, time 729.0, rides 147\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 4814, reward 1209.0, memory_length 2000, epsilon 0.013095963240599726, time 730.0, rides 141\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 4815, reward 1204.0, memory_length 2000, epsilon 0.013084176873683186, time 730.0, rides 143\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 4816, reward 1051.0, memory_length 2000, epsilon 0.013072401114496871, time 728.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4817, reward 1097.0, memory_length 2000, epsilon 0.013060635953493823, time 729.0, rides 137\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 4818, reward 1266.0, memory_length 2000, epsilon 0.013048881381135679, time 728.0, rides 137\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 4819, reward 1234.0, memory_length 2000, epsilon 0.013037137387892656, time 731.0, rides 153\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 4820, reward 1037.0, memory_length 2000, epsilon 0.013025403964243553, time 728.0, rides 131\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 4821, reward 804.0, memory_length 2000, epsilon 0.013013681100675733, time 736.0, rides 146\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 4822, reward 938.0, memory_length 2000, epsilon 0.013001968787685125, time 727.0, rides 145\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 4823, reward 738.0, memory_length 2000, epsilon 0.012990267015776208, time 728.0, rides 145\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 4824, reward 843.0, memory_length 2000, epsilon 0.01297857577546201, time 731.0, rides 151\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 4825, reward 1111.0, memory_length 2000, epsilon 0.012966895057264094, time 730.0, rides 133\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 4826, reward 975.0, memory_length 2000, epsilon 0.012955224851712556, time 734.0, rides 145\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 4827, reward 1094.0, memory_length 2000, epsilon 0.012943565149346015, time 731.0, rides 137\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 4828, reward 732.0, memory_length 2000, epsilon 0.012931915940711605, time 725.0, rides 149\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 4829, reward 977.0, memory_length 2000, epsilon 0.012920277216364963, time 728.0, rides 146\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 4830, reward 727.0, memory_length 2000, epsilon 0.012908648966870235, time 726.0, rides 131\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 4831, reward 675.0, memory_length 2000, epsilon 0.012897031182800051, time 726.0, rides 141\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 4832, reward 710.0, memory_length 2000, epsilon 0.01288542385473553, time 727.0, rides 132\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 4833, reward 1297.0, memory_length 2000, epsilon 0.01287382697326627, time 739.0, rides 134\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4834, reward 1159.0, memory_length 2000, epsilon 0.01286224052899033, time 729.0, rides 137\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 4835, reward 887.0, memory_length 2000, epsilon 0.012850664512514237, time 720.0, rides 133\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 4836, reward 961.0, memory_length 2000, epsilon 0.012839098914452974, time 735.0, rides 139\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 4837, reward 813.0, memory_length 2000, epsilon 0.012827543725429966, time 734.0, rides 163\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 4838, reward 832.0, memory_length 2000, epsilon 0.012815998936077079, time 727.0, rides 150\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4839, reward 1188.0, memory_length 2000, epsilon 0.01280446453703461, time 728.0, rides 131\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 4840, reward 1094.0, memory_length 2000, epsilon 0.012792940518951279, time 720.0, rides 136\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 4841, reward 661.0, memory_length 2000, epsilon 0.012781426872484222, time 728.0, rides 109\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 4842, reward 679.0, memory_length 2000, epsilon 0.012769923588298987, time 731.0, rides 138\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 4843, reward 952.0, memory_length 2000, epsilon 0.012758430657069518, time 727.0, rides 143\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4844, reward 890.0, memory_length 2000, epsilon 0.012746948069478155, time 729.0, rides 128\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 4845, reward 707.0, memory_length 2000, epsilon 0.012735475816215624, time 730.0, rides 142\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 4846, reward 1067.0, memory_length 2000, epsilon 0.01272401388798103, time 722.0, rides 131\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 4847, reward 970.0, memory_length 2000, epsilon 0.012712562275481848, time 727.0, rides 153\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 4848, reward 919.0, memory_length 2000, epsilon 0.012701120969433913, time 722.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 4849, reward 616.0, memory_length 2000, epsilon 0.012689689960561423, time 723.0, rides 135\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 4850, reward 1033.0, memory_length 2000, epsilon 0.012678269239596918, time 737.0, rides 135\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4851, reward 954.0, memory_length 2000, epsilon 0.01266685879728128, time 723.0, rides 132\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 4852, reward 992.0, memory_length 2000, epsilon 0.012655458624363727, time 729.0, rides 143\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 4853, reward 805.0, memory_length 2000, epsilon 0.0126440687116018, time 727.0, rides 143\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 4854, reward 923.0, memory_length 2000, epsilon 0.012632689049761357, time 729.0, rides 124\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 4855, reward 734.0, memory_length 2000, epsilon 0.012621319629616571, time 731.0, rides 138\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 4856, reward 929.0, memory_length 2000, epsilon 0.012609960441949916, time 726.0, rides 131\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 4857, reward 991.0, memory_length 2000, epsilon 0.01259861147755216, time 734.0, rides 140\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 4858, reward 1109.0, memory_length 2000, epsilon 0.012587272727222362, time 729.0, rides 137\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 4859, reward 943.0, memory_length 2000, epsilon 0.012575944181767862, time 722.0, rides 134\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 4860, reward 1144.0, memory_length 2000, epsilon 0.01256462583200427, time 725.0, rides 150\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4861, reward 940.0, memory_length 2000, epsilon 0.012553317668755467, time 725.0, rides 133\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 4862, reward 1028.0, memory_length 2000, epsilon 0.012542019682853588, time 736.0, rides 137\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 4863, reward 790.0, memory_length 2000, epsilon 0.01253073186513902, time 733.0, rides 130\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 4864, reward 735.0, memory_length 2000, epsilon 0.012519454206460393, time 728.0, rides 139\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 4865, reward 515.0, memory_length 2000, epsilon 0.012508186697674579, time 726.0, rides 132\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 4866, reward 1216.0, memory_length 2000, epsilon 0.012496929329646671, time 726.0, rides 138\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 4867, reward 867.0, memory_length 2000, epsilon 0.012485682093249989, time 725.0, rides 142\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 4868, reward 1197.0, memory_length 2000, epsilon 0.012474444979366063, time 733.0, rides 127\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 4869, reward 767.0, memory_length 2000, epsilon 0.012463217978884633, time 725.0, rides 119\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 4870, reward 568.0, memory_length 2000, epsilon 0.012452001082703636, time 729.0, rides 129\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 4871, reward 1017.0, memory_length 2000, epsilon 0.012440794281729202, time 734.0, rides 135\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 4872, reward 804.0, memory_length 2000, epsilon 0.012429597566875646, time 733.0, rides 136\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 4873, reward 977.0, memory_length 2000, epsilon 0.012418410929065458, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 4874, reward 912.0, memory_length 2000, epsilon 0.012407234359229299, time 729.0, rides 136\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 4875, reward 1160.0, memory_length 2000, epsilon 0.012396067848305992, time 730.0, rides 132\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 4876, reward 1026.0, memory_length 2000, epsilon 0.012384911387242516, time 726.0, rides 138\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 4877, reward 980.0, memory_length 2000, epsilon 0.012373764966993998, time 730.0, rides 123\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 4878, reward 870.0, memory_length 2000, epsilon 0.012362628578523703, time 728.0, rides 140\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 4879, reward 765.0, memory_length 2000, epsilon 0.012351502212803032, time 732.0, rides 145\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4880, reward 747.0, memory_length 2000, epsilon 0.01234038586081151, time 729.0, rides 147\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 4881, reward 890.0, memory_length 2000, epsilon 0.01232927951353678, time 726.0, rides 136\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 4882, reward 848.0, memory_length 2000, epsilon 0.012318183161974597, time 728.0, rides 134\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 4883, reward 1068.0, memory_length 2000, epsilon 0.01230709679712882, time 727.0, rides 142\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 4884, reward 1059.0, memory_length 2000, epsilon 0.012296020410011403, time 724.0, rides 132\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 4885, reward 1110.0, memory_length 2000, epsilon 0.012284953991642393, time 730.0, rides 132\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 4886, reward 756.0, memory_length 2000, epsilon 0.012273897533049914, time 732.0, rides 146\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 4887, reward 960.0, memory_length 2000, epsilon 0.01226285102527017, time 727.0, rides 129\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 4888, reward 1065.0, memory_length 2000, epsilon 0.012251814459347426, time 731.0, rides 148\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 4889, reward 950.0, memory_length 2000, epsilon 0.012240787826334013, time 738.0, rides 129\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 4890, reward 930.0, memory_length 2000, epsilon 0.012229771117290312, time 732.0, rides 138\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 4891, reward 905.0, memory_length 2000, epsilon 0.01221876432328475, time 731.0, rides 133\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 4892, reward 821.0, memory_length 2000, epsilon 0.012207767435393794, time 733.0, rides 137\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 4893, reward 729.0, memory_length 2000, epsilon 0.01219678044470194, time 729.0, rides 145\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 4894, reward 803.0, memory_length 2000, epsilon 0.012185803342301708, time 725.0, rides 147\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 4895, reward 1053.0, memory_length 2000, epsilon 0.012174836119293637, time 729.0, rides 135\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 4896, reward 1028.0, memory_length 2000, epsilon 0.012163878766786273, time 734.0, rides 138\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 4897, reward 882.0, memory_length 2000, epsilon 0.012152931275896166, time 722.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 4898, reward 979.0, memory_length 2000, epsilon 0.012141993637747858, time 739.0, rides 142\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 4899, reward 622.0, memory_length 2000, epsilon 0.012131065843473884, time 727.0, rides 133\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 4900, reward 914.0, memory_length 2000, epsilon 0.012120147884214758, time 730.0, rides 136\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 4901, reward 819.0, memory_length 2000, epsilon 0.012109239751118965, time 726.0, rides 143\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4902, reward 1189.0, memory_length 2000, epsilon 0.012098341435342958, time 730.0, rides 127\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 4903, reward 1028.0, memory_length 2000, epsilon 0.01208745292805115, time 729.0, rides 140\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 4904, reward 1012.0, memory_length 2000, epsilon 0.012076574220415904, time 732.0, rides 133\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4905, reward 1142.0, memory_length 2000, epsilon 0.01206570530361753, time 725.0, rides 138\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 4906, reward 1015.0, memory_length 2000, epsilon 0.012054846168844275, time 732.0, rides 136\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 4907, reward 904.0, memory_length 2000, epsilon 0.012043996807292314, time 730.0, rides 129\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4908, reward 689.0, memory_length 2000, epsilon 0.01203315721016575, time 733.0, rides 129\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 4909, reward 980.0, memory_length 2000, epsilon 0.0120223273686766, time 728.0, rides 138\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 4910, reward 1079.0, memory_length 2000, epsilon 0.012011507274044791, time 729.0, rides 136\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 4911, reward 966.0, memory_length 2000, epsilon 0.01200069691749815, time 726.0, rides 140\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 4912, reward 993.0, memory_length 2000, epsilon 0.011989896290272401, time 724.0, rides 131\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 4913, reward 833.0, memory_length 2000, epsilon 0.011979105383611157, time 736.0, rides 130\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 4914, reward 1052.0, memory_length 2000, epsilon 0.011968324188765906, time 722.0, rides 133\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 4915, reward 971.0, memory_length 2000, epsilon 0.011957552696996016, time 724.0, rides 151\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 4916, reward 769.0, memory_length 2000, epsilon 0.01194679089956872, time 732.0, rides 134\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 4917, reward 872.0, memory_length 2000, epsilon 0.01193603878775911, time 727.0, rides 130\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 4918, reward 755.0, memory_length 2000, epsilon 0.011925296352850126, time 733.0, rides 144\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 4919, reward 1059.0, memory_length 2000, epsilon 0.01191456358613256, time 741.0, rides 141\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 4920, reward 882.0, memory_length 2000, epsilon 0.011903840478905041, time 729.0, rides 130\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 4921, reward 791.0, memory_length 2000, epsilon 0.011893127022474026, time 730.0, rides 129\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 4922, reward 635.0, memory_length 2000, epsilon 0.0118824232081538, time 728.0, rides 133\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 4923, reward 1121.0, memory_length 2000, epsilon 0.011871729027266461, time 728.0, rides 132\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 4924, reward 1058.0, memory_length 2000, epsilon 0.011861044471141922, time 731.0, rides 125\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 4925, reward 730.0, memory_length 2000, epsilon 0.011850369531117894, time 730.0, rides 124\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 4926, reward 873.0, memory_length 2000, epsilon 0.011839704198539887, time 730.0, rides 136\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 4927, reward 981.0, memory_length 2000, epsilon 0.011829048464761202, time 728.0, rides 136\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 4928, reward 1096.0, memory_length 2000, epsilon 0.011818402321142917, time 732.0, rides 137\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 4929, reward 1163.0, memory_length 2000, epsilon 0.011807765759053887, time 727.0, rides 125\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 4930, reward 1050.0, memory_length 2000, epsilon 0.011797138769870739, time 731.0, rides 145\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 4931, reward 962.0, memory_length 2000, epsilon 0.011786521344977855, time 727.0, rides 131\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 4932, reward 663.0, memory_length 2000, epsilon 0.011775913475767374, time 725.0, rides 131\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 4933, reward 935.0, memory_length 2000, epsilon 0.011765315153639183, time 724.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 4934, reward 951.0, memory_length 2000, epsilon 0.011754726370000908, time 725.0, rides 135\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 4935, reward 1303.0, memory_length 2000, epsilon 0.011744147116267907, time 730.0, rides 135\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 4936, reward 949.0, memory_length 2000, epsilon 0.011733577383863266, time 723.0, rides 132\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 4937, reward 589.0, memory_length 2000, epsilon 0.01172301716421779, time 732.0, rides 132\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4938, reward 546.0, memory_length 2000, epsilon 0.011712466448769993, time 732.0, rides 133\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 4939, reward 740.0, memory_length 2000, epsilon 0.0117019252289661, time 725.0, rides 144\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4940, reward 877.0, memory_length 2000, epsilon 0.011691393496260031, time 729.0, rides 137\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 4941, reward 923.0, memory_length 2000, epsilon 0.011680871242113396, time 725.0, rides 139\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 4942, reward 733.0, memory_length 2000, epsilon 0.011670358457995494, time 728.0, rides 135\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 4943, reward 887.0, memory_length 2000, epsilon 0.011659855135383299, time 730.0, rides 140\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 4944, reward 1079.0, memory_length 2000, epsilon 0.011649361265761453, time 736.0, rides 136\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 4945, reward 1172.0, memory_length 2000, epsilon 0.011638876840622267, time 724.0, rides 123\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 4946, reward 1125.0, memory_length 2000, epsilon 0.011628401851465707, time 736.0, rides 142\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 4947, reward 1078.0, memory_length 2000, epsilon 0.011617936289799388, time 721.0, rides 139\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 4948, reward 768.0, memory_length 2000, epsilon 0.011607480147138569, time 729.0, rides 135\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 4949, reward 671.0, memory_length 2000, epsilon 0.011597033415006144, time 726.0, rides 134\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 4950, reward 954.0, memory_length 2000, epsilon 0.011586596084932638, time 728.0, rides 144\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 4951, reward 1020.0, memory_length 2000, epsilon 0.011576168148456198, time 731.0, rides 145\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 4952, reward 864.0, memory_length 2000, epsilon 0.011565749597122588, time 734.0, rides 133\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 4953, reward 916.0, memory_length 2000, epsilon 0.011555340422485178, time 732.0, rides 133\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 4954, reward 873.0, memory_length 2000, epsilon 0.011544940616104941, time 728.0, rides 139\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 4955, reward 951.0, memory_length 2000, epsilon 0.011534550169550448, time 731.0, rides 120\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 4956, reward 999.0, memory_length 2000, epsilon 0.011524169074397852, time 728.0, rides 142\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 4957, reward 906.0, memory_length 2000, epsilon 0.011513797322230894, time 721.0, rides 125\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 4958, reward 1068.0, memory_length 2000, epsilon 0.011503434904640886, time 730.0, rides 132\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4959, reward 668.0, memory_length 2000, epsilon 0.011493081813226709, time 730.0, rides 143\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 4960, reward 1030.0, memory_length 2000, epsilon 0.011482738039594804, time 735.0, rides 133\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 4961, reward 768.0, memory_length 2000, epsilon 0.011472403575359169, time 725.0, rides 129\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4962, reward 789.0, memory_length 2000, epsilon 0.011462078412141346, time 723.0, rides 134\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 4963, reward 1191.0, memory_length 2000, epsilon 0.011451762541570418, time 732.0, rides 131\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 4964, reward 854.0, memory_length 2000, epsilon 0.011441455955283003, time 723.0, rides 135\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 4965, reward 1262.0, memory_length 2000, epsilon 0.011431158644923249, time 733.0, rides 132\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 4966, reward 853.0, memory_length 2000, epsilon 0.011420870602142818, time 721.0, rides 133\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 4967, reward 1069.0, memory_length 2000, epsilon 0.01141059181860089, time 733.0, rides 124\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 4968, reward 1068.0, memory_length 2000, epsilon 0.011400322285964149, time 735.0, rides 127\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 4969, reward 1124.0, memory_length 2000, epsilon 0.01139006199590678, time 726.0, rides 138\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 4970, reward 1090.0, memory_length 2000, epsilon 0.011379810940110464, time 729.0, rides 140\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4971, reward 958.0, memory_length 2000, epsilon 0.011369569110264365, time 726.0, rides 137\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 4972, reward 1203.0, memory_length 2000, epsilon 0.011359336498065127, time 729.0, rides 132\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 4973, reward 587.0, memory_length 2000, epsilon 0.011349113095216868, time 730.0, rides 128\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 4974, reward 991.0, memory_length 2000, epsilon 0.011338898893431173, time 725.0, rides 147\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 4975, reward 909.0, memory_length 2000, epsilon 0.011328693884427084, time 726.0, rides 135\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 4976, reward 933.0, memory_length 2000, epsilon 0.0113184980599311, time 724.0, rides 137\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 4977, reward 760.0, memory_length 2000, epsilon 0.01130831141167716, time 733.0, rides 138\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 4978, reward 1158.0, memory_length 2000, epsilon 0.011298133931406652, time 726.0, rides 132\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 4979, reward 1183.0, memory_length 2000, epsilon 0.011287965610868386, time 724.0, rides 138\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 4980, reward 912.0, memory_length 2000, epsilon 0.011277806441818604, time 734.0, rides 126\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 4981, reward 1251.0, memory_length 2000, epsilon 0.011267656416020967, time 726.0, rides 127\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4982, reward 856.0, memory_length 2000, epsilon 0.011257515525246549, time 724.0, rides 137\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 4983, reward 640.0, memory_length 2000, epsilon 0.011247383761273827, time 729.0, rides 134\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 4984, reward 1012.0, memory_length 2000, epsilon 0.01123726111588868, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 4985, reward 787.0, memory_length 2000, epsilon 0.01122714758088438, time 729.0, rides 132\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 4986, reward 877.0, memory_length 2000, epsilon 0.011217043148061585, time 731.0, rides 128\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4987, reward 896.0, memory_length 2000, epsilon 0.01120694780922833, time 727.0, rides 136\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 4988, reward 1071.0, memory_length 2000, epsilon 0.011196861556200024, time 728.0, rides 134\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 4989, reward 628.0, memory_length 2000, epsilon 0.011186784380799444, time 724.0, rides 135\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 4990, reward 1196.0, memory_length 2000, epsilon 0.011176716274856724, time 736.0, rides 123\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 4991, reward 1067.0, memory_length 2000, epsilon 0.011166657230209353, time 725.0, rides 123\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4992, reward 649.0, memory_length 2000, epsilon 0.011156607238702165, time 738.0, rides 130\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4993, reward 924.0, memory_length 2000, epsilon 0.011146566292187332, time 731.0, rides 131\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 4994, reward 895.0, memory_length 2000, epsilon 0.011136534382524363, time 736.0, rides 139\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 4995, reward 917.0, memory_length 2000, epsilon 0.01112651150158009, time 726.0, rides 124\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 4996, reward 910.0, memory_length 2000, epsilon 0.011116497641228669, time 721.0, rides 131\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 4997, reward 775.0, memory_length 2000, epsilon 0.011106492793351562, time 729.0, rides 130\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 4998, reward 643.0, memory_length 2000, epsilon 0.011096496949837546, time 726.0, rides 128\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 4999, reward 1126.0, memory_length 2000, epsilon 0.011086510102582693, time 733.0, rides 141\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 5000, reward 1171.0, memory_length 2000, epsilon 0.011076532243490369, time 722.0, rides 136\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 5001, reward 1053.0, memory_length 2000, epsilon 0.011066563364471227, time 726.0, rides 128\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 5002, reward 1017.0, memory_length 2000, epsilon 0.011056603457443203, time 725.0, rides 128\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 5003, reward 957.0, memory_length 2000, epsilon 0.011046652514331503, time 725.0, rides 127\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5004, reward 824.0, memory_length 2000, epsilon 0.011036710527068604, time 737.0, rides 148\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 5005, reward 1212.0, memory_length 2000, epsilon 0.011026777487594243, time 728.0, rides 133\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 5006, reward 805.0, memory_length 2000, epsilon 0.011016853387855408, time 729.0, rides 139\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 5007, reward 948.0, memory_length 2000, epsilon 0.011006938219806337, time 729.0, rides 123\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 5008, reward 975.0, memory_length 2000, epsilon 0.010997031975408512, time 729.0, rides 123\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 5009, reward 957.0, memory_length 2000, epsilon 0.010987134646630644, time 735.0, rides 131\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 5010, reward 862.0, memory_length 2000, epsilon 0.010977246225448677, time 732.0, rides 126\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 5011, reward 1021.0, memory_length 2000, epsilon 0.010967366703845773, time 735.0, rides 151\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 5012, reward 886.0, memory_length 2000, epsilon 0.010957496073812311, time 730.0, rides 137\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 5013, reward 1182.0, memory_length 2000, epsilon 0.010947634327345879, time 727.0, rides 127\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 5014, reward 1163.0, memory_length 2000, epsilon 0.010937781456451268, time 723.0, rides 143\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5015, reward 1081.0, memory_length 2000, epsilon 0.010927937453140461, time 727.0, rides 151\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 5016, reward 1055.0, memory_length 2000, epsilon 0.010918102309432635, time 729.0, rides 137\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 5017, reward 1152.0, memory_length 2000, epsilon 0.010908276017354146, time 732.0, rides 137\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 5018, reward 1374.0, memory_length 2000, epsilon 0.010898458568938526, time 728.0, rides 144\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 5019, reward 979.0, memory_length 2000, epsilon 0.010888649956226482, time 739.0, rides 136\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 5020, reward 1525.0, memory_length 2000, epsilon 0.010878850171265877, time 732.0, rides 137\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 5021, reward 1107.0, memory_length 2000, epsilon 0.010869059206111737, time 732.0, rides 134\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 5022, reward 767.0, memory_length 2000, epsilon 0.010859277052826237, time 724.0, rides 144\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 5023, reward 878.0, memory_length 2000, epsilon 0.010849503703478694, time 724.0, rides 124\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 5024, reward 906.0, memory_length 2000, epsilon 0.010839739150145562, time 726.0, rides 132\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 5025, reward 1050.0, memory_length 2000, epsilon 0.010829983384910431, time 727.0, rides 150\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 5026, reward 1016.0, memory_length 2000, epsilon 0.010820236399864012, time 731.0, rides 141\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5027, reward 849.0, memory_length 2000, epsilon 0.010810498187104134, time 735.0, rides 131\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 5028, reward 991.0, memory_length 2000, epsilon 0.01080076873873574, time 729.0, rides 127\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5029, reward 1077.0, memory_length 2000, epsilon 0.010791048046870878, time 732.0, rides 134\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 5030, reward 1207.0, memory_length 2000, epsilon 0.010781336103628695, time 728.0, rides 130\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 5031, reward 1256.0, memory_length 2000, epsilon 0.010771632901135428, time 739.0, rides 124\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 5032, reward 712.0, memory_length 2000, epsilon 0.010761938431524407, time 732.0, rides 128\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 5033, reward 961.0, memory_length 2000, epsilon 0.010752252686936034, time 723.0, rides 128\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 5034, reward 907.0, memory_length 2000, epsilon 0.010742575659517792, time 726.0, rides 123\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 5035, reward 790.0, memory_length 2000, epsilon 0.010732907341424226, time 725.0, rides 125\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 5036, reward 1193.0, memory_length 2000, epsilon 0.010723247724816944, time 726.0, rides 131\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 5037, reward 771.0, memory_length 2000, epsilon 0.010713596801864608, time 733.0, rides 131\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 5038, reward 762.0, memory_length 2000, epsilon 0.01070395456474293, time 731.0, rides 126\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 5039, reward 1161.0, memory_length 2000, epsilon 0.01069432100563466, time 735.0, rides 127\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 5040, reward 894.0, memory_length 2000, epsilon 0.01068469611672959, time 727.0, rides 123\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 5041, reward 823.0, memory_length 2000, epsilon 0.010675079890224533, time 729.0, rides 128\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 5042, reward 666.0, memory_length 2000, epsilon 0.010665472318323332, time 727.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 5043, reward 768.0, memory_length 2000, epsilon 0.01065587339323684, time 724.0, rides 128\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 5044, reward 911.0, memory_length 2000, epsilon 0.010646283107182927, time 730.0, rides 122\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 5045, reward 914.0, memory_length 2000, epsilon 0.010636701452386462, time 728.0, rides 123\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 5046, reward 485.0, memory_length 2000, epsilon 0.010627128421079313, time 721.0, rides 130\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 5047, reward 832.0, memory_length 2000, epsilon 0.010617564005500343, time 724.0, rides 142\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 5048, reward 1102.0, memory_length 2000, epsilon 0.010608008197895391, time 728.0, rides 130\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 5049, reward 786.0, memory_length 2000, epsilon 0.010598460990517285, time 725.0, rides 120\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 5050, reward 930.0, memory_length 2000, epsilon 0.01058892237562582, time 732.0, rides 140\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 5051, reward 1110.0, memory_length 2000, epsilon 0.010579392345487756, time 727.0, rides 125\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 5052, reward 930.0, memory_length 2000, epsilon 0.010569870892376817, time 726.0, rides 132\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5053, reward 1054.0, memory_length 2000, epsilon 0.010560358008573677, time 729.0, rides 132\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 5054, reward 1193.0, memory_length 2000, epsilon 0.010550853686365961, time 728.0, rides 136\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 5055, reward 905.0, memory_length 2000, epsilon 0.010541357918048232, time 726.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 5056, reward 817.0, memory_length 2000, epsilon 0.010531870695921989, time 732.0, rides 119\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 5057, reward 756.0, memory_length 2000, epsilon 0.01052239201229566, time 734.0, rides 130\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 5058, reward 770.0, memory_length 2000, epsilon 0.010512921859484593, time 728.0, rides 140\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 5059, reward 785.0, memory_length 2000, epsilon 0.010503460229811057, time 725.0, rides 132\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 5060, reward 993.0, memory_length 2000, epsilon 0.010494007115604227, time 733.0, rides 142\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 5061, reward 702.0, memory_length 2000, epsilon 0.010484562509200183, time 725.0, rides 138\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 5062, reward 862.0, memory_length 2000, epsilon 0.010475126402941903, time 723.0, rides 131\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 5063, reward 812.0, memory_length 2000, epsilon 0.010465698789179256, time 728.0, rides 131\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 5064, reward 667.0, memory_length 2000, epsilon 0.010456279660268995, time 734.0, rides 135\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 5065, reward 853.0, memory_length 2000, epsilon 0.010446869008574753, time 729.0, rides 140\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 5066, reward 800.0, memory_length 2000, epsilon 0.010437466826467035, time 725.0, rides 129\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 5067, reward 863.0, memory_length 2000, epsilon 0.010428073106323214, time 730.0, rides 128\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 5068, reward 786.0, memory_length 2000, epsilon 0.010418687840527522, time 729.0, rides 130\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 5069, reward 1038.0, memory_length 2000, epsilon 0.010409311021471046, time 734.0, rides 138\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 5070, reward 675.0, memory_length 2000, epsilon 0.010399942641551722, time 729.0, rides 139\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 5071, reward 905.0, memory_length 2000, epsilon 0.010390582693174326, time 726.0, rides 133\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 5072, reward 1086.0, memory_length 2000, epsilon 0.01038123116875047, time 728.0, rides 132\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 5073, reward 882.0, memory_length 2000, epsilon 0.010371888060698595, time 728.0, rides 129\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 5074, reward 673.0, memory_length 2000, epsilon 0.010362553361443965, time 730.0, rides 133\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 5075, reward 874.0, memory_length 2000, epsilon 0.010353227063418666, time 737.0, rides 131\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 5076, reward 850.0, memory_length 2000, epsilon 0.010343909159061589, time 725.0, rides 130\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 5077, reward 868.0, memory_length 2000, epsilon 0.010334599640818433, time 726.0, rides 130\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 5078, reward 1105.0, memory_length 2000, epsilon 0.010325298501141696, time 731.0, rides 141\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 5079, reward 762.0, memory_length 2000, epsilon 0.010316005732490668, time 728.0, rides 129\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 5080, reward 1229.0, memory_length 2000, epsilon 0.010306721327331427, time 725.0, rides 126\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 5081, reward 723.0, memory_length 2000, epsilon 0.010297445278136828, time 727.0, rides 136\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5082, reward 759.0, memory_length 2000, epsilon 0.010288177577386506, time 730.0, rides 135\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5083, reward 977.0, memory_length 2000, epsilon 0.010278918217566858, time 727.0, rides 135\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 5084, reward 1014.0, memory_length 2000, epsilon 0.010269667191171047, time 726.0, rides 134\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 5085, reward 922.0, memory_length 2000, epsilon 0.010260424490698994, time 723.0, rides 146\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 5086, reward 852.0, memory_length 2000, epsilon 0.010251190108657365, time 727.0, rides 134\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 5087, reward 751.0, memory_length 2000, epsilon 0.010241964037559573, time 727.0, rides 142\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 5088, reward 832.0, memory_length 2000, epsilon 0.010232746269925768, time 729.0, rides 134\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 5089, reward 904.0, memory_length 2000, epsilon 0.010223536798282836, time 723.0, rides 146\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5090, reward 1009.0, memory_length 2000, epsilon 0.010214335615164381, time 725.0, rides 136\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5091, reward 1000.0, memory_length 2000, epsilon 0.010205142713110732, time 730.0, rides 133\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 5092, reward 1040.0, memory_length 2000, epsilon 0.010195958084668933, time 727.0, rides 148\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 5093, reward 842.0, memory_length 2000, epsilon 0.010186781722392731, time 730.0, rides 122\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 5094, reward 619.0, memory_length 2000, epsilon 0.010177613618842578, time 728.0, rides 127\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 5095, reward 760.0, memory_length 2000, epsilon 0.01016845376658562, time 729.0, rides 133\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 5096, reward 866.0, memory_length 2000, epsilon 0.010159302158195693, time 723.0, rides 132\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 5097, reward 1213.0, memory_length 2000, epsilon 0.010150158786253317, time 725.0, rides 140\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 5098, reward 972.0, memory_length 2000, epsilon 0.010141023643345688, time 721.0, rides 125\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 5099, reward 781.0, memory_length 2000, epsilon 0.010131896722066677, time 731.0, rides 145\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 5100, reward 983.0, memory_length 2000, epsilon 0.010122778015016817, time 728.0, rides 133\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 5101, reward 1005.0, memory_length 2000, epsilon 0.0101136675148033, time 724.0, rides 128\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 5102, reward 944.0, memory_length 2000, epsilon 0.010104565214039978, time 727.0, rides 133\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 5103, reward 930.0, memory_length 2000, epsilon 0.010095471105347342, time 725.0, rides 137\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 5104, reward 805.0, memory_length 2000, epsilon 0.01008638518135253, time 734.0, rides 139\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 5105, reward 1040.0, memory_length 2000, epsilon 0.010077307434689313, time 726.0, rides 142\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 5106, reward 905.0, memory_length 2000, epsilon 0.010068237857998092, time 722.0, rides 140\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 5107, reward 968.0, memory_length 2000, epsilon 0.010059176443925894, time 726.0, rides 137\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 5108, reward 1095.0, memory_length 2000, epsilon 0.01005012318512636, time 727.0, rides 135\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 5109, reward 944.0, memory_length 2000, epsilon 0.010041078074259746, time 727.0, rides 132\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 5110, reward 1161.0, memory_length 2000, epsilon 0.010032041103992912, time 733.0, rides 142\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 5111, reward 1279.0, memory_length 2000, epsilon 0.010023012266999318, time 726.0, rides 139\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 5112, reward 910.0, memory_length 2000, epsilon 0.010013991555959018, time 725.0, rides 128\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 5113, reward 838.0, memory_length 2000, epsilon 0.010004978963558654, time 730.0, rides 148\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 5114, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 5115, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 5116, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 5117, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 5118, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 5119, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 5120, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 5121, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 114\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 5122, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 5123, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 5124, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 5125, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5126, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 5127, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 5128, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 5129, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 5130, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 5131, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 5132, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 5133, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 5134, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 5135, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 5136, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 5137, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5138, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5139, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5140, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 5141, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 5142, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 5143, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 5144, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 5145, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 5146, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 5147, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 5148, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 5149, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 5150, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5151, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 5152, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 141\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 5153, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5154, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 5155, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 5156, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5157, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 5158, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 5159, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 5160, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 127\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 5161, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 5162, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 5163, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 5164, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 5165, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 5166, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5167, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 5168, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 5169, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 5170, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5171, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5172, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 5173, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 5174, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 5175, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 5176, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 5177, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 5178, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 5179, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 5180, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 146\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 5181, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 5182, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5183, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 5184, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 5185, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 5186, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 5187, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 5188, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 5189, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5190, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 5191, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 5192, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 5193, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 137\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5194, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 5195, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 140\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5196, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 5197, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 5198, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 5199, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 5200, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 5201, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 5202, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 146\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 5203, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 5204, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 5205, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 5206, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5207, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5208, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5209, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 5210, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 5211, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 5212, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 5213, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 5214, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 5215, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 5216, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 130\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 5217, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 5218, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 5219, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5220, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 5221, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 5222, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 5223, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 5224, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 5225, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 5226, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 5227, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 5228, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 5229, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 5230, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 5231, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5232, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 5233, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5234, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 5235, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 5236, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 5237, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 5238, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 5239, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 5240, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 5241, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 5242, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5243, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 5244, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 5245, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 5246, reward 1387.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5247, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 5248, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 5249, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 5250, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 5251, reward 1317.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 5252, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5253, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 5254, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 5255, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 5256, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 5257, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 5258, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 5259, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 5260, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5261, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 5262, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 5263, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 5264, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 5265, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 5266, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 5267, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 5268, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 5269, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 5270, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 5271, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 5272, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 5273, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 5274, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 5275, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 5276, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 5277, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 154\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 5278, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 5279, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5280, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5281, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 5282, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 5283, reward 1318.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 5284, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 5285, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5286, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 5287, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 5288, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 5289, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 5290, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 5291, reward 1245.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5292, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 5293, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 5294, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 5295, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 5296, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 5297, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 5298, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 5299, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5300, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 5301, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5302, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 5303, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 5304, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 5305, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 5306, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 5307, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 5308, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 5309, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 5310, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 5311, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 5312, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 5313, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5314, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 5315, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 5316, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 5317, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 153\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 5318, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5319, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 5320, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 5321, reward 1358.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 5322, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 5323, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 5324, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 5325, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 5326, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 5327, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 5328, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 5329, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 5330, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 5331, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 5332, reward 1281.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 152\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 5333, reward 573.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 5334, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 5335, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 5336, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 5337, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 5338, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 122\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 5339, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5340, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 5341, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 5342, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 5343, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 5344, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 5345, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 5346, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 5347, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 5348, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 5349, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 5350, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 5351, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5352, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 5353, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 5354, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 5355, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 5356, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 5357, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 5358, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 123\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 5359, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 5360, reward 594.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 5361, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 5362, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 5363, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 5364, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 5365, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 5366, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 5367, reward 1423.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 5368, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 5369, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 5370, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 5371, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 5372, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 5373, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 5374, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5375, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 5376, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 5377, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 5378, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 5379, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 5380, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 5381, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 5382, reward 1355.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 5383, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 5384, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 5385, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 5386, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 5387, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 5388, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 5389, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 5390, reward 1358.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 5391, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 5392, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 5393, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 5394, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 5395, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 5396, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 5397, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 5398, reward 494.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 5399, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5400, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 113\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 5401, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 5402, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 5403, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 5404, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5405, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 5406, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 5407, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 5408, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 5409, reward 483.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 5410, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 5411, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 5412, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 119\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 5413, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 5414, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 5415, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 5416, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 5417, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 5418, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 5419, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5420, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 5421, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 120\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 5422, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 5423, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 5424, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 5425, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 5426, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 5427, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 5428, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 5429, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 5430, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 5431, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 5432, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 5433, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 5434, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5435, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 5436, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 5437, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 5438, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 5439, reward 576.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 5440, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 148\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 5441, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 5442, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 153\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 5443, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 5444, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 5445, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 5446, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 5447, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 5448, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5449, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5450, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 5451, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 5452, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 5453, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 5454, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 5455, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 5456, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 5457, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 5458, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5459, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 5460, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 5461, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 5462, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 5463, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5464, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 5465, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 5466, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5467, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 118\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 5468, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 5469, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5470, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 5471, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 5472, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 5473, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 5474, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 5475, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 5476, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 5477, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 5478, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 5479, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 5480, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 5481, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 5482, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 5483, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 5484, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 112\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 5485, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 5486, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 5487, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 5488, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 5489, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 5490, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 5491, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 5492, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 5493, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 114\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 5494, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 5495, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 5496, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 5497, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 5498, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 5499, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 152\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 5500, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 5501, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 5502, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 5503, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 5504, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 5505, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 5506, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 5507, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 5508, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5509, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 5510, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 5511, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 5512, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 5513, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 5514, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 5515, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 5516, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5517, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 5518, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 5519, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 5520, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5521, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 5522, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 5523, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 5524, reward 1433.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 5525, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5526, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 5527, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 5528, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 5529, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 5530, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 5531, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 5532, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 5533, reward 554.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 5534, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 116\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 5535, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5536, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 5537, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 117\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 5538, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 5539, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 5540, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 5541, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 5542, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 5543, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 5544, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 5545, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 5546, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 5547, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 5548, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 5549, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 5550, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 5551, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 5552, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 5553, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 5554, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5555, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 5556, reward 650.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 5557, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 5558, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 5559, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 119\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 5560, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5561, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 5562, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 5563, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 5564, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5565, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 5566, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 5567, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 5568, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 5569, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 5570, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5571, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 5572, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 5573, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 5574, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 5575, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5576, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5577, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 5578, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 5579, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 5580, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 5581, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 5582, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 5583, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 5584, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 5585, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 5586, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 5587, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 5588, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 5589, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 5590, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 5591, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 5592, reward 623.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 5593, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 5594, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 5595, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5596, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 5597, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 5598, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 5599, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 5600, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5601, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 5602, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5603, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 5604, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 5605, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 5606, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 5607, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 5608, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 5609, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 5610, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 5611, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 5612, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 5613, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 5614, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 5615, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 5616, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 5617, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 5618, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 5619, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 5620, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 5621, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 5622, reward 1294.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5623, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 5624, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 5625, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 5626, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5627, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5628, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5629, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 5630, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 5631, reward 610.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 5632, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 5633, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 5634, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 137\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 5635, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 5636, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 5637, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 5638, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 5639, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 5640, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 5641, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 5642, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 5643, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 5644, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 5645, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 5646, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 5647, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 5648, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 5649, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 121\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 5650, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 5651, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 5652, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 5653, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 5654, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 5655, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 5656, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 5657, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5658, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 5659, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 5660, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 5661, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 5662, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5663, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 5664, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 5665, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 5666, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 5667, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5668, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5669, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 121\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 5670, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 5671, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 5672, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 5673, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5674, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 5675, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 5676, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 5677, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 5678, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 5679, reward 645.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 5680, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 5681, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 5682, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5683, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5684, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 5685, reward 669.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 5686, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 5687, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5688, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 5689, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5690, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 5691, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 5692, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 5693, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5694, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 120\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 5695, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 5696, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 5697, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 5698, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 5699, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 5700, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5701, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5702, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 5703, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 5704, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 5705, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 5706, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 5707, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 5708, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 5709, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 5710, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5711, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 5712, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 5713, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 5714, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 5715, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 5716, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 5717, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 5718, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 5719, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 5720, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 5721, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 5722, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 5723, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 5724, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5725, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 5726, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 5727, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 5728, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 5729, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 5730, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 5731, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 5732, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 5733, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 5734, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 5735, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 5736, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 5737, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 5738, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 5739, reward 521.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 5740, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 5741, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 5742, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 5743, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 5744, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 5745, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5746, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 5747, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 5748, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 5749, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 5750, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 5751, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5752, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 120\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5753, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5754, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 5755, reward 585.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 5756, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 5757, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 5758, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 5759, reward 515.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 5760, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 5761, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5762, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 5763, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 5764, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 5765, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 5766, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 5767, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 5768, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 5769, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 5770, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5771, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 5772, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 5773, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 5774, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 5775, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5776, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 5777, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 5778, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5779, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 5780, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 5781, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 5782, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 5783, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 5784, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 5785, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 5786, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 5787, reward 566.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 5788, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 5789, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 5790, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 5791, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 5792, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 5793, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 127\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 5794, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 137\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 5795, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 5796, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 5797, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 5798, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 5799, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 5800, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 5801, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 5802, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 5803, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 5804, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 5805, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 5806, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 5807, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 5808, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 5809, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 5810, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 5811, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 5812, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 5813, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 5814, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 5815, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5816, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 5817, reward 544.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 5818, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 5819, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 5820, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5821, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 5822, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 5823, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 5824, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 5825, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 5826, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 5827, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5828, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 5829, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 5830, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 5831, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5832, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 5833, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 5834, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 5835, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5836, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 5837, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 5838, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 5839, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 5840, reward 1369.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 5841, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 5842, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 5843, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 5844, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 5845, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5846, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 5847, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 5848, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 5849, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 5850, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 5851, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 5852, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5853, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 5854, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 5855, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 5856, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 5857, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 5858, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 5859, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 141\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 5860, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 5861, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 117\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 5862, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 5863, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5864, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 5865, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 5866, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 5867, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 5868, reward 1316.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5869, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 5870, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 5871, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 5872, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 148\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 5873, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 5874, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 5875, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 5876, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 5877, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 5878, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 5879, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 5880, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 5881, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 5882, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 120\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 5883, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 5884, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 5885, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 5886, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 5887, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 5888, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 5889, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 5890, reward 480.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 5891, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 5892, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 5893, reward 1337.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 5894, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 5895, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 5896, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5897, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 5898, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 5899, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 5900, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 5901, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 5902, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 5903, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5904, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 5905, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 5906, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 5907, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 5908, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 5909, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 5910, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 5911, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 5912, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 5913, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 5914, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 118\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 5915, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 5916, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5917, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 5918, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 5919, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 5920, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 5921, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 5922, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5923, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 5924, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5925, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 5926, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 5927, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 5928, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 5929, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 5930, reward 1322.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 5931, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5932, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 5933, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 5934, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 5935, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 5936, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 5937, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 5938, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 5939, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 5940, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 5941, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 5942, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 5943, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 5944, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 5945, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5946, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 5947, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 122\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 5948, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 5949, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5950, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 5951, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 5952, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 5953, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 5954, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 5955, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 5956, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 5957, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5958, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 5959, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5960, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 5961, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 5962, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 5963, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 5964, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 5965, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 5966, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 5967, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 5968, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 5969, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 5970, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 5971, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 5972, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 5973, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 5974, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 5975, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5976, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 5977, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 5978, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 5979, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 5980, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 130\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 5981, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5982, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 5983, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 5984, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 5985, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 5986, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 5987, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 116\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 5988, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5989, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 5990, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 5991, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 5992, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 5993, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 5994, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 146\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 5995, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5996, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 5997, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 5998, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 5999, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 6000, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 6001, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 6002, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 6003, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6004, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 6005, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 6006, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 6007, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 6008, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 6009, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 6010, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6011, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 6012, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 6013, reward 553.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6014, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 6015, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 6016, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 6017, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 6018, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6019, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6020, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 6021, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 6022, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 6023, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6024, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 6025, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 6026, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 6027, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6028, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 6029, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 6030, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 6031, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 6032, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 6033, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6034, reward 1297.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 6035, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 6036, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 6037, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 6038, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 6039, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 126\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 6040, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6041, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 127\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 6042, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 6043, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 6044, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 6045, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 6046, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 6047, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 6048, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 6049, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6050, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 6051, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 6052, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 6053, reward 1282.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 6054, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 6055, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 6056, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 6057, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 6058, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 6059, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 6060, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 6061, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 6062, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 6063, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 6064, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 6065, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 6066, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 6067, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 6068, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 6069, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 6070, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 6071, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 6072, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 6073, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6074, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 745.0, rides 151\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 6075, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 6076, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 6077, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 6078, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 6079, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 6080, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 6081, reward 514.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 6082, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 6083, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 6084, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 6085, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 6086, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 6087, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 6088, reward 1369.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6089, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6090, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 6091, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 6092, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6093, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6094, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 6095, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 6096, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 6097, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 6098, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 6099, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6100, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 118\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 6101, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 6102, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 6103, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 6104, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 6105, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 6106, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6107, reward 1345.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 6108, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 6109, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 6110, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 6111, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 6112, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 6113, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6114, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 6115, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 6116, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 6117, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 6118, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 6119, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6120, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 6121, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 6122, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6123, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6124, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 6125, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6126, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6127, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 6128, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 6129, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 6130, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 6131, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 6132, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 6133, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 6134, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 6135, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 6136, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 6137, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 6138, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6139, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 6140, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 6141, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 6142, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 6143, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 6144, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6145, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 6146, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 6147, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 6148, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6149, reward 1321.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 6150, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 6151, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 6152, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 6153, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 6154, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 6155, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 141\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 6156, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 6157, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 6158, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 6159, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 6160, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 6161, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 6162, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 6163, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 6164, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 6165, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 6166, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 6167, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 6168, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6169, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 6170, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 6171, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 6172, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 6173, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 6174, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 6175, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6176, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6177, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 6178, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 6179, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 6180, reward 1463.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 6181, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 6182, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 6183, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 6184, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 6185, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 6186, reward 561.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 6187, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 6188, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 6189, reward 484.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 6190, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 117\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 6191, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6192, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6193, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 6194, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6195, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 6196, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6197, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 6198, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 6199, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 6200, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 6201, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 6202, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 6203, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6204, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 6205, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 6206, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 6207, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 6208, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 6209, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 121\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 6210, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 6211, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 6212, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 6213, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 6214, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 6215, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 6216, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 6217, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 6218, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 131\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 6219, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 6220, reward 1327.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 6221, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6222, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 6223, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 6224, reward 1440.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 6225, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 6226, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 6227, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 6228, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6229, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 6230, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6231, reward 1301.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6232, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 6233, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6234, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 6235, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 6236, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 6237, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 6238, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6239, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 6240, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 6241, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 6242, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6243, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 6244, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 6245, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 6246, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 6247, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 121\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 6248, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 6249, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 6250, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 6251, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 6252, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 6253, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 6254, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 6255, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 6256, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6257, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6258, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 6259, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6260, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 6261, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 6262, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 135\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 6263, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6264, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 6265, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 6266, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 6267, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 6268, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6269, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 6270, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 6271, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 6272, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 6273, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6274, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 6275, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 6276, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 6277, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 6278, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 6279, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 6280, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 6281, reward 1449.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 6282, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 6283, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 6284, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 6285, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 6286, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 6287, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 6288, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 6289, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 6290, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 6291, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 6292, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 6293, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 6294, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6295, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 6296, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 6297, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 6298, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 6299, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 6300, reward 621.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 6301, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 6302, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 120\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 6303, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6304, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6305, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 6306, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6307, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 6308, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6309, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 6310, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 6311, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 6312, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 6313, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 6314, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 6315, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 6316, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6317, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 6318, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 6319, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 6320, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 6321, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6322, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 6323, reward 1426.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 6324, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 6325, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 6326, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 6327, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 6328, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 6329, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 6330, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 6331, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 6332, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 6333, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 6334, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 6335, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 6336, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 6337, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6338, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 6339, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 6340, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6341, reward 584.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 6342, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 6343, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6344, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 6345, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 6346, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 125\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 6347, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 6348, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 6349, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 6350, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 6351, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 6352, reward 531.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 6353, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 6354, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 6355, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6356, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 6357, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6358, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 6359, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 6360, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 6361, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6362, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 6363, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6364, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 6365, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 6366, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 6367, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 6368, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 6369, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 6370, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 6371, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 6372, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 6373, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 6374, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6375, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 6376, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 123\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 6377, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 6378, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 6379, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 6380, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 6381, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 120\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6382, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 6383, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 6384, reward 494.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 6385, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 6386, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 6387, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6388, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 6389, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 6390, reward 1310.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 6391, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 6392, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 6393, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 6394, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 6395, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 6396, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 6397, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 6398, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 6399, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 6400, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 6401, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 6402, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 6403, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 6404, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 6405, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 6406, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 6407, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 6408, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 6409, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 116\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 6410, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 6411, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 6412, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 6413, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6414, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 6415, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 6416, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 6417, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6418, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 6419, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6420, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 6421, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 6422, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 6423, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 6424, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 6425, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 6426, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 6427, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 6428, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 6429, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 137\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 6430, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 6431, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 6432, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 6433, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 6434, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 6435, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 6436, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 6437, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 6438, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 6439, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 6440, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 6441, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6442, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 6443, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 6444, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 6445, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 6446, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 6447, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 6448, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 117\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 6449, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6450, reward 566.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 114\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 6451, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 6452, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 6453, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 6454, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 6455, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 6456, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 6457, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 6458, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 6459, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 123\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 6460, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 6461, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 6462, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 6463, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 6464, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 6465, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 6466, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 6467, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 6468, reward 1304.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 6469, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 6470, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 6471, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 6472, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 6473, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 6474, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 6475, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 6476, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 6477, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 6478, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 126\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 6479, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 6480, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 6481, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6482, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 6483, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6484, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 6485, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 6486, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 6487, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 6488, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 6489, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 6490, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 6491, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 6492, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 6493, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 119\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 6494, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 6495, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 6496, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 6497, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6498, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 6499, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 6500, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 6501, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 6502, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 6503, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6504, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 6505, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 6506, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 6507, reward 550.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 6508, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 116\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 6509, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 6510, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 6511, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 6512, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6513, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 6514, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 6515, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 6516, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 6517, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 6518, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 6519, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6520, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 6521, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 6522, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 6523, reward 1317.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 6524, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 6525, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 6526, reward 1295.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 6527, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6528, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 6529, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6530, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 6531, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 6532, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 6533, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6534, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 6535, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 6536, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 6537, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 6538, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 124\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 6539, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 118\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 6540, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 6541, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6542, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 6543, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 118\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6544, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 6545, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6546, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 6547, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 6548, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 6549, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 6550, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 115\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 6551, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 6552, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 6553, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 6554, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6555, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6556, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 6557, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 6558, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 6559, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 114\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 6560, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 6561, reward 1305.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 6562, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 6563, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 6564, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 6565, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 6566, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 6567, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 115\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6568, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 6569, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 6570, reward 1265.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 6571, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 6572, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 6573, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 6574, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 6575, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 6576, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 6577, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 6578, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 6579, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 6580, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 6581, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 6582, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 131\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6583, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 6584, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 119\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 6585, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 6586, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6587, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 6588, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6589, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 6590, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 6591, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 6592, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 119\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 6593, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 6594, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6595, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 6596, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 6597, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 6598, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 6599, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 6600, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 6601, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 121\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 6602, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 6603, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 6604, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 6605, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 6606, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 6607, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 6608, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 6609, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 6610, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 6611, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 6612, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 6613, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 6614, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 6615, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 6616, reward 595.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6617, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 6618, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 118\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6619, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 118\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 6620, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 6621, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 6622, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 6623, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 6624, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 6625, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 6626, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 6627, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 6628, reward 566.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 6629, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6630, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 6631, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 6632, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 6633, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 6634, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6635, reward 1353.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6636, reward 595.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 6637, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 6638, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 6639, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 6640, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 6641, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 6642, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 6643, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 6644, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 6645, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6646, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 6647, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 6648, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 6649, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6650, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 6651, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 6652, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6653, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 6654, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 6655, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 6656, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 6657, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6658, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 6659, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 6660, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 6661, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6662, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 6663, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6664, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 6665, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 6666, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 6667, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 6668, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 6669, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 6670, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 6671, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 6672, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6673, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 6674, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 6675, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 6676, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 6677, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 6678, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 6679, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 6680, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 6681, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 6682, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 6683, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 6684, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 6685, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 6686, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6687, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 6688, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 6689, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 6690, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 6691, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 6692, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 6693, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 6694, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 118\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6695, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 6696, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6697, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 6698, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 6699, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 142\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 6700, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6701, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 6702, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6703, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6704, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 6705, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 6706, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6707, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 6708, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 6709, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 6710, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 6711, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 6712, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 6713, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 124\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 6714, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 6715, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 6716, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6717, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 141\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 6718, reward 582.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 6719, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6720, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 6721, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 6722, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 6723, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 6724, reward 1372.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 6725, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 116\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 6726, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 152\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 6727, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 6728, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 6729, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 6730, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 124\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6731, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 6732, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 6733, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 6734, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 6735, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6736, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 6737, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 6738, reward 605.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 6739, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 6740, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 6741, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 6742, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 6743, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 6744, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 6745, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 6746, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 6747, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 6748, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 6749, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6750, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 6751, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 6752, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 6753, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 6754, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 6755, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 6756, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 6757, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 6758, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 6759, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 6760, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 6761, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 6762, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 6763, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 6764, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 6765, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6766, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 6767, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 126\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 6768, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 6769, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 6770, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 6771, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 6772, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 6773, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 6774, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 6775, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 6776, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 6777, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 6778, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 6779, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6780, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 124\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 6781, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6782, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6783, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 6784, reward 1282.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 6785, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 6786, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 6787, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6788, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 6789, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 6790, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 6791, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 6792, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 6793, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6794, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 6795, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 6796, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 6797, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 6798, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 6799, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 6800, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 6801, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 6802, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6803, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 6804, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 6805, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 6806, reward 537.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6807, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 6808, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 6809, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 6810, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 6811, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 6812, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 6813, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 6814, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 6815, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 6816, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 6817, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6818, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 6819, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 6820, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 6821, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 6822, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 6823, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 6824, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 6825, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 6826, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 6827, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 6828, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 6829, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 6830, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 6831, reward 637.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 6832, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6833, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 6834, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 6835, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 6836, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 6837, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 6838, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 6839, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 114\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 6840, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 6841, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 6842, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 6843, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 6844, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6845, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6846, reward 1245.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 149\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 6847, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 6848, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 6849, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 6850, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6851, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 6852, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 6853, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 6854, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 6855, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 6856, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 6857, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 6858, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 6859, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 6860, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 6861, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 6862, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6863, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 6864, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 6865, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6866, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 6867, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6868, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 6869, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 153\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6870, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6871, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 6872, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 6873, reward 613.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 6874, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 6875, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 6876, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 6877, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 6878, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 6879, reward 486.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 6880, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 6881, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 6882, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 6883, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 6884, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 6885, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 6886, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 149\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 6887, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6888, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 115\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 6889, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 6890, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 6891, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 6892, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 6893, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 155\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 6894, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6895, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 6896, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 116\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 6897, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 6898, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6899, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 6900, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 6901, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 154\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 6902, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 6903, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 6904, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 6905, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 6906, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 6907, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 6908, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 6909, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 6910, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 6911, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 6912, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 6913, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 6914, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 6915, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 6916, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 6917, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 6918, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 6919, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 6920, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 6921, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 114\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 6922, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 6923, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 6924, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 6925, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 6926, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 6927, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 6928, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 6929, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 6930, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 6931, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 6932, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 6933, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 6934, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 6935, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6936, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 6937, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 6938, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 6939, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 6940, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 6941, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 6942, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6943, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 6944, reward 1412.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 6945, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 6946, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 6947, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 6948, reward 1311.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 6949, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 6950, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 6951, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 6952, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 6953, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 6954, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 6955, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 6956, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 6957, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 6958, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 6959, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 6960, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 6961, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 6962, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 6963, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 136\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 6964, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 6965, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 6966, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6967, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 118\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 6968, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 6969, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6970, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 153\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 6971, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 6972, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 6973, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 6974, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 6975, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6976, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 6977, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 6978, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 6979, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 6980, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 116\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 6981, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 6982, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 6983, reward 514.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 110\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 6984, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 6985, reward 656.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 6986, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 6987, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 120\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 6988, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 6989, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 6990, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 6991, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6992, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6993, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 6994, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 6995, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 6996, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 6997, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 6998, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 6999, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 7000, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7001, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 7002, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7003, reward 386.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7004, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7005, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 7006, reward 1356.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 7007, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 7008, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 7009, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7010, reward 518.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 7011, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 7012, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 7013, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 7014, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 122\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7015, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 122\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7016, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 7017, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 7018, reward 498.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 7019, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 7020, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 7021, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 7022, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 7023, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 120\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 7024, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 7025, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 7026, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7027, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 7028, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 7029, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 7030, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 7031, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7032, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 7033, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 7034, reward 617.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 7035, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 7036, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 7037, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 7038, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 7039, reward 552.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 7040, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 7041, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 7042, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7043, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 7044, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 7045, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7046, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7047, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 7048, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 7049, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 7050, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 7051, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 7052, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7053, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 7054, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 7055, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 7056, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 7057, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 7058, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 7059, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 7060, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 157\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 7061, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 7062, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 7063, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 7064, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 7065, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 7066, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 7067, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 7068, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 7069, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 7070, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 7071, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 7072, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 7073, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 7074, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 7075, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 7076, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 7077, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 7078, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 7079, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 7080, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 7081, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 7082, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 150\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 7083, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 7084, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 7085, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 7086, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 7087, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 7088, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 7089, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 7090, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 7091, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 7092, reward 1354.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 7093, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 7094, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 7095, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7096, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 7097, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7098, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 7099, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 7100, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 7101, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 7102, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 7103, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7104, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 7105, reward 1334.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 7106, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 7107, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 7108, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 7109, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 7110, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 7111, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 7112, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 7113, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 7114, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 7115, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 7116, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 7117, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7118, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 745.0, rides 143\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 7119, reward 515.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 7120, reward 467.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 7121, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 7122, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 7123, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 7124, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 7125, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7126, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 7127, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 7128, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7129, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 7130, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 7131, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 7132, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7133, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 7134, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7135, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 7136, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 7137, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 7138, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 7139, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 7140, reward 584.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7141, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 7142, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 7143, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 7144, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 7145, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 7146, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 7147, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 7148, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7149, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 7150, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 7151, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 7152, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 7153, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 7154, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7155, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 7156, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 7157, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 7158, reward 1306.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7159, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 7160, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 7161, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 7162, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7163, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 7164, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 7165, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7166, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7167, reward 536.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7168, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 7169, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 7170, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 7171, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7172, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 7173, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 143\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 7174, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7175, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 7176, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 7177, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 7178, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7179, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 7180, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 7181, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 7182, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 7183, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 7184, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 7185, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 7186, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7187, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7188, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 7189, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 7190, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 7191, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 7192, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 7193, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 7194, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7195, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 7196, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 7197, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 7198, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 7199, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 7200, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 7201, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 7202, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 7203, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7204, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 7205, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 7206, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 7207, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 7208, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 7209, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7210, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 7211, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 7212, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 7213, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 7214, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 7215, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 7216, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 7217, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 7218, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 7219, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 7220, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7221, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 7222, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 7223, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 7224, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 7225, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 7226, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 7227, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 7228, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 7229, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 7230, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 7231, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 7232, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 7233, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 7234, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 7235, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 7236, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 7237, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 7238, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 7239, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 7240, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 7241, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 7242, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 7243, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7244, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 7245, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 7246, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 7247, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 7248, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 7249, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7250, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 7251, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7252, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7253, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 7254, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 7255, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 7256, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 7257, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7258, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 126\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 7259, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 7260, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 7261, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 7262, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 7263, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 7264, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 7265, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 7266, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 7267, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 7268, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 7269, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 7270, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 7271, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 7272, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 7273, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7274, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7275, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 7276, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7277, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7278, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 7279, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 7280, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 145\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 7281, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 7282, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7283, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 7284, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 7285, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 7286, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 7287, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 125\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 7288, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7289, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 7290, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7291, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 7292, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 7293, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 7294, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7295, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 7296, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 7297, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 7298, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7299, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 7300, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 7301, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 7302, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 7303, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 7304, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 7305, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 7306, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 7307, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 7308, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 7309, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7310, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 7311, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 7312, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 7313, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 7314, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 7315, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 7316, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 7317, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 7318, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 7319, reward 623.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 7320, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 7321, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 7322, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 7323, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 7324, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 7325, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 7326, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 7327, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 7328, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7329, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 7330, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 7331, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 7332, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 7333, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 7334, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 7335, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 7336, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 7337, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 7338, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 7339, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 7340, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 7341, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7342, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 7343, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7344, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 7345, reward 396.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 132\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 7346, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 7347, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 7348, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 7349, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 7350, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 7351, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 7352, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 7353, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 7354, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 7355, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 7356, reward 591.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7357, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7358, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 7359, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 7360, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 7361, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 7362, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 7363, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 7364, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 7365, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 7366, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7367, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 7368, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 120\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 7369, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 7370, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 7371, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 7372, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7373, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7374, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 7375, reward 427.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7376, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 7377, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 7378, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 7379, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 7380, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7381, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 7382, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 7383, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 7384, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 7385, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 7386, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 7387, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 7388, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 153\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 7389, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 7390, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7391, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 7392, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 7393, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 7394, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 7395, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 7396, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 152\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7397, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 7398, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 7399, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 7400, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 7401, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 7402, reward 511.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 7403, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 7404, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 7405, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 7406, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 7407, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7408, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7409, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 7410, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 7411, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 7412, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 7413, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7414, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 7415, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 7416, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 7417, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 7418, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 7419, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 7420, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 7421, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 7422, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7423, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 120\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 7424, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 7425, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 7426, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7427, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 7428, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 7429, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 7430, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 7431, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 7432, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 7433, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 7434, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7435, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 7436, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 138\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 7437, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 7438, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 7439, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7440, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 7441, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 7442, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 7443, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7444, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 118\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 7445, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7446, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 154\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 7447, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7448, reward 508.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 7449, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7450, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 7451, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 7452, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7453, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 7454, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7455, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 7456, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 7457, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 7458, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 7459, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7460, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 7461, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 7462, reward 554.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 7463, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 7464, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 7465, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 7466, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7467, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 7468, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 7469, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 7470, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 7471, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 7472, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7473, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 7474, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 7475, reward 1388.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 7476, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 7477, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 7478, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 7479, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 7480, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 7481, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 7482, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 7483, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7484, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7485, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 7486, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 7487, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 7488, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 155\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7489, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 156\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 7490, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 7491, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7492, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 7493, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 7494, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 7495, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 7496, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 7497, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 7498, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 7499, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 7500, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7501, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 7502, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 7503, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 7504, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 7505, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 7506, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7507, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 7508, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 7509, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 7510, reward 592.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 7511, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 7512, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 7513, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 7514, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7515, reward 533.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 150\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 7516, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 7517, reward 1321.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 7518, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 7519, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 7520, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 7521, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 7522, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 7523, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 7524, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7525, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 7526, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 7527, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 7528, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 7529, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 7530, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 116\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7531, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 7532, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 7533, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 7534, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 7535, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 7536, reward 575.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 7537, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 7538, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 7539, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 7540, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 7541, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 7542, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 7543, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 7544, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7545, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 7546, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 7547, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 7548, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 7549, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 7550, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 7551, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 113\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 7552, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 7553, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7554, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 7555, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 7556, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 7557, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 7558, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 7559, reward 626.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 7560, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7561, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 7562, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 7563, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 7564, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 7565, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7566, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7567, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 7568, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 7569, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 113\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 7570, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7571, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 7572, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 7573, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 7574, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7575, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7576, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 7577, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 7578, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 7579, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 7580, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 138\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7581, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 7582, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 7583, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 7584, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 7585, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 7586, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 7587, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 7588, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 7589, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7590, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 7591, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 7592, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 7593, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 7594, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 7595, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 7596, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 7597, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 7598, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7599, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 7600, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 7601, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 7602, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 7603, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 7604, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 7605, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 7606, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 7607, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 7608, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 7609, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 7610, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 7611, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 7612, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7613, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 7614, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 7615, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7616, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 7617, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7618, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 7619, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 7620, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 7621, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 7622, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 7623, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 7624, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 7625, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7626, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 7627, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7628, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 7629, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 7630, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 7631, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 7632, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 7633, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 7634, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 7635, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 7636, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 7637, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 7638, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 7639, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 7640, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 7641, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 7642, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 7643, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 7644, reward 589.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7645, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 7646, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 7647, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 7648, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 7649, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 7650, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 7651, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 7652, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 7653, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 7654, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 7655, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7656, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 7657, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 7658, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 7659, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 7660, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 7661, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 7662, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 7663, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 7664, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 7665, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 7666, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 7667, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7668, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 7669, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 7670, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 7671, reward 1349.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 7672, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 7673, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7674, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 7675, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 7676, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 7677, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 7678, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 7679, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7680, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 7681, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 7682, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 7683, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 7684, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7685, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 7686, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 7687, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 7688, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 7689, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 7690, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 7691, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 7692, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 7693, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 7694, reward 568.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 7695, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 7696, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7697, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 7698, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 7699, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7700, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 7701, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 7702, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 7703, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 7704, reward 1301.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 7705, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 7706, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7707, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 7708, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7709, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7710, reward 539.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 7711, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 7712, reward 1382.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 7713, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 7714, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 7715, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 7716, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 7717, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 7718, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7719, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 7720, reward 624.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 7721, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 7722, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 7723, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 7724, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 7725, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 7726, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 7727, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 7728, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 7729, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 7730, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 7731, reward 1418.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 7732, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 7733, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 7734, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 159\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 7735, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 7736, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7737, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7738, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7739, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 7740, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 7741, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7742, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 7743, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 7744, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 7745, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 7746, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7747, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 7748, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 7749, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 7750, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 7751, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 7752, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 7753, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7754, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7755, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 7756, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 7757, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7758, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 7759, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 7760, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 7761, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 7762, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 7763, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 7764, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 116\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 7765, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 7766, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 7767, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7768, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 7769, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 7770, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 7771, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 7772, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 7773, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 7774, reward 485.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 115\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 7775, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 7776, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 7777, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 7778, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 7779, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 7780, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 7781, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 7782, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 114\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 7783, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 7784, reward 568.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 7785, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 7786, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 7787, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7788, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 7789, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7790, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7791, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 7792, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 7793, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 7794, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 7795, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7796, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 7797, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 7798, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7799, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 7800, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7801, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 7802, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 116\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7803, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 7804, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 7805, reward 442.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 7806, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7807, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 7808, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 7809, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 7810, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 7811, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 7812, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 7813, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 7814, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 7815, reward 608.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 7816, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 7817, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 7818, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 7819, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 7820, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 7821, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 7822, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 7823, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 119\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 7824, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 7825, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 7826, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 7827, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 7828, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 157\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7829, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 7830, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 7831, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 7832, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7833, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 7834, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 7835, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 7836, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 7837, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 7838, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 7839, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 7840, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 113\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 7841, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 7842, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 7843, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 7844, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 7845, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 7846, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 7847, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7848, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7849, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 7850, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 7851, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 7852, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7853, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 7854, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 7855, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 7856, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 7857, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 7858, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 7859, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 7860, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 7861, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 7862, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7863, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 7864, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 7865, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 7866, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 7867, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 7868, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 7869, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 7870, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7871, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 7872, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 7873, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 7874, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 7875, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 7876, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 7877, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 7878, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 7879, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 7880, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 7881, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7882, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 7883, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 7884, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 7885, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 121\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 7886, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 114\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 7887, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 7888, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 7889, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 7890, reward 475.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 7891, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 7892, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 7893, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 7894, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7895, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 7896, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 7897, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7898, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 7899, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 7900, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 7901, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 7902, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 7903, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7904, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 7905, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7906, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 7907, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 7908, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 7909, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 7910, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 7911, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 7912, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 7913, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 7914, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 7915, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7916, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 7917, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 7918, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 7919, reward 1301.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 7920, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 7921, reward 1261.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 7922, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 7923, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 7924, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 7925, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7926, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 7927, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 7928, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7929, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 7930, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 7931, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 7932, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 7933, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 7934, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 7935, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7936, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 129\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 7937, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 7938, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 7939, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 7940, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 7941, reward 1383.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7942, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7943, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 7944, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 7945, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 7946, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7947, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 7948, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7949, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 7950, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 7951, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 7952, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 7953, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7954, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 140\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7955, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 7956, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 7957, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7958, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 7959, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 7960, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 7961, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 7962, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 128\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7963, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 7964, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 114\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 7965, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 7966, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 7967, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 7968, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 7969, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 7970, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 7971, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 7972, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 7973, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7974, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 7975, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 7976, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7977, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 7978, reward 572.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 7979, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 7980, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 7981, reward 623.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 7982, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 7983, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7984, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 7985, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7986, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 7987, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7988, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 7989, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 154\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 7990, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 7991, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7992, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 7993, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 7994, reward 492.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 158\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 7995, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7996, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 7997, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 128\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 7998, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 7999, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(36,21)\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    # Call all the initialised variables of the environment\n",
    "    state_space = env.state_space\n",
    "    action_space = env.action_space\n",
    "    state = env.state_init\n",
    "    print(\"Initial State is \",state)\n",
    "    time = 0\n",
    "    #Call the DQN agent\n",
    "    terminal_state = False\n",
    "    score = 0\n",
    "    action = agent.get_action(env.state_encod_arch1(state),env)\n",
    "    score += env.reward_func(state,action_space[action],Time_matrix)\n",
    "    next_state,ride_time = env.next_state_func(state,action_space[action],Time_matrix)\n",
    "    time += ride_time\n",
    "    if time >= 24*30:\n",
    "        agent.append_sample(env.state_encod_arch1(state),action,score,env.state_encod_arch1(next_state),True)\n",
    "    else:\n",
    "        agent.append_sample(env.state_encod_arch1(state),action,score,env.state_encod_arch1(next_state),False)\n",
    "    loop = 0\n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        \n",
    "        if time >= 24*30:\n",
    "            terminal_state = True\n",
    "            pass\n",
    "        state = next_state\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        action = agent.get_action(env.state_encod_arch1(state),env)\n",
    "        # 2. Evaluate your reward and next state\n",
    "        reward_curr_ride = env.reward_func(state,action_space[action],Time_matrix)\n",
    "        score+= reward_curr_ride\n",
    "        next_state,ride_time = env.next_state_func(next_state,action_space[action],Time_matrix)\n",
    "        time += ride_time\n",
    "        # 3. Append the experience to the memory\n",
    "        if time >= 24*30:\n",
    "            agent.append_sample(env.state_encod_arch1(state),action,reward_curr_ride,env.state_encod_arch1(next_state),True)\n",
    "        else:\n",
    "            agent.append_sample(env.state_encod_arch1(state),action,reward_curr_ride,env.state_encod_arch1(next_state),False)\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model(env)\n",
    "        #print('Time elapsed {} and current loop {}'.format(time,loop))\n",
    "        loop+= 1\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "    \n",
    "    rewards_per_episode.append(score)   \n",
    "    episodes.append(episode)\n",
    "    \n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}, time {4}, rides {5}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon,time,loop))\n",
    "    # every few episodes:\n",
    "    if episode % 1000 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "\n",
    "        # save model weights\n",
    "        agent.save(name=\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        34.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        36.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        23.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        -4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        4,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        27.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -3.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        23.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        27.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        18,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        18.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        7,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        27.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        18.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -26.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        44.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        20,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        7,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -13.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -5.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -15.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -18.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        -17.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        10.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -21.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        22.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -5.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        14.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        20,\n",
       "        3.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        26.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        23.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -6.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        -30.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        36.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        7.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        11.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        -15.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        14,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        20,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        13.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        32.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        14.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        -4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        17.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -3.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        -13.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        -12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        20,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        8,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        3.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        40.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        15.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        10.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        36.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        -4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -30.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        23.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        -45.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        -36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -39.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -15.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        44.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        -6.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        11.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -10.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        4,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        5.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        15.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        7.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        -7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        26.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -17.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        11.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        20,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        14.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        -12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        9.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        29.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        -14.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        44.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        8,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        13.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        3.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -17.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        10.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -15.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        22.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        23.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        -17.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        7,\n",
       "        6.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        -15.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        20,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        22.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -12.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -22.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        20,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        9.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        18,\n",
       "        -6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        44.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        7,\n",
       "        -14.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -27.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        13.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0fe9f4bf60>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes,rewards_per_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above graph shows that the rewards increased and stabilised after 4000 epochs as given by the epsilon function at the end of file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon2=[]\n",
    "for i in range(0,10000):\n",
    "    if i==0:\n",
    "        epsilon2.append(1)\n",
    "    else:\n",
    "        epsilon2.append(0.9991 * epsilon2[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
